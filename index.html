<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Longer Vision</title>
  <meta name="author" content="Nobody">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Longer Vision"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Longer Vision" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Longer Vision</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-11T00:38:47.000Z"><a href="/2017/03/10/opencv-calibration/">2017-03-10</a></time>
      
      
  
    <h1 class="title"><a href="/2017/03/10/opencv-calibration/">Camera Posture Estimation Using A Single aruco Marker</a></h1>
  

    </header>
    <div class="entry">
      
        <p></p><h2>Preparation</h2><br>Before start coding, you need to make sure that the camera to be used has already been calibrated. (Camera calibration is covered in our blog, and some pieces of codes are provided as well.) In the following coding, it’s assumed that you can successfully load the camera calibration parameters.<p></p>
<p></p><h2>Coding</h2><br>The code can be found at<p></p>
<p></p><h3>First of all</h3><br>We need to ensure cv2.so is included under our system folder. <strong>cv2.so</strong> is specifically for OpenCV Python.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">import sys</div><div class="line">sys.path.append(&apos;/usr/local/python/3.5&apos;)</div></pre></td></tr></table></figure><p></p>
<p>Then, some standard packages need to be imported. (Due to your own requirements)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">import os</div><div class="line">import cv2</div><div class="line">from cv2 import aruco</div><div class="line">import numpy as np</div></pre></td></tr></table></figure></p>
<p></p><h3>Secondly</h3><br>We now load all camera calibration parameters, including: <strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. For example, your code might look like the following:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">calibrationFile = &quot;calibrationFileName.xml&quot;</div><div class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</div><div class="line">camera_matrix = calibrationParams.getNode(&quot;cameraMatrix&quot;).mat()</div><div class="line">dist_coeffs = calibrationParams.getNode(&quot;distCoeffs&quot;).mat()</div></pre></td></tr></table></figure><p></p>
<p>Since we are testing a calibrated fisheye camera, two extra parameters are to be loaded from the calibration file.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">r = calibrationParams.getNode(&quot;R&quot;).mat()</div><div class="line">new_camera_matrix = calibrationParams.getNode(&quot;newCameraMatrix&quot;).mat()</div></pre></td></tr></table></figure></p>
<p>Afterwards, two mapping matrices are calculated by calling function <strong>cv2.fisheye.initUndistortRectifyMap()</strong> as (supposing the images to be processed are of 1080P):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">image_size = (1920, 1080)</div><div class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</div></pre></td></tr></table></figure></p>
<p></p><h3>Thirdly</h3><br>We load a dictionary to be used. Current OpenCV provides four groups of <a href="http://docs.opencv.org/trunk/d9/d6a/group__aruco.html" target="_blank" rel="external">aruco</a> patterns, <strong>4X4</strong>, <strong>5X5</strong>, <strong>6X6</strong>, <strong>7X7</strong>, etc. Here, <strong>aruco.DICT_6X6_1000</strong> is arbitrarily selected as an example, which looks like:<br><img src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/marker_66.jpg" alt="aruco.DICT_6X6_1000" title="aruco.DICT_6X6_1000">.<br>And, after having this aruco square marker printed, we need to measure the edge length of this particular marker, and have this length stored in a variable.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">aruco_dict = aruco.Dictionary_get( aruco.DICT_6X6_1000 )</div></pre></td></tr></table></figure><p></p>
<p>Meanwhile, create aruco detector with default parameters.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">arucoParams = aruco.DetectorParameters_create()</div><div class="line">markerLength = 20 # Here, I&apos;m using centimetre as a unit.</div></pre></td></tr></table></figure></p>
<p></p><h3>Finally</h3><br>Estimate camera postures. Here, we are testing a sequence of images, instead of video streams. We first list all file names in sequence.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">imgDir = &quot;imgSequence&quot;  # Specify the image directory</div><div class="line">imgFileNames = [os.path.join(imgDir, fn) for fn in next(os.walk(imgDir))[2]]</div><div class="line">nbOfImgs = len(imgFileNames)</div></pre></td></tr></table></figure><p></p>
<p>Then, we calculate the camera posture frame by frame:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">for i in range(0, nbOfImgs):</div><div class="line">  img = cv2.imread(imgFileNames[i], cv2.IMREAD_GRAYSCALE)</div><div class="line">  imgRemapped = cv2.remap(img, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT) # for fisheye remapping</div><div class="line">  imRemapped_color = cv2.cvtColor(imgRemapped, cv2.COLOR_GRAY2BGR)  # for later display in color</div><div class="line"></div><div class="line">  corners, ids, rejectedImgPoints = aruco.detectMarkers(imgRemapped, aruco_dict, parameters=arucoParams) # Detect aruco</div><div class="line">  if ids != None: # if aruco marker detected</div><div class="line">    rvec, tvec = aruco.estimatePoseSingleMarkers(corners, markerLength, camera_matrix, dist_coeffs) # For a single marker</div><div class="line">    imgWithAruco = aruco.drawDetectedMarkers(imRemapped_color, corners, ids, (0,255,0))</div><div class="line">    imgWithAruco = aruco.drawAxis(imgWithAruco, camera_matrix, dist_coeffs, rvec, tvec, 100)  # axis length 100 can be changed according to your requirement</div><div class="line">  else: # if aruco marker is NOT detected</div><div class="line">    imgWithAruco = imRemapped_color # assign imRemapped_color to imgWithAruco directly</div><div class="line"></div><div class="line">  cv2.imshow(&quot;aruco&quot;, imgWithAruco) # display</div><div class="line"></div><div class="line">  if cv2.waitKey(2) &amp; 0xFF == ord(&apos;q&apos;): # if &apos;q&apos; is pressed, quit.</div><div class="line">        break</div></pre></td></tr></table></figure></p>
<p>The drawn axis is just the world coordinators and orientations that estimated from the images taken by the testing camera.</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-11T00:24:13.000Z"><a href="/2017/03/10/hi-nobody/">2017-03-10</a></time>
      
      
  
    <h1 class="title"><a href="/2017/03/10/hi-nobody/">Hello World</a></h1>
  

    </header>
    <div class="entry">
      
        <p>Hi, everyone. This is Nobody from <a href="http://www.longervision.ca" target="_blank" rel="external">Longer Vision Technology</a>. I come back to life, at least, half life. And finally, I decided to write something, either useful, or useless. Hope my blogs will be able to help some of the pure researchers, as well as students, in the field of Computer Vision &amp; Machine Vision. By the way, our products will be put on sale soon. Keep an eye on our blogs please. Thank you…</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Suche">
    <input type="hidden" name="q" value="site:longervision.github.io">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/tags/Camera-Posture-Estimation-aruco-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, aruco, Marker, Pattern, OpenCV, Python</a><small>1</small></li>
  
    <li><a href="/tags/Longer-Vision-Technology-Computer-Vision-Machine-Vision/">Longer Vision Technology, Computer Vision, Machine Vision</a><small>1</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2017 Nobody
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>
