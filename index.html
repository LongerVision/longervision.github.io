<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="English">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/logo3d.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/logo3d_32X32.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/logo3d_16x16.png?v=6.3.0">


  <link rel="mask-icon" href="/images/logo3d.svg?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Longer Vision Technology Github Blog">
<meta name="keywords" content="Longer Vision, Computer Vision, AI, Machine Learning">
<meta property="og:type" content="website">
<meta property="og:title" content="Longer Vision Technology">
<meta property="og:url" content="http://longervision.ca/index.html">
<meta property="og:site_name" content="Longer Vision Technology">
<meta property="og:description" content="Longer Vision Technology Github Blog">
<meta property="og:locale" content="English">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Longer Vision Technology">
<meta name="twitter:description" content="Longer Vision Technology Github Blog">






  <link rel="canonical" href="http://longervision.ca/">



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Longer Vision Technology</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="English">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Longer Vision Technology</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Github Blog</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>
  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2019/01/29/Robotics/IgnitionRobotics-Gazebo/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/29/Robotics/IgnitionRobotics-Gazebo/" itemprop="url">
                  Ignition Robotics - Gazebo
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-29 00:00:00" itemprop="dateCreated datePublished" datetime="2019-01-29T00:00:00-08:00">2019-01-29</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-02-07 00:56:09" itemprop="dateModified" datetime="2019-02-07T00:56:09-08:00">2019-02-07</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Robotics/" itemprop="url" rel="index"><span itemprop="name">Robotics</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>It seems <a href="http://gazebosim.org/" target="_blank" rel="noopener">Gazebo</a> is <strong>NOW</strong> a part of <a href="https://ignitionrobotics.org/" target="_blank" rel="noopener">Ignition Robotics</a>??? Please take a look at my Ignition Robotics Bitbucket Issue <a href="https://bitbucket.org/ignitionrobotics/ign-gazebo/issues/11/whats-the-realationship-between-ign-gazebo" target="_blank" rel="noopener">What’s the realationship between ign-gazebo and gazebo?</a> And, today, let’s <strong>build <a href="https://bitbucket.org/ignitionrobotics/" target="_blank" rel="noopener">IgnitionRobotics</a> from source</strong>.</p>
<h1 id="how-to-build-ignitionrobotics"><a class="markdownIt-Anchor" href="#how-to-build-ignitionrobotics"></a> How to Build IgnitionRobotics</h1>
<h2 id="use-branch-gz11"><a class="markdownIt-Anchor" href="#use-branch-gz11"></a> Use Branch gz11</h2>
<p><span style="color:red"><strong>NOTE</strong>: In order to have the <strong>LATEST</strong> version built, please make sure you always give the priority to branch <strong>gz11</strong> rather than branch <strong>default</strong>.</span></p>
<p>For instance <a href="https://bitbucket.org/ignitionrobotics/ign-cmake/src/gz11/" target="_blank" rel="noopener">ign-cmake</a>:</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://bitbucket.org/ignitionrobotics/ign-cmake/src/gz11/</span><br></pre></td></tr></table></figure>
<h2 id="important-things"><a class="markdownIt-Anchor" href="#important-things"></a> Important Things</h2>
<p>Two things to emphasize before building.</p>
<ol>
<li>To have all the packages at <a href="https://ignitionrobotics.org/libs" target="_blank" rel="noopener">Ignition Robotics Development Libraries</a> successfully built, we need to build all libraries <strong>in a particular sequence</strong>.</li>
<li>Some required 3rd-party libraries are <strong>additionally</strong> installed while building <a href="https://ignitionrobotics.org/libs" target="_blank" rel="noopener">Ignition Robotics Development Libraries</a>, including:</li>
</ol>
<ul>
<li><a href="https://github.com/OSGeo/gdal/" target="_blank" rel="noopener">gdal</a></li>
<li><a href="https://github.com/dartsim/dart" target="_blank" rel="noopener">DART</a></li>
<li><a href="https://github.com/openscenegraph/OpenSceneGraph" target="_blank" rel="noopener">OpenSceneGraph</a></li>
<li><a href="https://bitbucket.org/sinbad/ogre/src/v2-1/" target="_blank" rel="noopener">Ogre2</a></li>
<li><a href="https://github.com/vrpn/vrpn" target="_blank" rel="noopener">vrpn</a></li>
<li><a href="https://github.com/OSVR/OSVR-Core.git" target="_blank" rel="noopener">OSVR</a>: Please make sure <strong>unifiedvideoinertialtracker</strong> is excluded from building for now.</li>
</ul>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#add_subdirectory(unifiedvideoinertialtracker)</span></span><br></pre></td></tr></table></figure>
<ul>
<li><a href="https://github.com/facebook/folly/" target="_blank" rel="noopener">folly</a>: required by <strong>unifiedvideoinertialtracker</strong>, which requires <a href="https://www.boost.org/" target="_blank" rel="noopener">boost</a> built by <strong>C++14</strong>. For now, this is <strong>excluded</strong> from building.</li>
</ul>
<h2 id="build-ignition-robotics"><a class="markdownIt-Anchor" href="#build-ignition-robotics"></a> Build Ignition Robotics</h2>
<p>Now, let’s start building <a href="https://ignitionrobotics.org/libs" target="_blank" rel="noopener">Ignition Robotics Development Libraries</a>.</p>
<ol>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-cmake/src/gz11/" target="_blank" rel="noopener">ign-cmake</a>: <strong>BUILD_TESTING OFF</strong></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-math/src/gz11" target="_blank" rel="noopener">ign-math</a>: <strong>ruby-dev needs to be installed FIRST</strong></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-common/src/gz11" target="_blank" rel="noopener">ign-common</a>: <strong>libgts needs to be installed FIRST</strong></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-tools/src/default/" target="_blank" rel="noopener">ign-tools</a></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-msgs/src/gz11/" target="_blank" rel="noopener">ign-msgs</a></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-transport/src/gz11/" target="_blank" rel="noopener">ign-transport</a>: <strong>CXX_FLAGS=-I/usr/include/c++/7</strong> and comment out line #35 of file <strong>test_config.cpp</strong>.</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//#include &lt;filesystem&gt; // line 35</span></span><br></pre></td></tr></table></figure>
<ol start="7">
<li><a href="https://bitbucket.org/ignitionrobotics/ign-rendering/src/default/" target="_blank" rel="noopener">ign-rendering</a>: Modify <strong>CMakeLists.txt line 62</strong>, <strong>ogre</strong> to <strong>ogre2</strong></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-gui/src/gz11/" target="_blank" rel="noopener">ign-gui</a></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-plugin/src/gz11/" target="_blank" rel="noopener">ign-plugin</a></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-fuel-tools/src/default/" target="_blank" rel="noopener">ign-fuel-tools</a></li>
<li><a href="https://bitbucket.org/osrf/sdformat/src/gz11/" target="_blank" rel="noopener">SDFormat8</a>: <strong>C++8 is required for building</strong></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-physics/src/gz11/" target="_blank" rel="noopener">ign-physics</a>: Since I’m using <a href="https://github.com/dartsim/dart" target="_blank" rel="noopener">dart 7.0</a>, please figure out some trivial bugs about <strong>DartLoader</strong> in file <a href="https://bitbucket.org/ignitionrobotics/ign-physics/src/default/test/plugins/DARTDoublePendulum.cc" target="_blank" rel="noopener">DARTDoublePendulum.cc</a>.</li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-sensors/src/default/" target="_blank" rel="noopener">ign-sensors</a></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-gazebo/src/default/" target="_blank" rel="noopener">ign-gazebo</a></li>
<li><a href="https://bitbucket.org/osrf/gazebo/src/default/" target="_blank" rel="noopener">gazebo</a>: <strong>Going to be deprecated soon</strong></li>
</ol>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- BUILD WARNINGS</span><br><span class="line">-- Oculus Rift support will be disabled.</span><br><span class="line">-- END BUILD WARNINGS</span><br></pre></td></tr></table></figure>
<h1 id="some-bugs-proposed-by-me"><a class="markdownIt-Anchor" href="#some-bugs-proposed-by-me"></a> Some Bugs Proposed by Me</h1>
<ul>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-gazebo/issues/11/whats-the-realationship-between-ign-gazebo" target="_blank" rel="noopener">What’s the realationship between ign-gazebo and gazebo?</a></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-rendering/issues/43/should-i-have-both-ogre-and-ogre2" target="_blank" rel="noopener">Should I have both OGRE and OGRE2 installed?</a></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-gui/issues/38/gz11-missing-ignition-rendering1" target="_blank" rel="noopener">gz11 - Missing: ignition-rendering1 (Components: ogre)</a></li>
<li><a href="https://bitbucket.org/ignitionrobotics/ign-cmake/issues/50/make-6-cmakefiles-codecheck-error-1" target="_blank" rel="noopener">make[6]: *** [CMakeFiles/codecheck] Error 1</a></li>
</ul>
<h1 id="some-tests"><a class="markdownIt-Anchor" href="#some-tests"></a> Some Tests</h1>
<h2 id="ign-rendering"><a class="markdownIt-Anchor" href="#ign-rendering"></a> <a href="https://bitbucket.org/ignitionrobotics/ign-rendering/src/gz11/" target="_blank" rel="noopener">ign-rendering</a> via <a href="https://bitbucket.org/sinbad/ogre/branch/v2-1" target="_blank" rel="noopener">Ogre2</a> Test</h2>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">21:31:15: Starting .../IgnitionRobotics/Ogre2Demo...</span><br><span class="line">[Wrn] [ColladaLoader.cc:2070] Triangle input semantic: 'COLOR' is currently not supported</span><br><span class="line">[Msg] Loading plugin [ignition-rendering1-ogre2]</span><br><span class="line">===============================</span><br><span class="line">  TAB - Switch render engines  </span><br><span class="line">  ESC - Exit                   </span><br><span class="line">===============================</span><br><span class="line">Selected visual at position: 309 294: pump</span><br><span class="line">Selected visual at position: 458 307: sphere</span><br><span class="line">Selected visual at position: 515 327: pump</span><br><span class="line">Selected visual at position: 447 365: pump</span><br><span class="line">Selected visual at position: 497 427: plane</span><br><span class="line">Selected visual at position: 197 328: cylinder</span><br><span class="line">Selected visual at position: 241 394: cylinder</span><br><span class="line">Selected visual at position: 130 340: duck</span><br><span class="line">Selected visual at position: 419 444: duck</span><br><span class="line">No visual found at position: 503 296</span><br><span class="line">Selected visual at position: 505 350: pump</span><br><span class="line">Selected visual at position: 412 326: pump</span><br><span class="line">Selected visual at position: 385 230: duck</span><br><span class="line">Selected visual at position: 361 264: box</span><br><span class="line">Selected visual at position: 396 270: sphere</span><br><span class="line">Selected visual at position: 322 335: pump</span><br><span class="line">Selected visual at position: 359 352: plane</span><br><span class="line">Selected visual at position: 539 422: plane</span><br><span class="line">Selected visual at position: 406 366: pump</span><br><span class="line">Selected visual at position: 431 374: pump</span><br><span class="line">Selected visual at position: 510 422: cylinder</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/IgnitionRobotics/01_ogre2_demo.png" alt="Ogre2 Demo"></p>
<h2 id="ign-gazebo"><a class="markdownIt-Anchor" href="#ign-gazebo"></a> <a href="https://bitbucket.org/ignitionrobotics/ign-gazebo/src/default/" target="_blank" rel="noopener">ign-gazebo</a> Performance Test</h2>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/IgnitionRobotics/02_matching-entity.png" alt="Matching Entity"></p>
<h2 id="ign-gazebo-2"><a class="markdownIt-Anchor" href="#ign-gazebo-2"></a> <a href="https://bitbucket.org/ignitionrobotics/ign-gazebo/src/default/" target="_blank" rel="noopener">ign-gazebo</a> Integration Test</h2>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2019/01/26/Robotics/ZR3D-drone-4-Surveying-Mapping/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/26/Robotics/ZR3D-drone-4-Surveying-Mapping/" itemprop="url">
                  ZR3D Drone for Surveying & Mapping
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-26 00:00:00 / Modified: 07:38:05" itemprop="dateCreated datePublished" datetime="2019-01-26T00:00:00-08:00">2019-01-26</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Robotics/" itemprop="url" rel="index"><span itemprop="name">Robotics</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/04_zr3d_southsurvey_6wings_overview_01.jpg" alt="ZR3D South Survey Drone with 6 Wings Overview"></p>
<p>In my <a href="https://longervision.github.io/2019/01/25/DeepLearning/TorchSeg-HUST/" target="_blank" rel="noopener">last blog</a>, I talked about <a href="https://github.com/ycszen/TorchSeg" target="_blank" rel="noopener">TorchSeg</a>, a <a href="https://pytorch.org/" target="_blank" rel="noopener">PyTorch</a> open source developed by my <strong>master’s lab, namely: <a href="http://auto.hust.edu.cn/info/1108/3394.htm" target="_blank" rel="noopener">The State-Level key Laboratory of Multispectral Signal Processing</a></strong> in <strong><a href="http://english.hust.edu.cn/" target="_blank" rel="noopener">Huazhong University of Science and Technology</a></strong>.</p>
<p>Today, I’m going to introduce professional drones developed by a start-up company <strong><a href="http://www.zr3d.cn/" target="_blank" rel="noopener">ZR3D</a></strong>, which is spinned-out from my <strong>bachelor’s department, namely: <a href="http://rsgis.whu.edu.cn/" target="_blank" rel="noopener">School of Remote Sensing and Information Engineering</a></strong> in <strong><a href="https://en.whu.edu.cn/" target="_blank" rel="noopener">Wuhan University</a></strong>. By the way, <strong><a href="http://www.lmars.whu.edu.cn/" target="_blank" rel="noopener">The State key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing</a></strong> in <strong><a href="https://en.whu.edu.cn/" target="_blank" rel="noopener">Wuhan University</a></strong> is specialized in <a href="https://en.wikipedia.org/wiki/Photogrammetry" target="_blank" rel="noopener">Tilt photogrammetry</a>.</p>
<p>OK, now it’s the time to show some of <strong><a href="http://www.zr3d.cn/" target="_blank" rel="noopener">ZR3D</a></strong>’s products.</p>
<h1 id="outdoor-work"><a class="markdownIt-Anchor" href="#outdoor-work"></a> Outdoor Work</h1>
<h2 id="the-drone"><a class="markdownIt-Anchor" href="#the-drone"></a> The Drone</h2>
<p><strong>Outdoor video capturing</strong> can be stably done by <strong><a href="http://www.zr3d.cn/" target="_blank" rel="noopener">ZR3D</a></strong> drones. In the following, we show some pictures of an OEMed drone manufactured/assembled by <strong><a href="http://www.zr3d.cn/" target="_blank" rel="noopener">ZR3D</a></strong>.</p>
<table>
<thead>
<tr>
<th style="text-align:center"><a href="http://www.zr3d.cn/" target="_blank" rel="noopener">ZR3D</a></th>
<th style="text-align:center"><a href="http://www.southsurvey.com/" target="_blank" rel="noopener">South Survey</a></th>
<th style="text-align:center"><a href="http://www.longervision.cn" target="_blank" rel="noopener">Longer Vision</a></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/01_inbox.jpg" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/01_inbox.jpg" alt="In Box"></a></td>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/02_openbox_inner_view_layer2.jpg" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/02_openbox_inner_view_layer2.jpg" alt="Open Box Layer 2"></a></td>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/03_front_view_02.jpg" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/03_front_view_02.jpg" alt="Front View"></a></td>
</tr>
<tr>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/04_zr3d_southsurvey_6wings_overview_01.jpg" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/04_zr3d_southsurvey_6wings_overview_01.jpg" alt="Overview"></a></td>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/05_front_view_01.jpg" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/05_front_view_01.jpg" alt="Front View"></a></td>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/06_openbox_inner_view_layer1.jpg" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/06_openbox_inner_view_layer1.jpg" alt="Open Box Layer 1"></a></td>
</tr>
<tr>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/07_thecam_01.jpg" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/07_thecam_01.jpg" alt="Camera"></a></td>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/08_thecam_02.jpg" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/08_thecam_02.jpg" alt="Camera"></a></td>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/09_pivot.jpg" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/09_pivot.jpg" alt="Pivot"></a></td>
</tr>
<tr>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/10_thewing_01.jpg" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/10_thewing_01.jpg" alt="Wing"></a></td>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/11_thewing_02.jpg" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/11_thewing_02.jpg" alt="Wing"></a></td>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/12_thewing_03.jpg" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/Robots/Drones/12_thewing_03.jpg" alt="Wing"></a></td>
</tr>
</tbody>
</table>
<h2 id="captured-sample-images-for-some-scenary"><a class="markdownIt-Anchor" href="#captured-sample-images-for-some-scenary"></a> Captured Sample Images For Some Scenary</h2>
<table>
<thead>
<tr>
<th style="text-align:center">Side View</th>
<th style="text-align:center">Half Side View</th>
<th style="text-align:center">Top View</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/GeoScience/SurveyingMapping/CapturedImages/01_sideview.png" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/GeoScience/SurveyingMapping/CapturedImages/01_sideview.png" alt="Side View"></a></td>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/GeoScience/SurveyingMapping/CapturedImages/02_halfsideview.png" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/GeoScience/SurveyingMapping/CapturedImages/02_halfsideview.png" alt="Half Side View"></a></td>
<td style="text-align:center"><a href="https://raw.githubusercontent.com/LongerVision/Resource/master/GeoScience/SurveyingMapping/CapturedImages/03_topview.png" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/GeoScience/SurveyingMapping/CapturedImages/03_topview.png" alt="Top View"></a></td>
</tr>
</tbody>
</table>
<h1 id="indoor-work"><a class="markdownIt-Anchor" href="#indoor-work"></a> Indoor Work</h1>
<p><strong>Indoor surveying &amp; mapping</strong> is done by a cluster of servers, namely, on a small cloud. Currently, we are still dockerizing our own SDK.<br>
Three videos are used to briefly explain the <strong>MOST</strong> important three steps of <strong>indoor surveying &amp; mapping</strong>, as shown:</p>
<table>
<thead>
<tr>
<th style="text-align:center">Point Cloud</th>
<th style="text-align:center">Meshlized</th>
<th style="text-align:center">Texturized</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><a href="https://www.facebook.com/jiapei100/videos/1204640356360031" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/GeoScience/SurveyingMapping/Processing/01_pointcloud.png" alt="Point Cloud"></a></td>
<td style="text-align:center"><a href="https://www.facebook.com/jiapei100/videos/1204640393026694" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/GeoScience/SurveyingMapping/Processing/02_meshlized.png" alt="Meshlized"></a></td>
<td style="text-align:center"><a href="https://www.facebook.com/jiapei100/videos/1204640419693358" target="_blank" rel="noopener"><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/GeoScience/SurveyingMapping/Processing/03_texturized.png" alt="Texturized"></a></td>
</tr>
</tbody>
</table>
<h1 id="px4-autopilot-software"><a class="markdownIt-Anchor" href="#px4-autopilot-software"></a> <a href="https://px4.io/" target="_blank" rel="noopener">PX4 Autopilot Software</a></h1>
<p>Popular open source drone firmwares and websites that I’ve been testing are briefly listed in the following:</p>
<ul>
<li><a href="https://px4.io/" target="_blank" rel="noopener">PX4</a></li>
<li><a href="http://pixhawk.org/" target="_blank" rel="noopener">Pixhawk</a></li>
<li><a href="https://www.dronecode.org/" target="_blank" rel="noopener">Dronecode</a></li>
<li><a href="http://ardupilot.org/" target="_blank" rel="noopener">ArduPilot</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2019/01/25/DeepLearning/TorchSeg-HUST/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/25/DeepLearning/TorchSeg-HUST/" itemprop="url">
                  TorchSeg - HUST's Semantic Segmentation algorithms in PyTorch
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-25 00:00:00" itemprop="dateCreated datePublished" datetime="2019-01-25T00:00:00-08:00">2019-01-25</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-01-26 04:07:45" itemprop="dateModified" datetime="2019-01-26T04:07:45-08:00">2019-01-26</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Happily got the info that my <strong>master’s supervisor’s lab, namely: <a href="http://auto.hust.edu.cn/info/1108/3394.htm" target="_blank" rel="noopener">The State-Level key Laboratory of Multispectral Signal Processing</a></strong> in <strong><a href="http://english.hust.edu.cn/" target="_blank" rel="noopener">Huazhong University of Science and Technology</a></strong> released <a href="https://github.com/ycszen/TorchSeg" target="_blank" rel="noopener">TorchSeg</a> just yesterday. I can’t helping testing it out.</p>
<h1 id="preparation"><a class="markdownIt-Anchor" href="#preparation"></a> Preparation</h1>
<h2 id="python-packages"><a class="markdownIt-Anchor" href="#python-packages"></a> Python Packages</h2>
<p>According to the <a href="https://github.com/ycszen/TorchSeg/blob/master/README.md" target="_blank" rel="noopener">README.md</a> on <a href="https://github.com/ycszen/TorchSeg" target="_blank" rel="noopener">TorchSeg</a>, serveral packages need to be prepared <strong>FIRST</strong>:</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ pip show torch</span><br><span class="line">Name: torch</span><br><span class="line">Version: 1.1.0a0+b6a8c45</span><br><span class="line">Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration</span><br><span class="line">Home-page: UNKNOWN</span><br><span class="line">Author: UNKNOWN</span><br><span class="line">Author-email: UNKNOWN</span><br><span class="line">License: UNKNOWN</span><br><span class="line">Location: /home/jiapei/.local/lib/python3.6/site-packages</span><br><span class="line">Requires: </span><br><span class="line">Required-by: torchvision, torchtext, torchgan, pytorch-pretrained-bert, pyro-ppl, flair, autokeras</span><br><span class="line">➜  ~ pip show torchvision</span><br><span class="line">Name: torchvision</span><br><span class="line">Version: 0.2.1</span><br><span class="line">Summary: image and video datasets and models for torch deep learning</span><br><span class="line">Home-page: https://github.com/pytorch/vision</span><br><span class="line">Author: PyTorch Core Team</span><br><span class="line">Author-email: soumith@pytorch.org</span><br><span class="line">License: BSD</span><br><span class="line">Location: /home/jiapei/.local/lib/python3.6/site-packages</span><br><span class="line">Requires: numpy, torch, pillow, six</span><br><span class="line">Required-by: torchgan, torchfusion, autokeras</span><br><span class="line">➜  ~ pip show easydict</span><br><span class="line">Name: easydict</span><br><span class="line">Version: 1.9</span><br><span class="line">Summary: Access dict values as attributes (works recursively).</span><br><span class="line">Home-page: https://github.com/makinacorpus/easydict</span><br><span class="line">Author: Mathieu Leplatre</span><br><span class="line">Author-email: mathieu.leplatre@makina-corpus.com</span><br><span class="line">License: LPGL, see LICENSE file.</span><br><span class="line">Location: /home/jiapei/.local/lib/python3.6/site-packages</span><br><span class="line">Requires: </span><br><span class="line">Required-by: luminoth</span><br><span class="line">➜  ~ pip show apex</span><br><span class="line">Name: apex</span><br><span class="line">Version: 0.1</span><br><span class="line">Summary: PyTorch Extensions written by NVIDIA</span><br><span class="line">Home-page: UNKNOWN</span><br><span class="line">Author: UNKNOWN</span><br><span class="line">Author-email: UNKNOWN</span><br><span class="line">License: UNKNOWN</span><br><span class="line">Location: /home/jiapei/.local/lib/python3.6/site-packages/apex-0.1-py3.6.egg</span><br><span class="line">Requires: </span><br><span class="line">Required-by: </span><br><span class="line">➜  ~ pip show tqdm</span><br><span class="line">Name: tqdm</span><br><span class="line">Version: 4.29.1</span><br><span class="line">Summary: Fast, Extensible Progress Meter</span><br><span class="line">Home-page: https://github.com/tqdm/tqdm</span><br><span class="line">Author: Noam Yorav-Raphael</span><br><span class="line">Author-email: noamraph@gmail.com</span><br><span class="line">License: MPLv2.0, MIT Licences</span><br><span class="line">Location: /home/jiapei/.local/lib/python3.6/site-packages</span><br><span class="line">Requires: </span><br><span class="line">Required-by: TPOT, torchtext, torchfusion, thinc, tensorpack, skorch, shap, pytorch-pretrained-bert, pyro-ppl, optimuspyspark, kaggle, flair, autokeras, tf-pose</span><br></pre></td></tr></table></figure>
<h2 id="pytorch-models"><a class="markdownIt-Anchor" href="#pytorch-models"></a> PyTorch Models</h2>
<p>Download all PyTorch models provided from within all <strong>.py</strong> files from <a href="https://github.com/pytorch/vision/tree/master/torchvision/models" target="_blank" rel="noopener">PyTorch Vision Models</a>. Let’s briefly summarize the models as follows:</p>
<ul>
<li><strong>alexnet</strong>: <a href="https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth</a></li>
<li><strong>densenet121</strong>: <a href="https://download.pytorch.org/models/densenet121-a639ec97.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/densenet121-a639ec97.pth</a></li>
<li><strong>densenet169</strong>: <a href="https://download.pytorch.org/models/densenet169-b2777c0a.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/densenet169-b2777c0a.pth</a></li>
<li><strong>densenet201</strong>: <a href="https://download.pytorch.org/models/densenet201-c1103571.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/densenet201-c1103571.pth</a></li>
<li><strong>densenet161</strong>: <a href="https://download.pytorch.org/models/densenet161-8d451a50.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/densenet161-8d451a50.pth</a></li>
<li><strong>inception_v3_google</strong>: <a href="https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth</a></li>
<li><strong>resnet18</strong>: <a href="https://download.pytorch.org/models/resnet18-5c106cde.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/resnet18-5c106cde.pth</a></li>
<li><strong>resnet34</strong>: <a href="https://download.pytorch.org/models/resnet34-333f7ec4.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/resnet34-333f7ec4.pth</a></li>
<li><strong>resnet50</strong>: <a href="https://download.pytorch.org/models/resnet50-19c8e357.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/resnet50-19c8e357.pth</a></li>
<li><strong>resnet101</strong>: <a href="https://download.pytorch.org/models/resnet101-5d3b4d8f.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/resnet101-5d3b4d8f.pth</a></li>
<li><strong>resnet152</strong>: <a href="https://download.pytorch.org/models/resnet152-b121ed2d.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/resnet152-b121ed2d.pth</a></li>
<li><strong>squeezenet1_0</strong>: <a href="https://download.pytorch.org/models/squeezenet1_0-a815701f.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/squeezenet1_0-a815701f.pth</a></li>
<li><strong>squeezenet1_1</strong>: <a href="https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth</a></li>
<li><strong>vgg11</strong>: <a href="https://download.pytorch.org/models/vgg11-bbd30ac9.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/vgg11-bbd30ac9.pth</a></li>
<li><strong>vgg13</strong>: <a href="https://download.pytorch.org/models/vgg13-c768596a.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/vgg13-c768596a.pth</a></li>
<li><strong>vgg16</strong>: <a href="https://download.pytorch.org/models/vgg16-397923af.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/vgg16-397923af.pth</a></li>
<li><strong>vgg19</strong>: <a href="https://download.pytorch.org/models/vgg19-dcbb9e9d.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/vgg19-dcbb9e9d.pth</a></li>
<li><strong>vgg11_bn</strong>: <a href="https://download.pytorch.org/models/vgg11_bn-6002323d.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/vgg11_bn-6002323d.pth</a></li>
<li><strong>vgg13_bn</strong>: <a href="https://download.pytorch.org/models/vgg13_bn-abd245e5.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/vgg13_bn-abd245e5.pth</a></li>
<li><strong>vgg16_bn</strong>: <a href="https://download.pytorch.org/models/vgg16_bn-6c64b313.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/vgg16_bn-6c64b313.pth</a></li>
<li><strong>vgg19_bn</strong>: <a href="https://download.pytorch.org/models/vgg19_bn-c79401a0.pth" target="_blank" rel="noopener">https://download.pytorch.org/models/vgg19_bn-c79401a0.pth</a></li>
</ul>
<h1 id="test"><a class="markdownIt-Anchor" href="#test"></a> Test</h1>
<h2 id="torchseg-configpy-modification"><a class="markdownIt-Anchor" href="#torchseg-configpy-modification"></a> TorchSeg <a href="http://config.py" target="_blank" rel="noopener">config.py</a> modification</h2>
<p>After <a href="https://github.com/ycszen/TorchSeg" target="_blank" rel="noopener">TorchSeg</a> is checked out, we need to modify all the <strong><a href="http://config.py" target="_blank" rel="noopener">config.py</a></strong> files and ensure all variables <strong>C.pretrained_model</strong> are specified to the <strong>RIGHT</strong> location and with the <strong>RIGHT</strong> names. In my case, I just downloaded all <strong>PyTorch models</strong> under the same directory as <a href="https://github.com/ycszen/TorchSeg" target="_blank" rel="noopener">TorchSeg</a>, therefore, all <strong>C.pretrained_model</strong> are designated as:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">C.pretrained_model = <span class="string">"./resnet18-5c106cde.pth"</span></span><br><span class="line">C.pretrained_model = <span class="string">"./resnet50-19c8e357.pth"</span></span><br><span class="line">C.pretrained_model = <span class="string">"./resnet101-5d3b4d8f.pth"</span></span><br></pre></td></tr></table></figure>
<p>etc.</p>
<p>We <strong>also</strong> need to modify all variables <strong>C.dataset_path</strong> and make sure we are using the <strong>RIGHT</strong> dataset. In fact, <strong>ONLY</strong> two datasets are directly adopted in the originally checked-out code of <a href="https://github.com/ycszen/TorchSeg" target="_blank" rel="noopener">TorchSeg</a>.</p>
<ul>
<li><a href="https://www.cityscapes-dataset.com/" target="_blank" rel="noopener">Cityscapes</a></li>
<li><a href="http://groups.csail.mit.edu/vision/datasets/ADE20K/" target="_blank" rel="noopener">ADE20K</a></li>
</ul>
<p>Currently, it seems there is still some tricks about how to configure these <strong>datasets</strong>, please refer to <a href="https://github.com/ycszen/TorchSeg/issues/4" target="_blank" rel="noopener">my Github issue</a>.</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2019/01/24/Kaggle/Airbus-Ship-Detection-Challenge-Mask-RCNN-and-COCO-Transfer-Learning/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/24/Kaggle/Airbus-Ship-Detection-Challenge-Mask-RCNN-and-COCO-Transfer-Learning/" itemprop="url">
                  Kaggle Competition - Airbus Ship Detection Challenge - Mask-RCNN and COCO Transfer Learning
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-24 00:00:00 / Modified: 04:33:57" itemprop="dateCreated datePublished" datetime="2019-01-24T00:00:00-08:00">2019-01-24</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Kaggle/" itemprop="url" rel="index"><span itemprop="name">Kaggle</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Yup, as mentioned, I’m going to test out one more Kaggle competition <a href="https://www.kaggle.com/c/airbus-ship-detection" target="_blank" rel="noopener">Airbus Ship Detection Challenge</a>.<br>
I believe you’ve already got accustomed to the data preparation.</p>
<h1 id="preparation"><a class="markdownIt-Anchor" href="#preparation"></a> Preparation</h1>
<h2 id="required-python-packages"><a class="markdownIt-Anchor" href="#required-python-packages"></a> Required Python Packages</h2>
<p>We <strong>FIRST</strong> make sure <a href="https://matterport.com/" target="_blank" rel="noopener">Matterport</a>’s package - <a href="https://github.com/matterport/Mask_RCNN" target="_blank" rel="noopener">Mask_RCNN</a> been successfully installed.</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ pip show Mask_RCNN</span><br><span class="line">Name: mask-rcnn</span><br><span class="line">Version: 2.1</span><br><span class="line">Summary: Mask R-CNN for object detection and instance segmentation</span><br><span class="line">Home-page: https://github.com/matterport/Mask_RCNN</span><br><span class="line">Author: Matterport</span><br><span class="line">Author-email: waleed.abdulla@gmail.com</span><br><span class="line">License: MIT</span><br><span class="line">Location: /home/jiapei/.local/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg</span><br><span class="line">Requires: </span><br><span class="line">Required-by:</span><br></pre></td></tr></table></figure>
<p>We also need to have <a href="https://opencv.org/" target="_blank" rel="noopener">OpenCV</a>’s Python package - <strong>cv2</strong> been successfully installed.</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ pip show cv2</span><br><span class="line">➜  ~ python</span><br><span class="line">Python 3.6.7 (default, Oct 22 2018, 11:32:17) </span><br><span class="line">[GCC 8.2.0] on linux</span><br><span class="line">Type "help", "copyright", "credits" or "license" for more information.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import cv2</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; cv2.__version__</span></span><br><span class="line">'4.0.0'</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; cv2.__file__</span></span><br><span class="line">'/home/jiapei/.local/lib/python3.6/site-packages/opencv_python-4.0.0.21-py3.6-linux-x86_64.egg/cv2/cv2.cpython-36m-x86_64-linux-gnu.so'</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="models"><a class="markdownIt-Anchor" href="#models"></a> Models</h2>
<p>Then, we manually download the trained data directly from <a href="https://github.com/matterport/Mask_RCNN/releases" target="_blank" rel="noopener">Matterport Github Mask_RCNN Release website</a>.</p>
<ul>
<li><a href="https://github.com/matterport/Mask_RCNN/releases/download/v2.1/mask_rcnn_balloon.h5" target="_blank" rel="noopener">mask_rcnn_balloon.h5</a></li>
<li><a href="https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5" target="_blank" rel="noopener">mask_rcnn_coco.h5</a></li>
</ul>
<h1 id="test"><a class="markdownIt-Anchor" href="#test"></a> Test</h1>
<h2 id="the-code"><a class="markdownIt-Anchor" href="#the-code"></a> The Code</h2>
<p>After the above preparation, we did some trivial modifications on <a href="https://www.kaggle.com/hmendonca/airbus-mask-rcnn-and-coco-transfer-learning" target="_blank" rel="noopener">Airbus Mask-RCNN and COCO Transfer Learning</a>, as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># **Mask-RCNN Starter Model for the Airbus Ship Detection Challenge with transfer learning **</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Using pre-trained COCO weights trained on http://cocodataset.org as in https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># We get some amazing performance training only within the 6hrs kaggle kernel limit.</span></span><br><span class="line"></span><br><span class="line">debug = <span class="keyword">False</span></span><br><span class="line"><span class="comment"># debug = True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> imgaug <span class="keyword">import</span> augmenters <span class="keyword">as</span> iaa</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> glob </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">DATA_DIR = <span class="string">'....../airbus-ship-detection'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Directory to save logs and trained model</span></span><br><span class="line">ROOT_DIR = <span class="string">'./'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### Install Matterport's Mask-RCNN model from github.</span></span><br><span class="line"><span class="comment"># See the [Matterport's implementation of Mask-RCNN](https://github.com/matterport/Mask_RCNN).</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Import Mask RCNN</span></span><br><span class="line">sys.path.append(os.path.join(ROOT_DIR, <span class="string">'Mask_RCNN'</span>))  <span class="comment"># To find local version of the library</span></span><br><span class="line"><span class="keyword">from</span> mrcnn.config <span class="keyword">import</span> Config</span><br><span class="line"><span class="keyword">from</span> mrcnn <span class="keyword">import</span> utils</span><br><span class="line"><span class="keyword">import</span> mrcnn.model <span class="keyword">as</span> modellib</span><br><span class="line"><span class="keyword">from</span> mrcnn <span class="keyword">import</span> visualize</span><br><span class="line"><span class="keyword">from</span> mrcnn.model <span class="keyword">import</span> log</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_dicom_dir = os.path.join(DATA_DIR, <span class="string">'train_v2'</span>)</span><br><span class="line">test_dicom_dir = os.path.join(DATA_DIR, <span class="string">'test_v2'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### Download COCO pre-trained weights</span></span><br><span class="line"></span><br><span class="line">COCO_WEIGHTS_PATH = <span class="string">"mask_rcnn_coco.h5"</span></span><br><span class="line">BALLOON_WEIGHTS_PATH = <span class="string">"mask_rcnn_balloon.h5"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### Some setup functions and classes for Mask-RCNN</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># - dicom_fps is a list of the dicom image path and filenames </span></span><br><span class="line"><span class="comment"># - image_annotions is a dictionary of the annotations keyed by the filenames</span></span><br><span class="line"><span class="comment"># - parsing the dataset returns a list of the image filenames and the annotations dictionary</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The following parameters have been selected to reduce running time for demonstration purposes </span></span><br><span class="line"><span class="comment"># These are not optimal </span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DetectorConfig</span><span class="params">(Config)</span>:</span>    </span><br><span class="line">    <span class="comment"># Give the configuration a recognizable name  </span></span><br><span class="line">    NAME = <span class="string">'airbus'</span></span><br><span class="line">    </span><br><span class="line">    GPU_COUNT = <span class="number">1</span></span><br><span class="line">    IMAGES_PER_GPU = <span class="number">10</span></span><br><span class="line">    </span><br><span class="line">    BACKBONE = <span class="string">'resnet50'</span></span><br><span class="line">    </span><br><span class="line">    NUM_CLASSES = <span class="number">2</span>  <span class="comment"># background and ship classes</span></span><br><span class="line">    </span><br><span class="line">    IMAGE_MIN_DIM = <span class="number">384</span></span><br><span class="line">    IMAGE_MAX_DIM = <span class="number">384</span></span><br><span class="line">    RPN_ANCHOR_SCALES = (<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>)</span><br><span class="line">    TRAIN_ROIS_PER_IMAGE = <span class="number">126</span></span><br><span class="line">    MAX_GT_INSTANCES = <span class="number">14</span></span><br><span class="line">    DETECTION_MAX_INSTANCES = <span class="number">14</span></span><br><span class="line">    DETECTION_MIN_CONFIDENCE = <span class="number">0.95</span></span><br><span class="line">    DETECTION_NMS_THRESHOLD = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    STEPS_PER_EPOCH = <span class="number">12</span> <span class="keyword">if</span> debug <span class="keyword">else</span> <span class="number">120</span></span><br><span class="line">    VALIDATION_STEPS = <span class="number">10</span> <span class="keyword">if</span> debug <span class="keyword">else</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line">config = DetectorConfig()</span><br><span class="line">config.display()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing, CSV file I/O (e.g. pd.read_csv)</span></span><br><span class="line"><span class="keyword">from</span> skimage.io <span class="keyword">import</span> imread</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.cm <span class="keyword">import</span> get_cmap</span><br><span class="line"><span class="keyword">from</span> skimage.segmentation <span class="keyword">import</span> mark_boundaries</span><br><span class="line"><span class="keyword">from</span> skimage.util <span class="keyword">import</span> montage</span><br><span class="line"><span class="keyword">from</span> skimage.morphology <span class="keyword">import</span> binary_opening, disk, label</span><br><span class="line"><span class="keyword">import</span> gc; gc.enable() <span class="comment"># memory is tight</span></span><br><span class="line"></span><br><span class="line">montage_rgb = <span class="keyword">lambda</span> x: np.stack([montage(x[:, :, :, i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(x.shape[<span class="number">3</span>])], <span class="number">-1</span>)</span><br><span class="line">ship_dir = <span class="string">'../input'</span></span><br><span class="line">train_image_dir = os.path.join(ship_dir, <span class="string">'train'</span>)</span><br><span class="line">test_image_dir = os.path.join(ship_dir, <span class="string">'test'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_rle_encode</span><span class="params">(img, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Encode connected regions as separated masks</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    labels = label(img)</span><br><span class="line">    <span class="keyword">if</span> img.ndim &gt; <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> [rle_encode(np.sum(labels==k, axis=<span class="number">2</span>), **kwargs) <span class="keyword">for</span> k <span class="keyword">in</span> np.unique(labels[labels&gt;<span class="number">0</span>])]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> [rle_encode(labels==k, **kwargs) <span class="keyword">for</span> k <span class="keyword">in</span> np.unique(labels[labels&gt;<span class="number">0</span>])]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rle_encode</span><span class="params">(img, min_max_threshold=<span class="number">1e-3</span>, max_mean_threshold=None)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    img: numpy array, 1 - mask, 0 - background</span></span><br><span class="line"><span class="string">    Returns run length as string formated</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">if</span> np.max(img) &lt; min_max_threshold:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span> <span class="comment">## no need to encode if it's all zeros</span></span><br><span class="line">    <span class="keyword">if</span> max_mean_threshold <span class="keyword">and</span> np.mean(img) &gt; max_mean_threshold:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span> <span class="comment">## ignore overfilled mask</span></span><br><span class="line">    pixels = img.T.flatten()</span><br><span class="line">    pixels = np.concatenate([[<span class="number">0</span>], pixels, [<span class="number">0</span>]])</span><br><span class="line">    runs = np.where(pixels[<span class="number">1</span>:] != pixels[:<span class="number">-1</span>])[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line">    runs[<span class="number">1</span>::<span class="number">2</span>] -= runs[::<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">' '</span>.join(str(x) <span class="keyword">for</span> x <span class="keyword">in</span> runs)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rle_decode</span><span class="params">(mask_rle, shape=<span class="params">(<span class="number">768</span>, <span class="number">768</span>)</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    mask_rle: run-length as string formated (start length)</span></span><br><span class="line"><span class="string">    shape: (height,width) of array to return </span></span><br><span class="line"><span class="string">    Returns numpy array, 1 - mask, 0 - background</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    s = mask_rle.split()</span><br><span class="line">    starts, lengths = [np.asarray(x, dtype=int) <span class="keyword">for</span> x <span class="keyword">in</span> (s[<span class="number">0</span>:][::<span class="number">2</span>], s[<span class="number">1</span>:][::<span class="number">2</span>])]</span><br><span class="line">    starts -= <span class="number">1</span></span><br><span class="line">    ends = starts + lengths</span><br><span class="line">    img = np.zeros(shape[<span class="number">0</span>]*shape[<span class="number">1</span>], dtype=np.uint8)</span><br><span class="line">    <span class="keyword">for</span> lo, hi <span class="keyword">in</span> zip(starts, ends):</span><br><span class="line">        img[lo:hi] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> img.reshape(shape).T  <span class="comment"># Needed to align to RLE direction</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">masks_as_image</span><span class="params">(in_mask_list)</span>:</span></span><br><span class="line">    <span class="comment"># Take the individual ship masks and create a single mask array for all ships</span></span><br><span class="line">    all_masks = np.zeros((<span class="number">768</span>, <span class="number">768</span>), dtype = np.uint8)</span><br><span class="line">    <span class="keyword">for</span> mask <span class="keyword">in</span> in_mask_list:</span><br><span class="line">        <span class="keyword">if</span> isinstance(mask, str):</span><br><span class="line">            all_masks |= rle_decode(mask)</span><br><span class="line">    <span class="keyword">return</span> all_masks</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">masks_as_color</span><span class="params">(in_mask_list)</span>:</span></span><br><span class="line">    <span class="comment"># Take the individual ship masks and create a color mask array for each ships</span></span><br><span class="line">    all_masks = np.zeros((<span class="number">768</span>, <span class="number">768</span>), dtype = np.float)</span><br><span class="line">    scale = <span class="keyword">lambda</span> x: (len(in_mask_list)+x+<span class="number">1</span>) / (len(in_mask_list)*<span class="number">2</span>) <span class="comment">## scale the heatmap image to shift </span></span><br><span class="line">    <span class="keyword">for</span> i,mask <span class="keyword">in</span> enumerate(in_mask_list):</span><br><span class="line">        <span class="keyword">if</span> isinstance(mask, str):</span><br><span class="line">            all_masks[:,:] += scale(i) * rle_decode(mask)</span><br><span class="line">    <span class="keyword">return</span> all_masks</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">exclude_list = [<span class="string">'6384c3e78.jpg'</span>,<span class="string">'13703f040.jpg'</span>, <span class="string">'14715c06d.jpg'</span>,  <span class="string">'33e0ff2d5.jpg'</span>,</span><br><span class="line">                <span class="string">'4d4e09f2a.jpg'</span>, <span class="string">'877691df8.jpg'</span>, <span class="string">'8b909bb20.jpg'</span>, <span class="string">'a8d99130e.jpg'</span>, </span><br><span class="line">                <span class="string">'ad55c3143.jpg'</span>, <span class="string">'c8260c541.jpg'</span>, <span class="string">'d6c7f17c7.jpg'</span>, <span class="string">'dc3e7c901.jpg'</span>,</span><br><span class="line">                <span class="string">'e44dffe88.jpg'</span>, <span class="string">'ef87bad36.jpg'</span>, <span class="string">'f083256d8.jpg'</span>] <span class="comment">#corrupted images</span></span><br><span class="line"></span><br><span class="line">train_names = [f <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(train_dicom_dir)]</span><br><span class="line">test_names = [f <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(test_dicom_dir)]</span><br><span class="line"><span class="keyword">for</span> el <span class="keyword">in</span> exclude_list:</span><br><span class="line">    <span class="keyword">if</span>(el <span class="keyword">in</span> train_names): train_names.remove(el)</span><br><span class="line">    <span class="keyword">if</span>(el <span class="keyword">in</span> test_names): test_names.remove(el)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># training dataset</span></span><br><span class="line">SEGMENTATION = <span class="string">'....../airbus-ship-detection/train_ship_segmentations_v2.csv'</span></span><br><span class="line">anns = pd.read_csv(SEGMENTATION)</span><br><span class="line">anns.head()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_names = anns[anns.EncodedPixels.notnull()].ImageId.unique().tolist()  <span class="comment">## override with ships</span></span><br><span class="line"></span><br><span class="line">test_size = config.VALIDATION_STEPS * config.IMAGES_PER_GPU</span><br><span class="line">image_fps_train, image_fps_val = train_test_split(train_names, test_size=test_size, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> debug:</span><br><span class="line">    image_fps_train = image_fps_train[:<span class="number">100</span>]</span><br><span class="line">    image_fps_val = image_fps_val[:<span class="number">100</span>]</span><br><span class="line">    test_names = test_names[:<span class="number">100</span>]</span><br><span class="line">    </span><br><span class="line">print(len(image_fps_train), len(image_fps_val), len(test_names))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DetectorDataset</span><span class="params">(utils.Dataset)</span>:</span></span><br><span class="line">    <span class="string">"""Dataset class for training our dataset.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, image_fps, image_annotations, orig_height, orig_width)</span>:</span></span><br><span class="line">        super().__init__(self)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Add classes</span></span><br><span class="line">        self.add_class(<span class="string">'ship'</span>, <span class="number">1</span>, <span class="string">'Ship'</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># add images </span></span><br><span class="line">        <span class="keyword">for</span> i, fp <span class="keyword">in</span> enumerate(image_fps):</span><br><span class="line">            annotations = image_annotations.query(<span class="string">'ImageId=="'</span> + fp + <span class="string">'"'</span>)[<span class="string">'EncodedPixels'</span>]</span><br><span class="line">            self.add_image(<span class="string">'ship'</span>, image_id=i, path=os.path.join(train_dicom_dir, fp), </span><br><span class="line">                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">image_reference</span><span class="params">(self, image_id)</span>:</span></span><br><span class="line">        info = self.image_info[image_id]</span><br><span class="line">        <span class="keyword">return</span> info[<span class="string">'path'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_image</span><span class="params">(self, image_id)</span>:</span></span><br><span class="line">        info = self.image_info[image_id]</span><br><span class="line">        fp = info[<span class="string">'path'</span>]</span><br><span class="line">        image = imread(fp)</span><br><span class="line">        <span class="comment"># If grayscale. Convert to RGB for consistency.</span></span><br><span class="line">        <span class="keyword">if</span> len(image.shape) != <span class="number">3</span> <span class="keyword">or</span> image.shape[<span class="number">2</span>] != <span class="number">3</span>:</span><br><span class="line">            image = np.stack((image,) * <span class="number">3</span>, <span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_mask</span><span class="params">(self, image_id)</span>:</span></span><br><span class="line">        info = self.image_info[image_id]</span><br><span class="line">        annotations = info[<span class="string">'annotations'</span>]</span><br><span class="line"><span class="comment">#         print(image_id, annotations)</span></span><br><span class="line">        count = len(annotations)</span><br><span class="line">        <span class="keyword">if</span> count == <span class="number">0</span>:</span><br><span class="line">            mask = np.zeros((info[<span class="string">'orig_height'</span>], info[<span class="string">'orig_width'</span>], <span class="number">1</span>), dtype=np.uint8)</span><br><span class="line">            class_ids = np.zeros((<span class="number">1</span>,), dtype=np.int32)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mask = np.zeros((info[<span class="string">'orig_height'</span>], info[<span class="string">'orig_width'</span>], count), dtype=np.uint8)</span><br><span class="line">            class_ids = np.zeros((count,), dtype=np.int32)</span><br><span class="line">            <span class="keyword">for</span> i, a <span class="keyword">in</span> enumerate(annotations):</span><br><span class="line">                mask[:, :, i] = rle_decode(a)</span><br><span class="line">                class_ids[i] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> mask.astype(np.bool), class_ids.astype(np.int32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### Examine the annotation data, parse the dataset, and view dicom fields</span></span><br><span class="line"></span><br><span class="line">image_fps, image_annotations = train_names, anns</span><br><span class="line"></span><br><span class="line">ds = imread(os.path.join(train_dicom_dir, image_fps[<span class="number">0</span>])) <span class="comment"># read  image from filepath </span></span><br><span class="line">_ = plt.imshow(ds)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Original image size: 768 x 768</span></span><br><span class="line">ORIG_SIZE = ds.shape[<span class="number">0</span>]</span><br><span class="line">ORIG_SIZE</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### Create and prepare the training dataset using the DetectorDataset class.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare the training dataset</span></span><br><span class="line">dataset_train = DetectorDataset(image_fps_train, image_annotations, ORIG_SIZE, ORIG_SIZE)</span><br><span class="line">dataset_train.prepare()</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare the validation dataset</span></span><br><span class="line">dataset_val = DetectorDataset(image_fps_val, image_annotations, ORIG_SIZE, ORIG_SIZE)</span><br><span class="line">dataset_val.prepare()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ### Display a random image with bounding boxes</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load and display random sample and their bounding boxes</span></span><br><span class="line"></span><br><span class="line">class_ids = [<span class="number">0</span>]</span><br><span class="line"><span class="keyword">while</span> class_ids[<span class="number">0</span>] == <span class="number">0</span>:  <span class="comment">## look for a mask</span></span><br><span class="line">    image_id = random.choice(dataset_val.image_ids)</span><br><span class="line">    image_fp = dataset_val.image_reference(image_id)</span><br><span class="line">    image = dataset_val.load_image(image_id)</span><br><span class="line">    mask, class_ids = dataset_val.load_mask(image_id)</span><br><span class="line"></span><br><span class="line">print(image.shape)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.imshow(image)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">masked = np.zeros(image.shape[:<span class="number">2</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(mask.shape[<span class="number">2</span>]):</span><br><span class="line">    masked += mask[:, :, i] <span class="comment">## * image[:, :, 0]</span></span><br><span class="line">plt.imshow(masked, cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line"></span><br><span class="line">print(image_fp)</span><br><span class="line">print(class_ids)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### Image Augmentation. Try finetuning some variables to custom values</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Image augmentation (light but constant)</span></span><br><span class="line">augmentation = iaa.Sequential([</span><br><span class="line">    iaa.OneOf([ <span class="comment">## rotate</span></span><br><span class="line">        iaa.Affine(rotate=<span class="number">0</span>),</span><br><span class="line">        iaa.Affine(rotate=<span class="number">90</span>),</span><br><span class="line">        iaa.Affine(rotate=<span class="number">180</span>),</span><br><span class="line">        iaa.Affine(rotate=<span class="number">270</span>),</span><br><span class="line">    ]),</span><br><span class="line">    iaa.Fliplr(<span class="number">0.5</span>),</span><br><span class="line">    iaa.Flipud(<span class="number">0.5</span>),</span><br><span class="line">    iaa.OneOf([ <span class="comment">## brightness or contrast</span></span><br><span class="line">        iaa.Multiply((<span class="number">0.9</span>, <span class="number">1.1</span>)),</span><br><span class="line">        iaa.ContrastNormalization((<span class="number">0.9</span>, <span class="number">1.1</span>)),</span><br><span class="line">    ]),</span><br><span class="line">    iaa.OneOf([ <span class="comment">## blur or sharpen</span></span><br><span class="line">        iaa.GaussianBlur(sigma=(<span class="number">0.0</span>, <span class="number">0.1</span>)),</span><br><span class="line">        iaa.Sharpen(alpha=(<span class="number">0.0</span>, <span class="number">0.1</span>)),</span><br><span class="line">    ]),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># test on the same image as above</span></span><br><span class="line">imggrid = augmentation.draw_grid(image, cols=<span class="number">5</span>, rows=<span class="number">2</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">12</span>))</span><br><span class="line">_ = plt.imshow(imggrid.astype(int))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### Now it's time to train the model. Note that training even a basic model can take a few hours. </span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Note: the following model is for demonstration purpose only. We have limited the training to one epoch, and have set nominal values for the Detector Configuration to reduce run-time. </span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># - dataset_train and dataset_val are derived from DetectorDataset </span></span><br><span class="line"><span class="comment"># - DetectorDataset loads images from image filenames and  masks from the annotation data</span></span><br><span class="line"><span class="comment"># - model is Mask-RCNN</span></span><br><span class="line"></span><br><span class="line">model = modellib.MaskRCNN(mode=<span class="string">'training'</span>, config=config, model_dir=ROOT_DIR)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Exclude the last layers because they require a matching</span></span><br><span class="line"><span class="comment"># number of classes</span></span><br><span class="line">model.load_weights(COCO_WEIGHTS_PATH, by_name=<span class="keyword">True</span>, exclude=[</span><br><span class="line">    <span class="string">"mrcnn_class_logits"</span>, <span class="string">"mrcnn_bbox_fc"</span>,</span><br><span class="line">    <span class="string">"mrcnn_bbox"</span>, <span class="string">"mrcnn_mask"</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">LEARNING_RATE = <span class="number">0.004</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Train Mask-RCNN Model </span></span><br><span class="line"><span class="keyword">import</span> warnings </span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## train heads with higher lr to speedup the learning</span></span><br><span class="line">model.train(dataset_train, dataset_val,</span><br><span class="line">            learning_rate=LEARNING_RATE*<span class="number">2</span>,</span><br><span class="line">            epochs=<span class="number">2</span>,</span><br><span class="line">            layers=<span class="string">'heads'</span>,</span><br><span class="line">            augmentation=<span class="keyword">None</span>)  <span class="comment">## no need to augment yet</span></span><br><span class="line"></span><br><span class="line">history = model.keras_model.history.history</span><br><span class="line"></span><br><span class="line">model.train(dataset_train, dataset_val,</span><br><span class="line">            learning_rate=LEARNING_RATE,</span><br><span class="line">            epochs=<span class="number">4</span> <span class="keyword">if</span> debug <span class="keyword">else</span> <span class="number">12</span>,</span><br><span class="line">            layers=<span class="string">'all'</span>,</span><br><span class="line">            augmentation=augmentation)</span><br><span class="line"></span><br><span class="line">new_history = model.keras_model.history.history</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> new_history: history[k] = history[k] + new_history[k]</span><br><span class="line"></span><br><span class="line">epochs = range(<span class="number">1</span>, len(history[<span class="string">'loss'</span>])+<span class="number">1</span>)</span><br><span class="line">pd.DataFrame(history, index=epochs)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">17</span>,<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">131</span>)</span><br><span class="line">plt.plot(epochs, history[<span class="string">"loss"</span>], label=<span class="string">"Train loss"</span>)</span><br><span class="line">plt.plot(epochs, history[<span class="string">"val_loss"</span>], label=<span class="string">"Valid loss"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.subplot(<span class="number">132</span>)</span><br><span class="line">plt.plot(epochs, history[<span class="string">"mrcnn_class_loss"</span>], label=<span class="string">"Train class ce"</span>)</span><br><span class="line">plt.plot(epochs, history[<span class="string">"val_mrcnn_class_loss"</span>], label=<span class="string">"Valid class ce"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.subplot(<span class="number">133</span>)</span><br><span class="line">plt.plot(epochs, history[<span class="string">"mrcnn_bbox_loss"</span>], label=<span class="string">"Train box loss"</span>)</span><br><span class="line">plt.plot(epochs, history[<span class="string">"val_mrcnn_bbox_loss"</span>], label=<span class="string">"Valid box loss"</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">best_epoch = np.argmin(history[<span class="string">"val_loss"</span>])</span><br><span class="line">score = history[<span class="string">"val_loss"</span>][best_epoch]</span><br><span class="line">print(<span class="string">f'Best Epoch:<span class="subst">&#123;best_epoch+<span class="number">1</span>&#125;</span> val_loss:<span class="subst">&#123;score&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># select trained model </span></span><br><span class="line">dir_names = next(os.walk(model.model_dir))[<span class="number">1</span>]</span><br><span class="line">key = config.NAME.lower()</span><br><span class="line">dir_names = filter(<span class="keyword">lambda</span> f: f.startswith(key), dir_names)</span><br><span class="line">dir_names = sorted(dir_names)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> dir_names:</span><br><span class="line">    <span class="keyword">import</span> errno</span><br><span class="line">    <span class="keyword">raise</span> FileNotFoundError(</span><br><span class="line">        errno.ENOENT,</span><br><span class="line">        <span class="string">"Could not find model directory under &#123;&#125;"</span>.format(self.model_dir))</span><br><span class="line">    </span><br><span class="line">fps = []</span><br><span class="line"><span class="comment"># Pick last directory</span></span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> dir_names: </span><br><span class="line">    dir_name = os.path.join(model.model_dir, d)</span><br><span class="line">    <span class="comment"># Find the last checkpoint</span></span><br><span class="line">    checkpoints = next(os.walk(dir_name))[<span class="number">2</span>]</span><br><span class="line">    checkpoints = filter(<span class="keyword">lambda</span> f: f.startswith(<span class="string">"mask_rcnn"</span>), checkpoints)</span><br><span class="line">    checkpoints = sorted(checkpoints)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> checkpoints:</span><br><span class="line">        print(<span class="string">'No weight files in &#123;&#125;'</span>.format(dir_name))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        checkpoint = os.path.join(dir_name, checkpoints[best_epoch])</span><br><span class="line">        fps.append(checkpoint)</span><br><span class="line"></span><br><span class="line">model_path = sorted(fps)[<span class="number">-1</span>]</span><br><span class="line">print(<span class="string">'Found model &#123;&#125;'</span>.format(model_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InferenceConfig</span><span class="params">(DetectorConfig)</span>:</span></span><br><span class="line">    GPU_COUNT = <span class="number">1</span></span><br><span class="line">    IMAGES_PER_GPU = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">inference_config = InferenceConfig()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Recreate the model in inference mode</span></span><br><span class="line">model = modellib.MaskRCNN(mode=<span class="string">'inference'</span>, </span><br><span class="line">                          config=inference_config,</span><br><span class="line">                          model_dir=ROOT_DIR)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load trained weights (fill in path to trained weights here)</span></span><br><span class="line"><span class="keyword">assert</span> model_path != <span class="string">""</span>, <span class="string">"Provide path to trained weights"</span></span><br><span class="line">print(<span class="string">"Loading weights from "</span>, model_path)</span><br><span class="line">model.load_weights(model_path, by_name=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># set color for class</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_colors_for_class_ids</span><span class="params">(class_ids)</span>:</span></span><br><span class="line">    colors = []</span><br><span class="line">    <span class="keyword">for</span> class_id <span class="keyword">in</span> class_ids:</span><br><span class="line">        <span class="keyword">if</span> class_id == <span class="number">1</span>:</span><br><span class="line">            colors.append((<span class="number">.941</span>, <span class="number">.204</span>, <span class="number">.204</span>))</span><br><span class="line">    <span class="keyword">return</span> colors</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### How does the predicted box compared to the expected value? Let's use the validation dataset to check. </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Show few example of ground truth vs. predictions on the validation dataset </span></span><br><span class="line">dataset = dataset_val</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">40</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line"></span><br><span class="line">    image_id = random.choice(dataset.image_ids)</span><br><span class="line">    </span><br><span class="line">    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =        modellib.load_image_gt(dataset_val, inference_config, </span><br><span class="line">                               image_id, use_mini_mask=<span class="keyword">False</span>)</span><br><span class="line">    </span><br><span class="line">    print(original_image.shape)</span><br><span class="line">    plt.subplot(<span class="number">8</span>, <span class="number">2</span>, <span class="number">2</span>*i + <span class="number">1</span>)</span><br><span class="line">    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, </span><br><span class="line">                                dataset.class_names,</span><br><span class="line">                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[<span class="number">-1</span>])</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">8</span>, <span class="number">2</span>, <span class="number">2</span>*i + <span class="number">2</span>)</span><br><span class="line">    results = model.detect([original_image]) <span class="comment">#, verbose=1)</span></span><br><span class="line">    r = results[<span class="number">0</span>]</span><br><span class="line">    visualize.display_instances(original_image, r[<span class="string">'rois'</span>], r[<span class="string">'masks'</span>], r[<span class="string">'class_ids'</span>], </span><br><span class="line">                                dataset.class_names, r[<span class="string">'scores'</span>], </span><br><span class="line">                                colors=get_colors_for_class_ids(r[<span class="string">'class_ids'</span>]), ax=fig.axes[<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get filenames of test dataset images</span></span><br><span class="line">test_image_fps = test_names</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### Final steps - Create the submission file</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions on test images, write out sample submission</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(image_fps, filepath=<span class="string">'submission.csv'</span>, min_conf=config.DETECTION_MIN_CONFIDENCE)</span>:</span></span><br><span class="line">    <span class="comment"># assume square image</span></span><br><span class="line">    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">#resize_factor = ORIG_SIZE</span></span><br><span class="line">    <span class="keyword">with</span> open(filepath, <span class="string">'w'</span>) <span class="keyword">as</span> file:</span><br><span class="line">        file.write(<span class="string">"ImageId,EncodedPixels\n"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> image_id <span class="keyword">in</span> tqdm(image_fps):</span><br><span class="line">            found = <span class="keyword">False</span></span><br><span class="line">            </span><br><span class="line">            image = imread(os.path.join(test_dicom_dir, image_id))</span><br><span class="line">            <span class="comment"># If grayscale. Convert to RGB for consistency.</span></span><br><span class="line">            <span class="keyword">if</span> len(image.shape) != <span class="number">3</span> <span class="keyword">or</span> image.shape[<span class="number">2</span>] != <span class="number">3</span>:</span><br><span class="line">                image = np.stack((image,) * <span class="number">3</span>, <span class="number">-1</span>)</span><br><span class="line">            image, window, scale, padding, crop = utils.resize_image(</span><br><span class="line">                image,</span><br><span class="line">                min_dim=config.IMAGE_MIN_DIM,</span><br><span class="line">                min_scale=config.IMAGE_MIN_SCALE,</span><br><span class="line">                max_dim=config.IMAGE_MAX_DIM,</span><br><span class="line">                mode=config.IMAGE_RESIZE_MODE)</span><br><span class="line"></span><br><span class="line">            results = model.detect([image])</span><br><span class="line">            r = results[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">assert</span>( len(r[<span class="string">'rois'</span>]) == len(r[<span class="string">'class_ids'</span>]) == len(r[<span class="string">'scores'</span>]) )</span><br><span class="line">            <span class="keyword">if</span> len(r[<span class="string">'rois'</span>]) == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                num_instances = len(r[<span class="string">'rois'</span>])</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(num_instances):</span><br><span class="line">                    <span class="keyword">if</span> r[<span class="string">'scores'</span>][i] &gt; min_conf:</span><br><span class="line"><span class="comment">#                         print(r['scores'][i], r['rois'][i], r['masks'][i].shape, np.sum(r['masks'][...,i]), r['masks'][i], r.keys())</span></span><br><span class="line">                        file.write(image_id + <span class="string">","</span> + rle_encode(r[<span class="string">'masks'</span>][...,i]) + <span class="string">"\n"</span>)</span><br><span class="line">                        found = <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> found:</span><br><span class="line">                file.write(image_id + <span class="string">",\n"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">submission_fp = os.path.join(ROOT_DIR, <span class="string">'submission.csv'</span>)</span><br><span class="line">predict(test_image_fps, filepath=submission_fp)</span><br><span class="line">print(submission_fp)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">output = pd.read_csv(submission_fp)</span><br><span class="line">output.head(<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># show a few test image detection example</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize_test</span><span class="params">()</span>:</span> </span><br><span class="line">    image_id = random.choice(test_image_fps)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># original image</span></span><br><span class="line"><span class="comment">#     print(image_id)</span></span><br><span class="line">    image = imread(os.path.join(test_dicom_dir, image_id))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># assume square image </span></span><br><span class="line">    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># If grayscale. Convert to RGB for consistency.</span></span><br><span class="line">    <span class="keyword">if</span> len(image.shape) != <span class="number">3</span> <span class="keyword">or</span> image.shape[<span class="number">2</span>] != <span class="number">3</span>:</span><br><span class="line">        image = np.stack((image,) * <span class="number">3</span>, <span class="number">-1</span>) </span><br><span class="line">    resized_image, window, scale, padding, crop = utils.resize_image(</span><br><span class="line">        image,</span><br><span class="line">        min_dim=config.IMAGE_MIN_DIM,</span><br><span class="line">        min_scale=config.IMAGE_MIN_SCALE,</span><br><span class="line">        max_dim=config.IMAGE_MAX_DIM,</span><br><span class="line">        mode=config.IMAGE_RESIZE_MODE)</span><br><span class="line"></span><br><span class="line">    results = model.detect([resized_image])</span><br><span class="line">    r = results[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> bbox <span class="keyword">in</span> r[<span class="string">'rois'</span>]: </span><br><span class="line"><span class="comment">#         print(bbox)</span></span><br><span class="line">        x1 = int(bbox[<span class="number">1</span>] * resize_factor)</span><br><span class="line">        y1 = int(bbox[<span class="number">0</span>] * resize_factor)</span><br><span class="line">        x2 = int(bbox[<span class="number">3</span>] * resize_factor)</span><br><span class="line">        y2 = int(bbox[<span class="number">2</span>]  * resize_factor)</span><br><span class="line">        cv2.rectangle(image, (x1,y1), (x2,y2), (<span class="number">77</span>, <span class="number">255</span>, <span class="number">9</span>), <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        width = x2 - x1 </span><br><span class="line">        height = y2 - y1 </span><br><span class="line"><span class="comment">#         print("x &#123;&#125; y &#123;&#125; h &#123;&#125; w &#123;&#125;".format(x1, y1, width, height))</span></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    ax.set_title(<span class="string">f"<span class="subst">&#123;len(r[<span class="string">'rois'</span>])&#125;</span>: <span class="subst">&#123;image_id&#125;</span>"</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">    visualize_test()</span><br></pre></td></tr></table></figure>
<h2 id="outcome"><a class="markdownIt-Anchor" href="#outcome"></a> Outcome</h2>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line">➜  airbus-ship-detection python airbus_ship_detection.py</span><br><span class="line">Using TensorFlow backend.</span><br><span class="line"></span><br><span class="line">Configurations:</span><br><span class="line">BACKBONE                       resnet50</span><br><span class="line">BACKBONE_STRIDES               [4, 8, 16, 32, 64]</span><br><span class="line">BATCH_SIZE                     10</span><br><span class="line">BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]</span><br><span class="line">COMPUTE_BACKBONE_SHAPE         None</span><br><span class="line">DETECTION_MAX_INSTANCES        14</span><br><span class="line">DETECTION_MIN_CONFIDENCE       0.95</span><br><span class="line">DETECTION_NMS_THRESHOLD        0.0</span><br><span class="line">FPN_CLASSIF_FC_LAYERS_SIZE     1024</span><br><span class="line">GPU_COUNT                      1</span><br><span class="line">GRADIENT_CLIP_NORM             5.0</span><br><span class="line">IMAGES_PER_GPU                 10</span><br><span class="line">IMAGE_CHANNEL_COUNT            3</span><br><span class="line">IMAGE_MAX_DIM                  384</span><br><span class="line">IMAGE_META_SIZE                14</span><br><span class="line">IMAGE_MIN_DIM                  384</span><br><span class="line">IMAGE_MIN_SCALE                0</span><br><span class="line">IMAGE_RESIZE_MODE              square</span><br><span class="line">IMAGE_SHAPE                    [384 384   3]</span><br><span class="line">LEARNING_MOMENTUM              0.9</span><br><span class="line">LEARNING_RATE                  0.001</span><br><span class="line">LOSS_WEIGHTS                   &#123;'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0&#125;</span><br><span class="line">MASK_POOL_SIZE                 14</span><br><span class="line">MASK_SHAPE                     [28, 28]</span><br><span class="line">MAX_GT_INSTANCES               14</span><br><span class="line">MEAN_PIXEL                     [123.7 116.8 103.9]</span><br><span class="line">MINI_MASK_SHAPE                (56, 56)</span><br><span class="line">NAME                           airbus</span><br><span class="line">NUM_CLASSES                    2</span><br><span class="line">POOL_SIZE                      7</span><br><span class="line">POST_NMS_ROIS_INFERENCE        1000</span><br><span class="line">POST_NMS_ROIS_TRAINING         2000</span><br><span class="line">PRE_NMS_LIMIT                  6000</span><br><span class="line">ROI_POSITIVE_RATIO             0.33</span><br><span class="line">RPN_ANCHOR_RATIOS              [0.5, 1, 2]</span><br><span class="line">RPN_ANCHOR_SCALES              (8, 16, 32, 64)</span><br><span class="line">RPN_ANCHOR_STRIDE              1</span><br><span class="line">RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]</span><br><span class="line">RPN_NMS_THRESHOLD              0.7</span><br><span class="line">RPN_TRAIN_ANCHORS_PER_IMAGE    256</span><br><span class="line">STEPS_PER_EPOCH                120</span><br><span class="line">TOP_DOWN_PYRAMID_SIZE          256</span><br><span class="line">TRAIN_BN                       False</span><br><span class="line">TRAIN_ROIS_PER_IMAGE           126</span><br><span class="line">USE_MINI_MASK                  True</span><br><span class="line">USE_RPN_ROIS                   True</span><br><span class="line">VALIDATION_STEPS               100</span><br><span class="line">WEIGHT_DECAY                   0.0001</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">41556 1000 15606</span><br><span class="line">(768, 768, 3)</span><br><span class="line">....../airbus-ship-detection/train_v2/ae490e3fb.jpg</span><br><span class="line">[1]</span><br><span class="line">2019-01-23 12:19:43.634701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:993] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero</span><br><span class="line">2019-01-23 12:19:43.635112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: </span><br><span class="line">name: GeForce GTX 980M major: 5 minor: 2 memoryClockRate(GHz): 1.1265</span><br><span class="line">pciBusID: 0000:01:00.0</span><br><span class="line">totalMemory: 3.94GiB freeMemory: 2.93GiB</span><br><span class="line">2019-01-23 12:19:43.635131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0</span><br><span class="line">2019-01-23 12:19:43.918100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:</span><br><span class="line">2019-01-23 12:19:43.918138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 </span><br><span class="line">2019-01-23 12:19:43.918145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N </span><br><span class="line">2019-01-23 12:19:43.918284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2636 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 980M, pci bus id: 0000:01:00.0, compute capability: 5.2)</span><br><span class="line"></span><br><span class="line">Starting at epoch 0. LR=0.008</span><br><span class="line"></span><br><span class="line">Checkpoint Path: ./airbus20190123T1219/mask_rcnn_airbus_&#123;epoch:04d&#125;.h5</span><br><span class="line">Selecting layers to train</span><br><span class="line">fpn_c5p5               (Conv2D)</span><br><span class="line">fpn_c4p4               (Conv2D)</span><br><span class="line">fpn_c3p3               (Conv2D)</span><br><span class="line">fpn_c2p2               (Conv2D)</span><br><span class="line">fpn_p5                 (Conv2D)</span><br><span class="line">fpn_p2                 (Conv2D)</span><br><span class="line">fpn_p3                 (Conv2D)</span><br><span class="line">fpn_p4                 (Conv2D)</span><br><span class="line">In model:  rpn_model</span><br><span class="line">    rpn_conv_shared        (Conv2D)</span><br><span class="line">    rpn_class_raw          (Conv2D)</span><br><span class="line">    rpn_bbox_pred          (Conv2D)</span><br><span class="line">mrcnn_mask_conv1       (TimeDistributed)</span><br><span class="line">mrcnn_mask_bn1         (TimeDistributed)</span><br><span class="line">mrcnn_mask_conv2       (TimeDistributed)</span><br><span class="line">mrcnn_mask_bn2         (TimeDistributed)</span><br><span class="line">mrcnn_class_conv1      (TimeDistributed)</span><br><span class="line">mrcnn_class_bn1        (TimeDistributed)</span><br><span class="line">mrcnn_mask_conv3       (TimeDistributed)</span><br><span class="line">mrcnn_mask_bn3         (TimeDistributed)</span><br><span class="line">mrcnn_class_conv2      (TimeDistributed)</span><br><span class="line">mrcnn_class_bn2        (TimeDistributed)</span><br><span class="line">mrcnn_mask_conv4       (TimeDistributed)</span><br><span class="line">mrcnn_mask_bn4         (TimeDistributed)</span><br><span class="line">mrcnn_bbox_fc          (TimeDistributed)</span><br><span class="line">mrcnn_mask_deconv      (TimeDistributed)</span><br><span class="line">mrcnn_class_logits     (TimeDistributed)</span><br><span class="line">mrcnn_mask             (TimeDistributed)</span><br><span class="line">Epoch 1/2</span><br><span class="line">......</span><br><span class="line">2019-01-23 12:21:14.922200: I tensorflow/core/common_runtime/bfc_allocator.cc:647] Stats: </span><br><span class="line">Limit:                  2764636160</span><br><span class="line">InUse:                  2422788608</span><br><span class="line">MaxInUse:               2500490496</span><br><span class="line">NumAllocs:                    3411</span><br><span class="line">MaxAllocSize:           1257242624</span><br><span class="line"></span><br><span class="line">2019-01-23 12:21:14.922287: W tensorflow/core/common_runtime/bfc_allocator.cc:271] *********************x*************************_**___******************************************_____</span><br><span class="line">2019-01-23 12:21:14.922318: W tensorflow/core/framework/op_kernel.cc:1333] OP_REQUIRES failed at transpose_op.cc:199 : Resource exhausted: OOM when allocating tensor with shape[1260,14,14,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File "airbus_ship_detection.py", line 356, in &lt;module&gt;</span><br><span class="line">    augmentation=None)  ## no need to augment yet</span><br><span class="line">  File "/home/jiapei/.local/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py", line 2375, in train</span><br><span class="line">  File "/home/jiapei/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py", line 91, in wrapper</span><br><span class="line">    return func(*args, **kwargs)</span><br><span class="line">  File "/home/jiapei/.local/lib/python3.6/site-packages/keras/engine/training.py", line 1418, in fit_generator</span><br><span class="line">    initial_epoch=initial_epoch)</span><br><span class="line">  File "/home/jiapei/.local/lib/python3.6/site-packages/keras/engine/training_generator.py", line 217, in fit_generator</span><br><span class="line">    class_weight=class_weight)</span><br><span class="line">  File "/home/jiapei/.local/lib/python3.6/site-packages/keras/engine/training.py", line 1217, in train_on_batch</span><br><span class="line">    outputs = self.train_function(ins)</span><br><span class="line">  File "/home/jiapei/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 2715, in __call__</span><br><span class="line">    return self._call(inputs)</span><br><span class="line">  File "/home/jiapei/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 2675, in _call</span><br><span class="line">    fetched = self._callable_fn(*array_vals)</span><br><span class="line">  File "/home/jiapei/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1439, in __call__</span><br><span class="line">    run_metadata_ptr)</span><br><span class="line">  File "/home/jiapei/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py", line 528, in __exit__</span><br><span class="line">    c_api.TF_GetCode(self.status.status))</span><br><span class="line">tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1260,14,14,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc</span><br><span class="line">         [[&#123;&#123;node mrcnn_mask_bn1/FusedBatchNorm-0-0-TransposeNCHWToNHWC-LayoutOptimizer&#125;&#125;]]</span><br><span class="line">Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.</span><br><span class="line"></span><br><span class="line">         [[&#123;&#123;node mrcnn_mask_loss/Shape_1/_4457&#125;&#125;]]</span><br><span class="line">Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.</span><br></pre></td></tr></table></figure>
<p>I haven’t quite figure out how to solve the <strong>Resource exhausted</strong> issue yet. But some resultant images can be viewed <strong>FIRST</strong>:</p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2018/airbus-ship-detection/01_sampleimg.jpg" alt="sample airbus ship"><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2018/airbus-ship-detection/02_ae490e3fb_boundingbox.jpg" alt="sample airbus ship and bounding box"><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2018/airbus-ship-detection/03_sampleimgs.jpg" alt="sample airbus ships"></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2019/01/23/Kaggle/PyTorch-dataset-dataloader/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/23/Kaggle/PyTorch-dataset-dataloader/" itemprop="url">
                  Kaggle Competition - PyTorch Dataset and DataLoader
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-23 00:00:00" itemprop="dateCreated datePublished" datetime="2019-01-23T00:00:00-08:00">2019-01-23</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-01-24 04:34:31" itemprop="dateModified" datetime="2019-01-24T04:34:31-08:00">2019-01-24</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Kaggle/" itemprop="url" rel="index"><span itemprop="name">Kaggle</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="preparation"><a class="markdownIt-Anchor" href="#preparation"></a> Preparation</h1>
<h2 id="required-python-packages"><a class="markdownIt-Anchor" href="#required-python-packages"></a> Required Python Packages</h2>
<p>We <strong>FIRST</strong> make sure 2 Python packages - <a href="https://pytorch.org/" target="_blank" rel="noopener">PyTorch</a> and <a href="https://pytorch.org/docs/stable/torchvision/index.html" target="_blank" rel="noopener">TorchVision</a> have been successfully installed.</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ pip show torch</span><br><span class="line">Name: torch</span><br><span class="line">Version: 1.1.0a0+b6a8c45</span><br><span class="line">Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration</span><br><span class="line">Home-page: UNKNOWN</span><br><span class="line">Author: UNKNOWN</span><br><span class="line">Author-email: UNKNOWN</span><br><span class="line">License: UNKNOWN</span><br><span class="line">Location: /home/jiapei/.local/lib/python3.6/site-packages</span><br><span class="line">Requires: </span><br><span class="line">Required-by: torchvision, torchtext, torchgan, pytorch-pretrained-bert, pyro-ppl, flair, autokeras</span><br><span class="line">➜  ~ pip show torchvision</span><br><span class="line">Name: torchvision</span><br><span class="line">Version: 0.2.1</span><br><span class="line">Summary: image and video datasets and models for torch deep learning</span><br><span class="line">Home-page: https://github.com/pytorch/vision</span><br><span class="line">Author: PyTorch Core Team</span><br><span class="line">Author-email: soumith@pytorch.org</span><br><span class="line">License: BSD</span><br><span class="line">Location: /home/jiapei/.local/lib/python3.6/site-packages</span><br><span class="line">Requires: numpy, six, torch, pillow</span><br><span class="line">Required-by: torchgan, torchfusion, autokeras</span><br></pre></td></tr></table></figure>
<p>As you can see, I actually built my own <a href="https://pytorch.org/" target="_blank" rel="noopener">PyTorch</a> from scratch, <strong>so that</strong> I can also use <a href="https://caffe2.ai/" target="_blank" rel="noopener">caffe2</a> sometimes. Please refer to the following:</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ pip show caffe2</span><br><span class="line">➜  ~ python</span><br><span class="line">Python 3.6.7 (default, Oct 22 2018, 11:32:17) </span><br><span class="line">[GCC 8.2.0] on linux</span><br><span class="line">Type "help", "copyright", "credits" or "license" for more information.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import caffe2</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; caffe2.__version__</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File "&lt;stdin&gt;", line 1, in &lt;module&gt;</span><br><span class="line">AttributeError: module 'caffe2' has no attribute '__version__'</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; caffe2.__file__</span></span><br><span class="line">'/home/jiapei/.local/lib/python3.6/site-packages/caffe2/__init__.py'</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="test"><a class="markdownIt-Anchor" href="#test"></a> Test</h1>
<h2 id="the-code"><a class="markdownIt-Anchor" href="#the-code"></a> The Code</h2>
<p>Trivial modifications have been done upon the code on <a href="https://www.kaggle.com/pinocookie/pytorch-dataset-and-dataloader" target="_blank" rel="noopener">PyTorch Dataset and DataLoader</a>, as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing, CSV file I/O (e.g. pd.read_csv)</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment">#get_ipython().run_line_magic('matplotlib', 'inline')</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">print(torch.__version__)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DatasetMNIST</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, file_path, transform=None)</span>:</span></span><br><span class="line">        self.data = pd.read_csv(file_path)</span><br><span class="line">        self.transform = transform</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.data)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="comment"># load image as ndarray type (Height * Width * Channels)</span></span><br><span class="line">        <span class="comment"># be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]</span></span><br><span class="line">        <span class="comment"># in this example, i don't use ToTensor() method of torchvision.transforms</span></span><br><span class="line">        <span class="comment"># so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --&gt; (C, H, W)</span></span><br><span class="line">        image = self.data.iloc[index, <span class="number">1</span>:].values.astype(np.uint8).reshape((<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">        label = self.data.iloc[index, <span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> image, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_dataset = DatasetMNIST(<span class="string">'./input/train.csv'</span>, transform=<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># we can access and get data with index by __getitem__(index)</span></span><br><span class="line">img, lab = train_dataset.__getitem__(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># we now didn't convert numpy array.</span></span><br><span class="line">print(img.shape)</span><br><span class="line">print(type(img))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ### 3.3 take a look at the dataset</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># you have to use data loader in PyTorch that will accutually read the data within batch size and put into memory.</span></span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=<span class="number">8</span>, shuffle=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># we can use dataloader as iterator by using iter() function.</span></span><br><span class="line">train_iter = iter(train_loader)</span><br><span class="line">print(type(train_iter))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># we can look at images and labels of batch size by extracting data .next() method.</span></span><br><span class="line">images, labels = train_iter.next()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'images shape on batch size = &#123;&#125;'</span>.format(images.size()))</span><br><span class="line">print(<span class="string">'labels shape on batch size = &#123;&#125;'</span>.format(labels.size()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># make grid takes tensor as arg</span></span><br><span class="line"><span class="comment"># tensor : (batchsize, channels, height, width)</span></span><br><span class="line">grid = torchvision.utils.make_grid(images)</span><br><span class="line"></span><br><span class="line">plt.imshow(grid.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.title(labels.numpy());</span><br><span class="line">plt.savefig(<span class="string">'1.jpg'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ### 3.4 transform is ToTensor()**</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DatasetMNIST2</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, file_path, transform=None)</span>:</span></span><br><span class="line">        self.data = pd.read_csv(file_path)</span><br><span class="line">        self.transform = transform</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.data)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="comment"># load image as ndarray type (Height * Width * Channels)</span></span><br><span class="line">        <span class="comment"># be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]</span></span><br><span class="line">        <span class="comment"># in this example, we use ToTensor(), so we define the numpy array like (H, W, C)</span></span><br><span class="line">        image = self.data.iloc[index, <span class="number">1</span>:].values.astype(np.uint8).reshape((<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">        label = self.data.iloc[index, <span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> image, label</span><br><span class="line"></span><br><span class="line">train_dataset2 = DatasetMNIST2(<span class="string">'./input/train.csv'</span>, transform=torchvision.transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">img, lab = train_dataset2.__getitem__(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'image shape at the first row : &#123;&#125;'</span>.format(img.size()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_loader2 = DataLoader(train_dataset2, batch_size=<span class="number">8</span>, shuffle=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">train_iter2 = iter(train_loader2)</span><br><span class="line">print(type(train_iter2))</span><br><span class="line"></span><br><span class="line">images, labels = train_iter2.next()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'images shape on batch size = &#123;&#125;'</span>.format(images.size()))</span><br><span class="line">print(<span class="string">'labels shape on batch size = &#123;&#125;'</span>.format(labels.size()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">grid = torchvision.utils.make_grid(images)</span><br><span class="line"></span><br><span class="line">plt.imshow(grid.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.title(labels.numpy());</span><br><span class="line">plt.savefig(<span class="string">'2.jpg'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(), <span class="comment"># because the input dtype is numpy.ndarray</span></span><br><span class="line">    transforms.RandomHorizontalFlip(<span class="number">0.5</span>), <span class="comment"># because this method is used for PIL Image dtype</span></span><br><span class="line">    transforms.ToTensor(), <span class="comment"># because inpus dtype is PIL Image</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_dataset3 = DatasetMNIST2(<span class="string">'./input/train.csv'</span>, transform=transform)</span><br><span class="line">train_loader3 = DataLoader(train_dataset3, batch_size=<span class="number">8</span>, shuffle=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">train_iter3 = iter(train_loader3)</span><br><span class="line">print(type(train_iter3))</span><br><span class="line"></span><br><span class="line">images, labels = train_iter3.next()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'images shape on batch size = &#123;&#125;'</span>.format(images.size()))</span><br><span class="line">print(<span class="string">'labels shape on batch size = &#123;&#125;'</span>.format(labels.size()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">grid = torchvision.utils.make_grid(images)</span><br><span class="line"></span><br><span class="line">plt.imshow(grid.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.title(labels.numpy());</span><br><span class="line">plt.savefig(<span class="string">'3.jpg'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="outcome"><a class="markdownIt-Anchor" href="#outcome"></a> Outcome</h2>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/general/pytorch/mnist_01.jpg" alt="MNIST 1st Load"><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/general/pytorch/mnist_02.jpg" alt="MNIST 2nd Load"><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/general/pytorch/mnist_03.jpg" alt="MNIST 3rd Load"></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2019/01/22/Finance/time-series-forecasting-with-Facebook-Prophet/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/22/Finance/time-series-forecasting-with-Facebook-Prophet/" itemprop="url">
                  Time Series Forecasting with Facebook Prophet
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-22 00:00:00" itemprop="dateCreated datePublished" datetime="2019-01-22T00:00:00-08:00">2019-01-22</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-01-23 04:13:50" itemprop="dateModified" datetime="2019-01-23T04:13:50-08:00">2019-01-23</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Finance/" itemprop="url" rel="index"><span itemprop="name">Finance</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Today, we are going to test out <a href="https://facebook.github.io/prophet/" target="_blank" rel="noopener">Facebook Prophet</a> by following <a href="https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-forecasting-with-prophet-in-python-3" target="_blank" rel="noopener">this DigitalOcean Tutorial</a>.</p>
<h1 id="preparation"><a class="markdownIt-Anchor" href="#preparation"></a> Preparation</h1>
<h2 id="required-python-packages"><a class="markdownIt-Anchor" href="#required-python-packages"></a> Required Python Packages</h2>
<p>We <strong>FIRST</strong> make sure 2 Python packages - <a href="https://facebook.github.io/prophet/" target="_blank" rel="noopener">Prophet</a> and <a href="https://pystan.readthedocs.io/en/latest/" target="_blank" rel="noopener">PyStan</a> have been successfully installed.</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ pip show prophet</span><br><span class="line">Name: prophet</span><br><span class="line">Version: 0.1.1</span><br><span class="line">Summary: Microframework for analyzing financial markets.</span><br><span class="line">Home-page: http://prophet.michaelsu.io/</span><br><span class="line">Author: Michael Su</span><br><span class="line">Author-email: mdasu1@gmail.com</span><br><span class="line">License: BSD</span><br><span class="line">Location: /home/jiapei/.local/lib/python3.6/site-packages</span><br><span class="line">Requires: six, pytz, pandas</span><br><span class="line">Required-by: </span><br><span class="line">➜  ~ pip show pystan</span><br><span class="line">Name: pystan</span><br><span class="line">Version: 2.18.1.0</span><br><span class="line">Summary: Python interface to Stan, a package for Bayesian inference</span><br><span class="line">Home-page: https://github.com/stan-dev/pystan</span><br><span class="line">Author: None</span><br><span class="line">Author-email: None</span><br><span class="line">License: GPLv3</span><br><span class="line">Location: /home/jiapei/.local/lib/python3.6/site-packages</span><br><span class="line">Requires: Cython, numpy</span><br><span class="line">Required-by: fbprophet</span><br></pre></td></tr></table></figure>
<h2 id="download-the-time-series-data"><a class="markdownIt-Anchor" href="#download-the-time-series-data"></a> Download the Time Series Data</h2>
<p>We just need to download the CSV file to some directory:</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  facebookprophet curl -O https://assets.digitalocean.com/articles/eng_python/prophet/AirPassengers.csv</span><br><span class="line"><span class="meta">  %</span><span class="bash"> Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100  1748  100  1748    0     0   2281      0 --:--:-- --:--:-- --:--:--  2279</span><br></pre></td></tr></table></figure>
<h1 id="test"><a class="markdownIt-Anchor" href="#test"></a> Test</h1>
<h2 id="the-code"><a class="markdownIt-Anchor" href="#the-code"></a> The Code</h2>
<p>Trivial modifications have been done upon the code on <a href="https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-forecasting-with-prophet-in-python-3" target="_blank" rel="noopener">this DigitalOcean Tutorial</a>, as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> fbprophet <span class="keyword">import</span> Prophet</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">'fivethirtyeight'</span>)</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'AirPassengers.csv'</span>)</span><br><span class="line">df.head(<span class="number">5</span>)</span><br><span class="line">df.dtypes</span><br><span class="line"></span><br><span class="line">df[<span class="string">'Month'</span>] = pd.DatetimeIndex(df[<span class="string">'Month'</span>])</span><br><span class="line">df.dtypes</span><br><span class="line"></span><br><span class="line">df = df.rename(columns=&#123;<span class="string">'Month'</span>: <span class="string">'ds'</span>, <span class="string">'AirPassengers'</span>: <span class="string">'y'</span>&#125;)</span><br><span class="line">df.head(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">ax = df.set_index(<span class="string">'ds'</span>).plot(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax.set_ylabel(<span class="string">'Monthly Number of Airline Passengers'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'Date'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># set the uncertainty interval to 95% (the Prophet default is 80%)</span></span><br><span class="line">my_model = Prophet(interval_width=<span class="number">0.95</span>)</span><br><span class="line">my_model.fit(df)</span><br><span class="line">future_dates = my_model.make_future_dataframe(periods=<span class="number">36</span>, freq=<span class="string">'MS'</span>)</span><br><span class="line">future_dates.tail()</span><br><span class="line">forecast = my_model.predict(future_dates)</span><br><span class="line">forecast[[<span class="string">'ds'</span>, <span class="string">'yhat'</span>, <span class="string">'yhat_lower'</span>, <span class="string">'yhat_upper'</span>]].tail()</span><br><span class="line">fig1 = my_model.plot(forecast, uncertainty=<span class="keyword">True</span>)</span><br><span class="line">fig1.show()</span><br><span class="line"></span><br><span class="line">my_model.plot_components(forecast).savefig(<span class="string">'prophet_forcast.png'</span>);</span><br></pre></td></tr></table></figure>
<h2 id="outcome"><a class="markdownIt-Anchor" href="#outcome"></a> Outcome</h2>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/finance/prophet/01_originaldata.jpg" alt="Original Data"></p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/finance/prophet/02_forcast.jpg" alt="Forcast"></p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/finance/prophet/03_forcast_components.jpg" alt="Forcast Component"></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2019/01/17/Kaggle/LANL-Earthquake-Prediction/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/17/Kaggle/LANL-Earthquake-Prediction/" itemprop="url">
                  Kaggle Competition - LANL Earthquake Prediction
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-17 00:00:00" itemprop="dateCreated datePublished" datetime="2019-01-17T00:00:00-08:00">2019-01-17</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-01-24 04:34:03" itemprop="dateModified" datetime="2019-01-24T04:34:03-08:00">2019-01-24</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Kaggle/" itemprop="url" rel="index"><span itemprop="name">Kaggle</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Hello everyone. It’s been quite busy these days… Anyway, today, let’s test out <a href="https://www.kaggle.com/c/LANL-Earthquake-Prediction" target="_blank" rel="noopener">Kaggle LANL Earthquake Prediction</a>.</p>
<h1 id="data-preparation"><a class="markdownIt-Anchor" href="#data-preparation"></a> Data Preparation</h1>
<h2 id="data-download"><a class="markdownIt-Anchor" href="#data-download"></a> Data Download</h2>
<p>Please refer to <a href="https://www.kaggle.com/c/LANL-Earthquake-Prediction/data" target="_blank" rel="noopener">Kaggle LANL Earthquake Prediction Data</a> and have the data prepared.</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kaggle competitions download -c LANL-Earthquake-Prediction</span><br><span class="line">➜  cd LANL-Earthquake-Prediction</span><br><span class="line">➜  LANL-Earthquake-Prediction ls</span><br><span class="line">sample_submission.csv  test.zip  train.csv.zip</span><br></pre></td></tr></table></figure>
<h2 id="data-exploration"><a class="markdownIt-Anchor" href="#data-exploration"></a> Data Exploration</h2>
<p>We can then use <a href="https://www.kaggle.com/gpreda/lanl-earthquake-eda-and-prediction" target="_blank" rel="noopener">Gabriel Preda’s existing kernel code</a> to briefly analyze the data and have the following resultant pictures re-produced <strong>FIRST</strong>:</p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/LANL-Earthquake-Prediction/01_acousticdata_time2failure1.jpg" alt="Acoustic Data and Time To Failure 1"></p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/LANL-Earthquake-Prediction/02_acousticdata_time2failure2.jpg" alt="Acoustic Data and Time To Failure 2"></p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/LANL-Earthquake-Prediction/03_lgbm_importances.jpg" alt="LGBM Feature Importance"></p>
<h1 id="the-algorithm"><a class="markdownIt-Anchor" href="#the-algorithm"></a> The Algorithm</h1>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2019/01/10/Kaggle/petfinder-adoption-prediction/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/10/Kaggle/petfinder-adoption-prediction/" itemprop="url">
                  Kaggle Competition - PetFinder.my Adoption Prediction
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-10 00:00:00" itemprop="dateCreated datePublished" datetime="2019-01-10T00:00:00-08:00">2019-01-10</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-01-24 04:34:25" itemprop="dateModified" datetime="2019-01-24T04:34:25-08:00">2019-01-24</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Kaggle/" itemprop="url" rel="index"><span itemprop="name">Kaggle</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Happy new year everybody. 2019 comes. Let’s have some <a href="https://www.kaggle.com" target="_blank" rel="noopener">Kaggle</a> fun. Today, we’re going to try <a href="https://www.kaggle.com/c/petfinder-adoption-prediction" target="_blank" rel="noopener">PetFinder.my Adoption Prediction</a>.</p>
<h1 id="system-preparation"><a class="markdownIt-Anchor" href="#system-preparation"></a> System Preparation</h1>
<p>Supposing you’ve already correctly set up all your configurations:</p>
<h2 id="python"><a class="markdownIt-Anchor" href="#python"></a> <a href="https://www.python.org/" target="_blank" rel="noopener">Python</a></h2>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ python --version</span><br><span class="line">Python 3.6.7</span><br><span class="line">➜  ~ which python</span><br><span class="line">/usr/bin/python</span><br></pre></td></tr></table></figure>
<h2 id="kaggle"><a class="markdownIt-Anchor" href="#kaggle"></a> <a href="https://www.kaggle.com" target="_blank" rel="noopener">Kaggle</a></h2>
<p>Please follow <a href="https://github.com/Kaggle/kaggle-api" target="_blank" rel="noopener">Kaggle Github</a> to install <strong>Python Kaggle</strong>. After installation, you’ll get:</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ pip show kaggle</span><br><span class="line">Name: kaggle</span><br><span class="line">Version: 1.5.1.1</span><br><span class="line">Summary: Kaggle API</span><br><span class="line">Home-page: https://github.com/Kaggle/kaggle-api</span><br><span class="line">Author: Kaggle</span><br><span class="line">Author-email: support@kaggle.com</span><br><span class="line">License: Apache 2.0</span><br><span class="line">Location: ~/.local/lib/python3.6/site-packages</span><br><span class="line">Requires: requests, certifi, tqdm, six, python-dateutil, python-slugify, urllib3</span><br><span class="line">Required-by:</span><br></pre></td></tr></table></figure>
<h2 id="cuda"><a class="markdownIt-Anchor" href="#cuda"></a> <a href="https://developer.nvidia.com/cuda-toolkit" target="_blank" rel="noopener">Cuda</a></h2>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ nvidia-smi</span><br><span class="line">Wed Jan  2 15:52:06 2019       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 410.78       Driver Version: 410.78       CUDA Version: 10.0     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  GeForce GTX 980M    Off  | 00000000:01:00.0  On |                  N/A |</span><br><span class="line">| N/A   32C    P8     8W /  N/A |    779MiB /  4035MiB |      0%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    0      1842      G   /usr/lib/xorg/Xorg                            15MiB |</span><br><span class="line">|    0      1952      G   /usr/bin/gnome-shell                          48MiB |</span><br><span class="line">|    0      2923      G   /usr/lib/xorg/Xorg                           188MiB |</span><br><span class="line">|    0      3039      G   /usr/bin/gnome-shell                         163MiB |</span><br><span class="line">|    0      3801      G   ...uest-channel-token=14688497433927674620   220MiB |</span><br><span class="line">|    0      7109      G   ...-token=FECD30C79B74E3AD9CF815BF4CB9EB09    70MiB |</span><br><span class="line">|    0     28276      G   ...-token=8CC4669488D477BE118BBC69F71B724E    64MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">➜  ~ /usr/local/cuda/samples/bin/x86_64/linux/release/deviceQuery</span><br><span class="line">/usr/local/cuda/samples/bin/x86_64/linux/release/deviceQuery Starting...</span><br><span class="line"></span><br><span class="line"> CUDA Device Query (Runtime API) version (CUDART static linking)</span><br><span class="line"></span><br><span class="line">Detected 1 CUDA Capable device(s)</span><br><span class="line"></span><br><span class="line">Device 0: "GeForce GTX 980M"</span><br><span class="line">  CUDA Driver Version / Runtime Version          10.0 / 10.0</span><br><span class="line">  CUDA Capability Major/Minor version number:    5.2</span><br><span class="line">  Total amount of global memory:                 4035 MBytes (4231331840 bytes)</span><br><span class="line">  (12) Multiprocessors, (128) CUDA Cores/MP:     1536 CUDA Cores</span><br><span class="line">  GPU Max Clock rate:                            1126 MHz (1.13 GHz)</span><br><span class="line">  Memory Clock rate:                             2505 Mhz</span><br><span class="line">  Memory Bus Width:                              256-bit</span><br><span class="line">  L2 Cache Size:                                 2097152 bytes</span><br><span class="line">  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)</span><br><span class="line">  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers</span><br><span class="line">  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers</span><br><span class="line">  Total amount of constant memory:               65536 bytes</span><br><span class="line">  Total amount of shared memory per block:       49152 bytes</span><br><span class="line">  Total number of registers available per block: 65536</span><br><span class="line">  Warp size:                                     32</span><br><span class="line">  Maximum number of threads per multiprocessor:  2048</span><br><span class="line">  Maximum number of threads per block:           1024</span><br><span class="line">  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)</span><br><span class="line">  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)</span><br><span class="line">  Maximum memory pitch:                          2147483647 bytes</span><br><span class="line">  Texture alignment:                             512 bytes</span><br><span class="line">  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)</span><br><span class="line">  Run time limit on kernels:                     Yes</span><br><span class="line">  Integrated GPU sharing Host Memory:            No</span><br><span class="line">  Support host page-locked memory mapping:       Yes</span><br><span class="line">  Alignment requirement for Surfaces:            Yes</span><br><span class="line">  Device has ECC support:                        Disabled</span><br><span class="line">  Device supports Unified Addressing (UVA):      Yes</span><br><span class="line">  Device supports Compute Preemption:            No</span><br><span class="line">  Supports Cooperative Kernel Launch:            No</span><br><span class="line">  Supports MultiDevice Co-op Kernel Launch:      No</span><br><span class="line">  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0</span><br><span class="line">  Compute Mode:</span><br><span class="line">     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;</span><br><span class="line"></span><br><span class="line">deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.0, CUDA Runtime Version = 10.0, NumDevs = 1</span><br><span class="line">Result = PASS</span><br></pre></td></tr></table></figure>
<h1 id="data-preparation"><a class="markdownIt-Anchor" href="#data-preparation"></a> Data Preparation</h1>
<h2 id="data-download"><a class="markdownIt-Anchor" href="#data-download"></a> Data Download</h2>
<p>Please refer to <a href="https://www.kaggle.com/c/petfinder-adoption-prediction/data" target="_blank" rel="noopener">Kaggle petfinder-adoption-prediction Data</a> and have the data prepared.</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ kaggle competitions download -c petfinder-adoption-prediction</span><br><span class="line">➜  cd petfinder-adoption-prediction</span><br><span class="line">➜  petfinder-adoption-prediction ls</span><br><span class="line">breed_labels.csv  color_labels.csv  state_labels.csv  test_images.zip  test_metadata.zip  test_sentiment.zip  test.zip  train_images.zip  train_metadata.zip  train_sentiment.zip  train.zip</span><br></pre></td></tr></table></figure>
<h2 id="data-exploration"><a class="markdownIt-Anchor" href="#data-exploration"></a> Data Exploration</h2>
<p>We can then use <a href="https://www.kaggle.com/artgor/exploration-of-data-step-by-step" target="_blank" rel="noopener">Andrew Lukyanenko’s existing kernel code</a> to explore how the data look like. It’s <strong>NOT hard</strong> to re-produce the following resultant pictures:</p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/01_classcounts.jpg" alt="Number of Samples (both cats and dogs) in Each Classes -- Classified by Adoption Speed"></p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/02_classrates.jpg" alt=""></p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/03_nbofcatsdogs.jpg" alt="Number of Cats &amp; Dogs in Train and Test Datasets"></p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/04_pettyperates.jpg" alt="Number of Samples (respectively for cats and dogs) in Each Classes -- Classified by Adoption Speed "></p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/05_wordcounts.jpg" alt="Word Count for Cats &amp; Dogs"></p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/06_classrates_namenoname.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/07_petsages.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/08_typeage.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/09_purebreedanalysis.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/10_wordcounts_breed.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/11_genderanalysis.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/12_gender_traintest.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/13_coloranalysis.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/14_color_classcounts_1.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/14_color_classcounts_2.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/15_maturitysize.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/16_maturitysize_classcounts.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/17_breed_SmallCats.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/17_breed_MediumCats.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/17_breed_LargeCats.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/17_breed_ExtraLargeCats.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/17_breed_SmallDogs.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/17_breed_MediumDogs.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/17_breed_LargeDogs.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/17_breed_ExtraLargeDogs.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/18_furlengthanalysis.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/19_wordcounts_breed_fur.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/20_StrangePets.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/21_healthanalysis.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/22_health_classcounts.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/23_agedistribution.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/24_quantityanalysis.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/25_freeanalysis.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/26_feeanalysis.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/27_feequantity.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/28_countsbyrescuers.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/29_countsbystates.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/30_countsbyphotoamt.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/31_photoamtanalysis.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/32_wordcounts_description.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/33_type_descriptionlength.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/34_langanalysis.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/35_typeanalysis.jpg" alt=""><br>
<img src="https://raw.githubusercontent.com/LongerVision/Resource/master/AI/Kaggle/2019/petfinder-adoption-prediction/36_LGBFeatures.jpg" alt=""></p>
<h1 id="the-algorithm"><a class="markdownIt-Anchor" href="#the-algorithm"></a> The Algorithm</h1>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2019/01/09/Bugs/matplotlib-path-home/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/09/Bugs/matplotlib-path-home/" itemprop="url">
                  Matplotlib.pyplot - AttributeError - type object 'Path' has no attribute 'home'
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-09 00:00:00 / Modified: 22:34:16" itemprop="dateCreated datePublished" datetime="2019-01-09T00:00:00-08:00">2019-01-09</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Bug/" itemprop="url" rel="index"><span itemprop="name">Bug</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="attributeerror-type-object-path-has-no-attribute-home"><a class="markdownIt-Anchor" href="#attributeerror-type-object-path-has-no-attribute-home"></a> AttributeError: type object ‘Path’ has no attribute ‘home’</h1>
<p>This error message is found while I was trying to <strong>from matplotlib.pyplot as plt</strong> today. I’ve got <strong>NO</strong> idea what had happened to my <strong>python</strong>. But, it seems this issue had been met and solved in some public posts. For instance:</p>
<ul>
<li><a href="https://github.com/addok/addok/issues/280" target="_blank" rel="noopener">github addok</a></li>
</ul>
<h1 id="solutions"><a class="markdownIt-Anchor" href="#solutions"></a> Solutions:</h1>
<p>In my case, I need to manually modify 3 files under folder <strong>~/.local/lib/python3.6/site-packages/matplotlib</strong>.</p>
<h2 id="pathhome-ospathexpanduser~"><a class="markdownIt-Anchor" href="#pathhome-ospathexpanduser~"></a> Path.home() -&gt; os.path.expanduser(’~’)</h2>
<ul>
<li>In file <strong>~/.local/lib/python3.6/site-packages/matplotlib/font_manager.py</strong>, around line 135, change</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> USE_FONTCONFIG <span class="keyword">and</span> sys.platform != <span class="string">'win32'</span>:</span><br><span class="line">    OSXFontDirectories.append(str(Path.home() / <span class="string">"Library/Fonts"</span>))</span><br><span class="line">    X11FontDirectories.append(str(Path.home() / <span class="string">".fonts"</span>))</span><br></pre></td></tr></table></figure>
<p>to</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> USE_FONTCONFIG <span class="keyword">and</span> sys.platform != <span class="string">'win32'</span>:</span><br><span class="line">    OSXFontDirectories.append(str(os.path.expanduser(<span class="string">'~'</span>)+<span class="string">'/'</span>+<span class="string">"Library/Fonts"</span>))</span><br><span class="line">    X11FontDirectories.append(str(os.path.expanduser(<span class="string">'~'</span>)+<span class="string">'/'</span>+<span class="string">".fonts"</span>))</span><br></pre></td></tr></table></figure>
<h2 id="remove-exist_oktrue-in-function-mkdir"><a class="markdownIt-Anchor" href="#remove-exist_oktrue-in-function-mkdir"></a> Remove exist_ok=True in function mkdir()</h2>
<ul>
<li>In file <strong>~/.local/lib/python3.6/site-packages/matplotlib/<strong>init</strong>.py</strong>, around line 615</li>
<li>In file <strong>~/.local/lib/python3.6/site-packages/matplotlib/texmanager.py</strong>, around line 56 and 104</li>
</ul>
<p>change all</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir(parents=<span class="keyword">True</span>, exist_ok=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>to</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir(parents=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2019/01/06/Bugs/flownet2-pytorch-vid2vid/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/06/Bugs/flownet2-pytorch-vid2vid/" itemprop="url">
                  3 Bugs - Pytorch, Flownet2-Pytorch and vid2vid
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-01-06 00:00:00" itemprop="dateCreated datePublished" datetime="2019-01-06T00:00:00-08:00">2019-01-06</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-01-09 01:29:24" itemprop="dateModified" datetime="2019-01-09T01:29:24-08:00">2019-01-09</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Bug/" itemprop="url" rel="index"><span itemprop="name">Bug</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Haven’t successfully tested three packages (all related to <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener">PyTorch</a>), <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener">PyTorch</a>, <a href="https://github.com/NVIDIA/flownet2-pytorch" target="_blank" rel="noopener">FlowNet2-Pytorch</a> and <a href="https://github.com/NVIDIA/vid2vid" target="_blank" rel="noopener">vid2vid</a>. Looking forward to assistance…</p>
<h1 id="pytorch"><a class="markdownIt-Anchor" href="#pytorch"></a> PyTorch</h1>
<h2 id="the-bug"><a class="markdownIt-Anchor" href="#the-bug"></a> The Bug</h2>
<p>After having successfully installed <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener">PyTorch</a> current version <strong>1.1</strong>, I still failed to <strong>import torch</strong>. Please refer to the following <strong>ERROR</strong>.</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ python</span><br><span class="line">Python 3.6.7 (default, Oct 22 2018, 11:32:17) </span><br><span class="line">[GCC 8.2.0] on linux</span><br><span class="line">Type "help", "copyright", "credits" or "license" for more information.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import torch</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File "&lt;stdin&gt;", line 1, in &lt;module&gt;</span><br><span class="line">  File "~/.local/lib/python3.6/site-packages/torch/__init__.py", line 84, in &lt;module&gt;</span><br><span class="line">    from torch._C import *</span><br><span class="line">ImportError: ~/.local/lib/python3.6/site-packages/torch/lib/libcaffe2.so: undefined symbol: _ZTIN3c1010TensorImplE</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import caffe2</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; caffe2.__version__</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File "&lt;stdin&gt;", line 1, in &lt;module&gt;</span><br><span class="line">AttributeError: module 'caffe2' has no attribute '__version__'</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; caffe2.__file__</span></span><br><span class="line">'~/.local/lib/python3.6/site-packages/caffe2/__init__.py'</span><br></pre></td></tr></table></figure>
<p>In order to have <strong><a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener">PyTorch</a></strong> successully imported, I’ve got to remove the <strong>manually installed <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener">PyTorch</a> v 1.1</strong>, but had it installed by <strong>pip</strong></p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl</span><br></pre></td></tr></table></figure>
<p>This is <strong>PyTorch v1.0</strong>, which seems <strong>NOT</strong> come with <strong>caffe2</strong>, and of course <strong>should NOT</strong> be compatible with the installed <strong>caffe2</strong> built with <strong>PyTorch v1.1</strong>. Can anybody help to solve this issue? Please also refer to <a href="https://github.com/pytorch/pytorch/issues/15800" target="_blank" rel="noopener">Github issue</a>.</p>
<h2 id="solution"><a class="markdownIt-Anchor" href="#solution"></a> Solution</h2>
<p>Remove <strong>anything/everything</strong> related to your <strong>previously installed <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener">PyTorch</a></strong>. In my case, file <strong>/usr/local/lib/libc10.s0</strong> is to be removed. In order to analyze which files are possibly related to the concerned package, we can use the command <strong>ldd</strong>.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">➜  lib ldd libcaffe2.so</span><br><span class="line">        linux-vdso.so.1 (0x00007ffcf3dc9000)</span><br><span class="line">        libc10.so =&gt; /usr/local/lib/libc10.so (0x00007fca41b88000)</span><br><span class="line">        libmpi.so.12 =&gt; /opt/intel/mpi/intel64/lib/libmpi.so.12 (0x00007f8acdad9000)</span><br><span class="line">        librt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007f8acd8d1000)</span><br><span class="line">        libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f8acd6b2000)</span><br><span class="line">        libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f8acd4ae000)</span><br><span class="line">        libgcc_s.so.1 =&gt; /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f8acd296000)</span><br><span class="line">        libmkl_intel_lp64.so =&gt; /opt/intel/mkl/lib/intel64/libmkl_intel_lp64.so (0x00007f8acc765000)</span><br><span class="line">        libmkl_gnu_thread.so =&gt; /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.so (0x00007f8acaf2c000)</span><br><span class="line">        libmkl_core.so =&gt; /opt/intel/mkl/lib/intel64/libmkl_core.so (0x00007f8ac6df3000)</span><br><span class="line">        libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007f8ac6a55000)</span><br><span class="line">        libstdc++.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f8ac66cc000)</span><br><span class="line">        libgomp.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libgomp.so.1 (0x00007f8ac649d000)</span><br><span class="line">        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8ac60ac000)</span><br><span class="line">        /lib64/ld-linux-x86-64.so.2 (0x00007f8ad250d000)</span><br><span class="line">        libnuma.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libnuma.so.1 (0x00007f8ac5ea1000)</span><br><span class="line">        libfabric.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libfabric.so.1 (0x00007f8ac5bf4000)</span><br><span class="line">        librdmacm.so.1 =&gt; /usr/lib/x86_64-linux-gnu/librdmacm.so.1 (0x00007f8ac59de000)</span><br><span class="line">        libibverbs.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libibverbs.so.1 (0x00007f8ac57c8000)</span><br><span class="line">        libpsm_infinipath.so.1 =&gt; /usr/lib/x86_64-linux-gnu/libpsm_infinipath.so.1 (0x00007f8ac556f000)</span><br><span class="line">        libnl-route-3.so.200 =&gt; /usr/lib/x86_64-linux-gnu/libnl-route-3.so.200 (0x00007f8ac52fa000)</span><br><span class="line">        libnl-3.so.200 =&gt; /lib/x86_64-linux-gnu/libnl-3.so.200 (0x00007f8ac50da000)</span><br><span class="line">        libinfinipath.so.4 =&gt; /usr/lib/x86_64-linux-gnu/libinfinipath.so.4 (0x00007f8ac4ecb000)</span><br><span class="line">        libuuid.so.1 =&gt; /lib/x86_64-linux-gnu/libuuid.so.1 (0x00007f8ac4cc4000)</span><br></pre></td></tr></table></figure>
<h1 id="flownet2-pytorch"><a class="markdownIt-Anchor" href="#flownet2-pytorch"></a> FlowNet2-Pytorch</h1>
<h2 id="installation"><a class="markdownIt-Anchor" href="#installation"></a> Installation</h2>
<p>It’s not hard to have <a href="https://github.com/NVIDIA/flownet2-pytorch" target="_blank" rel="noopener">FlowNet2-Pytorch</a> installed by one line of commands:</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜  flownet2-pytorch git:(master) ✗ ./install.sh</span><br></pre></td></tr></table></figure>
<p>After installation, there will be 3 packages installed under folder <strong>~/.local/lib/python3.6/site-packages</strong>:</p>
<ul>
<li><strong>correlation-cuda</strong></li>
<li><strong>resample2d-cuda</strong></li>
<li><strong>channelnorm-cuda</strong></li>
</ul>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">➜  site-packages ls -lsd correlation*</span><br><span class="line">4 drwxrwxr-x 4 jiapei jiapei 4096 Jan  7 00:07 correlation_cuda-0.0.0-py3.6-linux-x86_64.egg</span><br><span class="line">➜  site-packages ls -lsd channelnorm*</span><br><span class="line">4 drwxrwxr-x 4 jiapei jiapei 4096 Jan  7 00:07 channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg</span><br><span class="line">➜  site-packages ls -lsd resample2d*</span><br><span class="line">4 drwxrwxr-x 4 jiapei jiapei 4096 Jan  7 00:07 resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg</span><br><span class="line">➜  site-packages ls -lsd flownet2*</span><br><span class="line">zsh: no matches found: flownet2*</span><br><span class="line">➜  site-packages pwd</span><br><span class="line">~/.local/lib/python3.6/site-packages</span><br></pre></td></tr></table></figure>
<p>That is to say: you should <strong>NEVER</strong> import <strong>flownet2</strong>, nor <strong>correlation</strong>, nor <strong>channelnorm</strong>, nor <strong>resampled2d</strong>, but</p>
<ul>
<li><strong>correlation_cuda</strong></li>
<li><strong>resample2d_cuda</strong></li>
<li><strong>channelnorm_cuda</strong></li>
</ul>
<h2 id="current-bug"><a class="markdownIt-Anchor" href="#current-bug"></a> Current Bug</h2>
<p>Here comes the <strong>ERROR</strong>:</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ python</span><br><span class="line">Python 3.6.7 (default, Oct 22 2018, 11:32:17) </span><br><span class="line">[GCC 8.2.0] on linux</span><br><span class="line">Type "help", "copyright", "credits" or "license" for more information.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import correlation_cuda</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File "&lt;stdin&gt;", line 1, in &lt;module&gt;</span><br><span class="line">ImportError: ~/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg/correlation_cuda.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN2at19UndefinedTensorImpl10_singletonE</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import channelnorm_cuda</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File "&lt;stdin&gt;", line 1, in &lt;module&gt;</span><br><span class="line">ImportError: ~/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg/channelnorm_cuda.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN2at19UndefinedTensorImpl10_singletonE</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import resample2d_cuda</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File "&lt;stdin&gt;", line 1, in &lt;module&gt;</span><br><span class="line">ImportError: ~/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg/resample2d_cuda.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN2at19UndefinedTensorImpl10_singletonE</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt;</span></span><br></pre></td></tr></table></figure>
<p>I’ve already posted <a href="https://github.com/NVIDIA/flownet2-pytorch/issues/116" target="_blank" rel="noopener">an issue on github</a>. Had anybody solved this problem?</p>
<h2 id="solution-2"><a class="markdownIt-Anchor" href="#solution-2"></a> Solution</h2>
<p><strong>import torch FIRST</strong>.</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ python</span><br><span class="line">Python 3.6.7 (default, Oct 22 2018, 11:32:17) </span><br><span class="line">[GCC 8.2.0] on linux</span><br><span class="line">Type "help", "copyright", "credits" or "license" for more information.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import torch</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import correlation_cuda</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import resample2d_cuda</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import channelnorm_cuda</span></span><br></pre></td></tr></table></figure>
<h2 id="still-buggy"><a class="markdownIt-Anchor" href="#still-buggy"></a> Still Buggy</h2>
<h3 id="flownet2-pytorch-inference"><a class="markdownIt-Anchor" href="#flownet2-pytorch-inference"></a> FlowNet2-Pytorch Inference</h3>
<p>Where can we find and download <strong>checkpoints</strong>? Please refer to <a href="https://github.com/NVIDIA/flownet2-pytorch#inference" target="_blank" rel="noopener">Inference</a> on <a href="https://github.com/NVIDIA/flownet2-pytorch" target="_blank" rel="noopener">FlowNet2-Pytorch</a>:</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python main.py --inference --model FlowNet2 --save_flow --inference_dataset MpiSintelClean --inference_dataset_root /path/to/mpi-sintel/clean/dataset --resume /path/to/checkpoints</span><br></pre></td></tr></table></figure>
<h3 id="flownet2-pytorch-training"><a class="markdownIt-Anchor" href="#flownet2-pytorch-training"></a> FlowNet2-Pytorch Training</h3>
<p><a href="https://github.com/NVIDIA/flownet2-pytorch#training-and-validation" target="_blank" rel="noopener">Training</a> on <a href="https://github.com/NVIDIA/flownet2-pytorch" target="_blank" rel="noopener">FlowNet2-Pytorch</a> gives the following <strong>ERROR</strong>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">➜  flownet2-pytorch git:(master) ✗ python main.py --batch_size 8 --model FlowNet2 --loss=L1Loss --optimizer=Adam --optimizer_lr=1e-4 --training_dataset MpiSintelFinal --training_dataset_root /path/to/mpi-sintel/training/final/mountain_1  --validation_dataset MpiSintelClean --validation_dataset_root /path/tompi-sintel/training/clean/mountain_1</span><br><span class="line">Parsing Arguments</span><br><span class="line">  [0.013s] batch_size: 8</span><br><span class="line">  [0.013s] crop_size: [256, 256]</span><br><span class="line">  [0.013s] fp16: False</span><br><span class="line">  [0.014s] fp16_scale: 1024.0</span><br><span class="line">  [0.014s] gradient_clip: None</span><br><span class="line">  [0.014s] inference: False</span><br><span class="line">  [0.014s] inference_batch_size: 1</span><br><span class="line">  [0.014s] inference_dataset: MpiSintelClean</span><br><span class="line">  [0.014s] inference_dataset_replicates: 1</span><br><span class="line">  [0.014s] inference_dataset_root: ./MPI-Sintel/flow/training</span><br><span class="line">  [0.014s] inference_n_batches: -1</span><br><span class="line">  [0.014s] inference_size: [-1, -1]</span><br><span class="line">  [0.014s] log_frequency: 1</span><br><span class="line">  [0.014s] loss: L1Loss</span><br><span class="line">  [0.014s] model: FlowNet2</span><br><span class="line">  [0.014s] model_batchNorm: False</span><br><span class="line">  [0.014s] model_div_flow: 20.0</span><br><span class="line">  [0.014s] name: run</span><br><span class="line">  [0.014s] no_cuda: False</span><br><span class="line">  [0.014s] number_gpus: 1</span><br><span class="line">  [0.014s] number_workers: 8</span><br><span class="line">  [0.014s] optimizer: Adam</span><br><span class="line">  [0.014s] optimizer_amsgrad: False</span><br><span class="line">  [0.014s] optimizer_betas: (0.9, 0.999)</span><br><span class="line">  [0.014s] optimizer_eps: 1e-08</span><br><span class="line">  [0.014s] optimizer_lr: 0.0001</span><br><span class="line">  [0.014s] optimizer_weight_decay: 0</span><br><span class="line">  [0.014s] render_validation: False</span><br><span class="line">  [0.014s] resume: </span><br><span class="line">  [0.014s] rgb_max: 255.0</span><br><span class="line">  [0.014s] save: ./work</span><br><span class="line">  [0.014s] save_flow: False</span><br><span class="line">  [0.014s] schedule_lr_fraction: 10</span><br><span class="line">  [0.014s] schedule_lr_frequency: 0</span><br><span class="line">  [0.014s] seed: 1</span><br><span class="line">  [0.014s] skip_training: False</span><br><span class="line">  [0.014s] skip_validation: False</span><br><span class="line">  [0.014s] start_epoch: 1</span><br><span class="line">  [0.014s] total_epochs: 10000</span><br><span class="line">  [0.014s] train_n_batches: -1</span><br><span class="line">  [0.014s] training_dataset: MpiSintelFinal</span><br><span class="line">  [0.014s] training_dataset_replicates: 1</span><br><span class="line">  [0.014s] training_dataset_root: ....../mpi-sintel/training/final/mountain_1</span><br><span class="line">  [0.014s] validation_dataset: MpiSintelClean</span><br><span class="line">  [0.014s] validation_dataset_replicates: 1</span><br><span class="line">  [0.014s] validation_dataset_root: ....../mpi-sintel/training/clean/mountain_1</span><br><span class="line">  [0.014s] validation_frequency: 5</span><br><span class="line">  [0.014s] validation_n_batches: -1</span><br><span class="line">  [0.016s] Operation finished</span><br><span class="line"></span><br><span class="line">Source Code</span><br><span class="line">  Current Git Hash: b&apos;ac1602a72f0454f65872126b70665a596fae8009&apos;</span><br><span class="line"></span><br><span class="line">Initializing Datasets</span><br><span class="line">  [0.003s] Operation failed</span><br><span class="line"></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;main.py&quot;, line 139, in &lt;module&gt;</span><br><span class="line">    train_dataset = args.training_dataset_class(args, True, **tools.kwargs_from_args(args, &apos;training_dataset&apos;))</span><br><span class="line">  File &quot;....../flownet2-pytorch/datasets.py&quot;, line 112, in __init__</span><br><span class="line">    super(MpiSintelFinal, self).__init__(args, is_cropped = is_cropped, root = root, dstype = &apos;final&apos;, replicates = replicates)</span><br><span class="line">  File &quot;....../flownet2-pytorch/datasets.py&quot;, line 66, in __init__</span><br><span class="line">    self.frame_size = frame_utils.read_gen(self.image_list[0][0]).shape</span><br><span class="line">IndexError: list index out of range</span><br></pre></td></tr></table></figure>
<p>Therefore, I posted <a href="https://github.com/NVIDIA/flownet2-pytorch/issues/99" target="_blank" rel="noopener">a further issue on Github</a>.</p>
<h1 id="vid2vid"><a class="markdownIt-Anchor" href="#vid2vid"></a> vid2vid</h1>
<h2 id="preparation"><a class="markdownIt-Anchor" href="#preparation"></a> Preparation</h2>
<p>There are 4 scripts under folder scripts to run before testing <a href="https://github.com/NVIDIA/vid2vid" target="_blank" rel="noopener">vid2vid</a>.</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜  vid2vid git:(master) ✗ ll scripts/*.py</span><br><span class="line">-rwxrwxrwx 1 jiapei jiapei  322 Jan  5 22:04 scripts/download_datasets.py</span><br><span class="line">-rwxrwxrwx 1 jiapei jiapei  579 Jan  5 22:04 scripts/download_flownet2.py</span><br><span class="line">-rwxrwxrwx 1 jiapei jiapei 1.3K Jan  5 22:04 scripts/download_gdrive.py</span><br><span class="line">-rwxrwxrwx 1 jiapei jiapei  257 Jan  5 22:04 scripts/download_models_flownet2.py</span><br></pre></td></tr></table></figure>
<p>However, <strong>ONLY 3</strong> of the scripts can be successfully run, but <strong>scripts/download_flownet2.py</strong> failed to run, as follows:</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">➜  vid2vid git:(master) python scripts/download_flownet2.py </span><br><span class="line">Compiling correlation kernels by nvcc...</span><br><span class="line">rm: cannot remove '../_ext': No such file or directory</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File "build.py", line 3, in &lt;module&gt;</span><br><span class="line">    import torch.utils.ffi</span><br><span class="line">  File "~/.local/lib/python3.6/site-packages/torch/utils/ffi/__init__.py", line 1, in &lt;module&gt;</span><br><span class="line">    raise ImportError("torch.utils.ffi is deprecated. Please use cpp extensions instead.")</span><br><span class="line">ImportError: torch.utils.ffi is deprecated. Please use cpp extensions instead.</span><br><span class="line">Compiling resample2d kernels by nvcc...</span><br><span class="line">rm: cannot remove 'Resample2d_kernel.o': No such file or directory</span><br><span class="line">rm: cannot remove '../_ext': No such file or directory</span><br><span class="line">In file included from Resample2d_kernel.cu:1:0:</span><br><span class="line">~/.local/lib/python3.6/site-packages/torch/lib/include/THC/THC.h:4:10: fatal error: THC/THCGeneral.h: No such file or directory</span><br><span class="line"><span class="meta"> #</span><span class="bash">include &lt;THC/THCGeneral.h&gt;</span></span><br><span class="line">          ^~~~~~~~~~~~~~~~~~</span><br><span class="line">compilation terminated.</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File "build.py", line 3, in &lt;module&gt;</span><br><span class="line">    import torch.utils.ffi</span><br><span class="line">  File "~/.local/lib/python3.6/site-packages/torch/utils/ffi/__init__.py", line 1, in &lt;module&gt;</span><br><span class="line">    raise ImportError("torch.utils.ffi is deprecated. Please use cpp extensions instead.")</span><br><span class="line">ImportError: torch.utils.ffi is deprecated. Please use cpp extensions instead.</span><br><span class="line">Compiling channelnorm kernels by nvcc...</span><br><span class="line">rm: cannot remove 'ChannelNorm_kernel.o': No such file or directory</span><br><span class="line">rm: cannot remove '../_ext': No such file or directory</span><br><span class="line">In file included from ChannelNorm_kernel.cu:1:0:</span><br><span class="line">~/.local/lib/python3.6/site-packages/torch/lib/include/THC/THC.h:4:10: fatal error: THC/THCGeneral.h: No such file or directory</span><br><span class="line"><span class="meta"> #</span><span class="bash">include &lt;THC/THCGeneral.h&gt;</span></span><br><span class="line">          ^~~~~~~~~~~~~~~~~~</span><br><span class="line">compilation terminated.</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File "build.py", line 3, in &lt;module&gt;</span><br><span class="line">    import torch.utils.ffi</span><br><span class="line">  File "~/.local/lib/python3.6/site-packages/torch/utils/ffi/__init__.py", line 1, in &lt;module&gt;</span><br><span class="line">    raise ImportError("torch.utils.ffi is deprecated. Please use cpp extensions instead.")</span><br><span class="line">ImportError: torch.utils.ffi is deprecated. Please use cpp extensions instead.</span><br></pre></td></tr></table></figure>
<h2 id="testing-is-also-buggy"><a class="markdownIt-Anchor" href="#testing-is-also-buggy"></a> Testing is ALSO Buggy</h2>
<p>If we run <a href="https://github.com/NVIDIA/vid2vid#testing" target="_blank" rel="noopener">Testing</a> on <a href="https://github.com/NVIDIA/vid2vid" target="_blank" rel="noopener">vid2vid homepage</a>, it gives the following <strong>ERROR</strong>:</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">➜  vid2vid git:(master) python test.py --name label2city_2048 --label_nc 35 --loadSize 2048 --n_scales_spatial 3 --use_instance --fg --use_single_G</span><br><span class="line">------------ Options -------------</span><br><span class="line">add_face_disc: False</span><br><span class="line">aspect_ratio: 1.0</span><br><span class="line">basic_point_only: False</span><br><span class="line">batchSize: 1</span><br><span class="line">checkpoints_dir: ./checkpoints</span><br><span class="line">dataroot: datasets/Cityscapes/</span><br><span class="line">dataset_mode: temporal</span><br><span class="line">debug: False</span><br><span class="line">densepose_only: False</span><br><span class="line">display_id: 0</span><br><span class="line">display_winsize: 512</span><br><span class="line">feat_num: 3</span><br><span class="line">fg: True</span><br><span class="line">fg_labels: [26]</span><br><span class="line">fineSize: 512</span><br><span class="line">gpu_ids: [0]</span><br><span class="line">how_many: 300</span><br><span class="line">input_nc: 3</span><br><span class="line">isTrain: False</span><br><span class="line">label_feat: False</span><br><span class="line">label_nc: 35</span><br><span class="line">loadSize: 2048</span><br><span class="line">load_features: False</span><br><span class="line">load_pretrain: </span><br><span class="line">max_dataset_size: inf</span><br><span class="line">model: vid2vid</span><br><span class="line">nThreads: 2</span><br><span class="line">n_blocks: 9</span><br><span class="line">n_blocks_local: 3</span><br><span class="line">n_downsample_E: 3</span><br><span class="line">n_downsample_G: 3</span><br><span class="line">n_frames_G: 3</span><br><span class="line">n_gpus_gen: 1</span><br><span class="line">n_local_enhancers: 1</span><br><span class="line">n_scales_spatial: 3</span><br><span class="line">name: label2city_2048</span><br><span class="line">ndf: 64</span><br><span class="line">nef: 32</span><br><span class="line">netE: simple</span><br><span class="line">netG: composite</span><br><span class="line">ngf: 128</span><br><span class="line">no_canny_edge: False</span><br><span class="line">no_dist_map: False</span><br><span class="line">no_first_img: False</span><br><span class="line">no_flip: False</span><br><span class="line">no_flow: False</span><br><span class="line">norm: batch</span><br><span class="line">ntest: inf</span><br><span class="line">openpose_only: False</span><br><span class="line">output_nc: 3</span><br><span class="line">phase: test</span><br><span class="line">random_drop_prob: 0.05</span><br><span class="line">random_scale_points: False</span><br><span class="line">remove_face_labels: False</span><br><span class="line">resize_or_crop: scaleWidth</span><br><span class="line">results_dir: ./results/</span><br><span class="line">serial_batches: False</span><br><span class="line">start_frame: 0</span><br><span class="line">tf_log: False</span><br><span class="line">use_instance: True</span><br><span class="line">use_real_img: False</span><br><span class="line">use_single_G: True</span><br><span class="line">which_epoch: latest</span><br><span class="line">-------------- End ----------------</span><br><span class="line">CustomDatasetDataLoader</span><br><span class="line">dataset [TestDataset] was created</span><br><span class="line">vid2vid</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File "test.py", line 25, in &lt;module&gt;</span><br><span class="line">    model = create_model(opt)</span><br><span class="line">  File "....../vid2vid/models/models.py", line 7, in create_model</span><br><span class="line">    from .vid2vid_model_G import Vid2VidModelG</span><br><span class="line">  File "....../vid2vid/models/vid2vid_model_G.py", line 13, in &lt;module&gt;</span><br><span class="line">    from . import networks</span><br><span class="line">  File "....../vid2vid/models/networks.py", line 12, in &lt;module&gt;</span><br><span class="line">    from .flownet2_pytorch.networks.resample2d_package.resample2d import Resample2d</span><br><span class="line">  File "....../vid2vid/models/flownet2_pytorch/networks/resample2d_package/resample2d.py", line 2, in &lt;module&gt;</span><br><span class="line">    from .functions.resample2d import Resample2dFunction</span><br><span class="line">  File "....../vid2vid/models/flownet2_pytorch/networks/resample2d_package/functions/resample2d.py", line 3, in &lt;module&gt;</span><br><span class="line">    from .._ext import resample2d</span><br><span class="line">ModuleNotFoundError: No module named 'models.flownet2_pytorch.networks.resample2d_package._ext'</span><br></pre></td></tr></table></figure>
<p>This is still annoying me. <a href="https://github.com/NVIDIA/vid2vid/issues/86" target="_blank" rel="noopener">A detailed github issue</a> has been posted today. Please give me a hand. Thanks…</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Nobody</p>
              <p class="site-description motion-element" itemprop="description">Longer Vision Technology Github Blog</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">46</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">14</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">44</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Nobody</span>

  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Muse</a> v6.3.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



	





  





  










  





  

  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" type="text/css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

   
  


  
  

  

  

  

  

  

</body>
</html>
