<pre><code class="python"># Copy and paste from
# https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b
# with trivial modifications
#
# Author: Nobody in Computer Vision
# Date: 2022-03-04
# 
# Contacts:
# Company: Longer Vision Technology
# Email: jiapei@longervision.com
# Website: https://www.longervision.com
</code></pre>
<pre><code class="python">from __future__ import print_function
import time
import numpy as np
import pandas as pd
from sklearn.datasets import fetch_openml
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
%matplotlib inline
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns
</code></pre>
<pre><code class="python">mnist = fetch_openml(&quot;mnist_784&quot;)
X = mnist.data / 255.0
y = mnist.target
print(X.shape, y.shape)
</code></pre>
<pre><code>(70000, 784) (70000,)
</code></pre>
<pre><code class="python">feat_cols = [ &#39;pixel&#39;+str(i+1) for i in range(X.shape[1]) ]
df = pd.DataFrame(X,columns=feat_cols)
df[&#39;y&#39;] = list(map(int, y))
df[&#39;label&#39;] = y.apply(lambda i: str(i))
print(&#39;Size of the dataframe: {}&#39;.format(df.shape))
X, y = None, None
</code></pre>
<pre><code>Size of the dataframe: (70000, 786)
</code></pre>
<pre><code class="python"># For reproducability of the results
np.random.seed(42)
rndperm = np.random.permutation(df.shape[0])
</code></pre>
<pre><code class="python">plt.gray()
fig = plt.figure( figsize=(16,7) )
for i in range(0,15):
    ax = fig.add_subplot(3,5,i+1, title=&quot;Digit: {}&quot;.format(str(df.loc[rndperm[i],&#39;label&#39;])) )
    ax.matshow(df.loc[rndperm[i],feat_cols].values.reshape((28,28)).astype(float))
plt.show()
</code></pre>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src="EDA-tSNE-1-MNIST_files/EDA-tSNE-1-MNIST_5_1.png" alt="png"></p>
<pre><code class="python">pca = PCA(n_components=3)
pca_result = pca.fit_transform(df[feat_cols].values)
df[&#39;pca-one&#39;] = pca_result[:,0]
df[&#39;pca-two&#39;] = pca_result[:,1] 
df[&#39;pca-three&#39;] = pca_result[:,2]
print(&#39;Explained variation per principal component: {}&#39;.format(pca.explained_variance_ratio_))
</code></pre>
<pre><code>Explained variation per principal component: [0.09746116 0.07155445 0.06149531]
</code></pre>
<pre><code class="python">plt.figure(figsize=(16,10))
sns.scatterplot(
    x=&quot;pca-one&quot;, y=&quot;pca-two&quot;,
    hue=&quot;y&quot;,
    palette=sns.color_palette(&quot;hls&quot;, 10),
    data=df.loc[rndperm,:],
    legend=&quot;full&quot;,
    alpha=0.3
)
</code></pre>
<pre><code>&lt;AxesSubplot:xlabel=&#39;pca-one&#39;, ylabel=&#39;pca-two&#39;&gt;
</code></pre>
<p><img src="EDA-tSNE-1-MNIST_files/EDA-tSNE-1-MNIST_7_1.png" alt="png"></p>
<pre><code class="python">df
c=df.loc[rndperm,:][&quot;label&quot;]
print(c)
print(type(c))
</code></pre>
<pre><code>46730    8
48393    4
41416    8
34506    7
43725    7
        ..
37194    6
6265     6
54886    1
860      0
15795    0
Name: label, Length: 70000, dtype: category
Categories (10, object): [&#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, ..., &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;]
&lt;class &#39;pandas.core.series.Series&#39;&gt;
</code></pre>
<pre><code class="python">ax = plt.figure(figsize=(16,10)).add_subplot(projection=&#39;3d&#39;)
ax.scatter(
    xs=df.loc[rndperm,:][&quot;pca-one&quot;], 
    ys=df.loc[rndperm,:][&quot;pca-two&quot;], 
    zs=df.loc[rndperm,:][&quot;pca-three&quot;], 
    c=df.loc[rndperm,:][&quot;y&quot;], 
    cmap=&#39;tab10&#39;
)
ax.set_xlabel(&#39;pca-one&#39;)
ax.set_ylabel(&#39;pca-two&#39;)
ax.set_zlabel(&#39;pca-three&#39;)
plt.show()
</code></pre>
<p><img src="EDA-tSNE-1-MNIST_files/EDA-tSNE-1-MNIST_9_0.png" alt="png"></p>
<pre><code class="python">N = 10000
df_subset = df.loc[rndperm[:N],:].copy()
data_subset = df_subset[feat_cols].values
pca = PCA(n_components=3)
pca_result = pca.fit_transform(data_subset)
df_subset[&#39;pca-one&#39;] = pca_result[:,0]
df_subset[&#39;pca-two&#39;] = pca_result[:,1] 
df_subset[&#39;pca-three&#39;] = pca_result[:,2]
print(&#39;Explained variation per principal component: {}&#39;.format(pca.explained_variance_ratio_))
</code></pre>
<pre><code>Explained variation per principal component: [0.09819946 0.07123677 0.06113222]
</code></pre>
<pre><code class="python">time_start = time.time()
tsne = TSNE(n_components=2, learning_rate=&#39;auto&#39;, init=&#39;pca&#39;, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(data_subset)
print(&#39;t-SNE done! Time elapsed: {} seconds&#39;.format(time.time()-time_start))
</code></pre>
<pre><code>[t-SNE] Computing 121 nearest neighbors...
[t-SNE] Indexed 10000 samples in 0.003s...
[t-SNE] Computed neighbors for 10000 samples in 1.547s...
[t-SNE] Computed conditional probabilities for sample 1000 / 10000
[t-SNE] Computed conditional probabilities for sample 2000 / 10000
[t-SNE] Computed conditional probabilities for sample 3000 / 10000
[t-SNE] Computed conditional probabilities for sample 4000 / 10000
[t-SNE] Computed conditional probabilities for sample 5000 / 10000
[t-SNE] Computed conditional probabilities for sample 6000 / 10000
[t-SNE] Computed conditional probabilities for sample 7000 / 10000
[t-SNE] Computed conditional probabilities for sample 8000 / 10000
[t-SNE] Computed conditional probabilities for sample 9000 / 10000
[t-SNE] Computed conditional probabilities for sample 10000 / 10000
[t-SNE] Mean sigma: 2.117974


/home/lvision/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.
  warnings.warn(


[t-SNE] KL divergence after 250 iterations with early exaggeration: 85.990288
[t-SNE] KL divergence after 300 iterations: 2.786253
t-SNE done! Time elapsed: 8.129722356796265 seconds
</code></pre>
<pre><code class="python">df_subset[&#39;tsne-2d-one&#39;] = tsne_results[:,0]
df_subset[&#39;tsne-2d-two&#39;] = tsne_results[:,1]
plt.figure(figsize=(16,10))
sns.scatterplot(
    x=&quot;tsne-2d-one&quot;, y=&quot;tsne-2d-two&quot;,
    hue=&quot;y&quot;,
    palette=sns.color_palette(&quot;hls&quot;, 10),
    data=df_subset,
    legend=&quot;full&quot;,
    alpha=0.3
)
</code></pre>
<pre><code>&lt;AxesSubplot:xlabel=&#39;tsne-2d-one&#39;, ylabel=&#39;tsne-2d-two&#39;&gt;
</code></pre>
<p><img src="EDA-tSNE-1-MNIST_files/EDA-tSNE-1-MNIST_12_1.png" alt="png"></p>
<pre><code class="python">plt.figure(figsize=(16,7))
ax1 = plt.subplot(1, 2, 1)
sns.scatterplot(
    x=&quot;pca-one&quot;, y=&quot;pca-two&quot;,
    hue=&quot;y&quot;,
    palette=sns.color_palette(&quot;hls&quot;, 10),
    data=df_subset,
    legend=&quot;full&quot;,
    alpha=0.3,
    ax=ax1
)
ax2 = plt.subplot(1, 2, 2)
sns.scatterplot(
    x=&quot;tsne-2d-one&quot;, y=&quot;tsne-2d-two&quot;,
    hue=&quot;y&quot;,
    palette=sns.color_palette(&quot;hls&quot;, 10),
    data=df_subset,
    legend=&quot;full&quot;,
    alpha=0.3,
    ax=ax2
)
</code></pre>
<pre><code>&lt;AxesSubplot:xlabel=&#39;tsne-2d-one&#39;, ylabel=&#39;tsne-2d-two&#39;&gt;
</code></pre>
<p><img src="EDA-tSNE-1-MNIST_files/EDA-tSNE-1-MNIST_13_1.png" alt="png"></p>
<pre><code class="python">pca_50 = PCA(n_components=50)
pca_result_50 = pca_50.fit_transform(data_subset)
print(&#39;Cumulative explained variation for 50 principal components: {}&#39;.format(np.sum(pca_50.explained_variance_ratio_)))
</code></pre>
<pre><code>Cumulative explained variation for 50 principal components: 0.8261769578399734
</code></pre>
<pre><code class="python">time_start = time.time()
tsne = TSNE(n_components=2, learning_rate=&#39;auto&#39;, init=&#39;pca&#39;, verbose=0, perplexity=40, n_iter=300)
tsne_pca_results = tsne.fit_transform(pca_result_50)
print(&#39;t-SNE done! Time elapsed: {} seconds&#39;.format(time.time()-time_start))
</code></pre>
<pre><code>/home/lvision/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.
  warnings.warn(


t-SNE done! Time elapsed: 7.227182388305664 seconds
</code></pre>
<pre><code class="python">df_subset[&#39;tsne-pca50-one&#39;] = tsne_pca_results[:,0]
df_subset[&#39;tsne-pca50-two&#39;] = tsne_pca_results[:,1]
plt.figure(figsize=(16,4))
ax1 = plt.subplot(1, 3, 1)
sns.scatterplot(
    x=&quot;pca-one&quot;, y=&quot;pca-two&quot;,
    hue=&quot;y&quot;,
    palette=sns.color_palette(&quot;hls&quot;, 10),
    data=df_subset,
    legend=&quot;full&quot;,
    alpha=0.3,
    ax=ax1
)
ax2 = plt.subplot(1, 3, 2)
sns.scatterplot(
    x=&quot;tsne-2d-one&quot;, y=&quot;tsne-2d-two&quot;,
    hue=&quot;y&quot;,
    palette=sns.color_palette(&quot;hls&quot;, 10),
    data=df_subset,
    legend=&quot;full&quot;,
    alpha=0.3,
    ax=ax2
)
ax3 = plt.subplot(1, 3, 3)
sns.scatterplot(
    x=&quot;tsne-pca50-one&quot;, y=&quot;tsne-pca50-two&quot;,
    hue=&quot;y&quot;,
    palette=sns.color_palette(&quot;hls&quot;, 10),
    data=df_subset,
    legend=&quot;full&quot;,
    alpha=0.3,
    ax=ax3
)
</code></pre>
<pre><code>&lt;AxesSubplot:xlabel=&#39;tsne-pca50-one&#39;, ylabel=&#39;tsne-pca50-two&#39;&gt;
</code></pre>
<p><img src="EDA-tSNE-1-MNIST_files/EDA-tSNE-1-MNIST_16_1.png" alt="png"></p>
