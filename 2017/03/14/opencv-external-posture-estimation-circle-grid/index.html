<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Camera Posture Estimation Using Circle Grid Pattern | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="PreparationA widely used asymmetric circle grid pattern can be found in doc of OpenCV 2.4. Same as previous blogs, the camera needs to be calibrated beforehand. For this asymmetric circle grid example">
<meta name="keywords" content="Camera Posture Estimation, Circle Grid, Marker, Pattern, OpenCV, Python">
<meta property="og:type" content="article">
<meta property="og:title" content="Camera Posture Estimation Using Circle Grid Pattern">
<meta property="og:url" content="http://yoursite.com/2017/03/14/opencv-external-posture-estimation-circle-grid/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="PreparationA widely used asymmetric circle grid pattern can be found in doc of OpenCV 2.4. Same as previous blogs, the camera needs to be calibrated beforehand. For this asymmetric circle grid example">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/pattern_acircles.png">
<meta property="og:updated_time" content="2018-06-15T05:03:16.310Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Camera Posture Estimation Using Circle Grid Pattern">
<meta name="twitter:description" content="PreparationA widely used asymmetric circle grid pattern can be found in doc of OpenCV 2.4. Same as previous blogs, the camera needs to be calibrated beforehand. For this asymmetric circle grid example">
<meta name="twitter:image" content="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/pattern_acircles.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-opencv-external-posture-estimation-circle-grid" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/14/opencv-external-posture-estimation-circle-grid/" class="article-date">
  <time datetime="2017-03-14T07:00:00.000Z" itemprop="datePublished">2017-03-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Camera Posture Estimation Using Circle Grid Pattern
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h1><p>A widely used asymmetric circle grid pattern can be found in <a href="http://docs.opencv.org/2.4/_downloads/acircles_pattern.png" target="_blank" rel="noopener">doc of OpenCV 2.4</a>. Same as previous blogs, the camera needs to be calibrated beforehand. For this asymmetric circle grid example, a sequence of images (instead of a video stream) is tested.</p>
<h1 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h1><p>The code can be found at <a href="https://github.com/LongerVision/OpenCV_Examples/blob/master/02_external_camera_posture_estimation/circle_grid.py" target="_blank" rel="noopener">OpenCV Examples</a>.</p>
<h2 id="First-of-all"><a href="#First-of-all" class="headerlink" title="First of all"></a>First of all</h2><p>We need to ensure <strong>cv2.so</strong> is under our system path. <strong>cv2.so</strong> is specifically for OpenCV Python.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">'/usr/local/python/3.5'</span>)</span><br></pre></td></tr></table></figure>
<p>Then, we import some packages to be used (<strong>NO ArUco</strong>).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h2 id="Secondly"><a href="#Secondly" class="headerlink" title="Secondly"></a>Secondly</h2><p>We now load all camera calibration parameters, including: <strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. For example, your code might look like the following:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">calibrationFile = <span class="string">"calibrationFileName.xml"</span></span><br><span class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</span><br><span class="line">camera_matrix = calibrationParams.getNode(<span class="string">"cameraMatrix"</span>).mat()</span><br><span class="line">dist_coeffs = calibrationParams.getNode(<span class="string">"distCoeffs"</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Since we are testing a calibrated fisheye camera, two extra parameters are to be loaded from the calibration file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = calibrationParams.getNode(<span class="string">"R"</span>).mat()</span><br><span class="line">new_camera_matrix = calibrationParams.getNode(<span class="string">"newCameraMatrix"</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Afterwards, two mapping matrices are pre-calculated by calling function <a href="http://docs.opencv.org/trunk/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a" target="_blank" rel="noopener">cv2.fisheye.initUndistortRectifyMap()</a> as (supposing the images to be processed are of 1080P):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_size = (<span class="number">1920</span>, <span class="number">1080</span>)</span><br><span class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</span><br></pre></td></tr></table></figure>
<h2 id="Thirdly"><a href="#Thirdly" class="headerlink" title="Thirdly"></a>Thirdly</h2><p>The circle pattern is to be loaded.</p>
<p><img src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/pattern_acircles.png" alt="asymmetric_circle_grid"></p>
<p>Here in our case, this asymmetric circle grid pattern is manually loaded as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Original blob coordinates</span></span><br><span class="line">objectPoints = np.zeros((<span class="number">44</span>, <span class="number">3</span>))  <span class="comment"># In this asymmetric circle grid, 44 circles are adopted.</span></span><br><span class="line">objectPoints[<span class="number">0</span>]  = (<span class="number">0</span>  , <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">1</span>]  = (<span class="number">0</span>  , <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">2</span>]  = (<span class="number">0</span>  , <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">3</span>]  = (<span class="number">0</span>  , <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">4</span>]  = (<span class="number">36</span> , <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">5</span>]  = (<span class="number">36</span> , <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">6</span>]  = (<span class="number">36</span> , <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">7</span>]  = (<span class="number">36</span> , <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">8</span>]  = (<span class="number">72</span> , <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">9</span>]  = (<span class="number">72</span> , <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">10</span>] = (<span class="number">72</span> , <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">11</span>] = (<span class="number">72</span> , <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">12</span>] = (<span class="number">108</span>, <span class="number">36</span>,  <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">13</span>] = (<span class="number">108</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">14</span>] = (<span class="number">108</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">15</span>] = (<span class="number">108</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">16</span>] = (<span class="number">144</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">17</span>] = (<span class="number">144</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">18</span>] = (<span class="number">144</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">19</span>] = (<span class="number">144</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">20</span>] = (<span class="number">180</span>, <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">21</span>] = (<span class="number">180</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">22</span>] = (<span class="number">180</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">23</span>] = (<span class="number">180</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">24</span>] = (<span class="number">216</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">25</span>] = (<span class="number">216</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">26</span>] = (<span class="number">216</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">27</span>] = (<span class="number">216</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">28</span>] = (<span class="number">252</span>, <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">29</span>] = (<span class="number">252</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">30</span>] = (<span class="number">252</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">31</span>] = (<span class="number">252</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">32</span>] = (<span class="number">288</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">33</span>] = (<span class="number">288</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">34</span>] = (<span class="number">288</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">35</span>] = (<span class="number">288</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">36</span>] = (<span class="number">324</span>, <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">37</span>] = (<span class="number">324</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">38</span>] = (<span class="number">324</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">39</span>] = (<span class="number">324</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">40</span>] = (<span class="number">360</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">41</span>] = (<span class="number">360</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">42</span>] = (<span class="number">360</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">43</span>] = (<span class="number">360</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>In our case, the distance between two neighbour circle centres (in the same column) is measured as 72 centimetres. Meanwhile, the axis at the origin is loaded as well, with respective length 300, 200, 100 centimetres.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">axis = np.float32([[<span class="number">360</span>,<span class="number">0</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">240</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">0</span>,<span class="number">-120</span>]]).reshape(<span class="number">-1</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Fourthly"><a href="#Fourthly" class="headerlink" title="Fourthly"></a>Fourthly</h2><p>Since we are going to use OpenCV’s SimpleBlobDetector for the blob detection, the SimpleBlobDetector’s parameters are to be created beforehand. The parameter values can be adjusted according to your own testing environments. The iteration <strong>criteria</strong> for the simple blob detection is also created at the same time.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup SimpleBlobDetector parameters.</span></span><br><span class="line">blobParams = cv2.SimpleBlobDetector_Params()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change thresholds</span></span><br><span class="line">blobParams.minThreshold = <span class="number">8</span></span><br><span class="line">blobParams.maxThreshold = <span class="number">255</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Area.</span></span><br><span class="line">blobParams.filterByArea = <span class="keyword">True</span></span><br><span class="line">blobParams.minArea = <span class="number">64</span>     <span class="comment"># minArea may be adjusted to suit for your experiment</span></span><br><span class="line">blobParams.maxArea = <span class="number">2500</span>   <span class="comment"># maxArea may be adjusted to suit for your experiment</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Circularity</span></span><br><span class="line">blobParams.filterByCircularity = <span class="keyword">True</span></span><br><span class="line">blobParams.minCircularity = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Convexity</span></span><br><span class="line">blobParams.filterByConvexity = <span class="keyword">True</span></span><br><span class="line">blobParams.minConvexity = <span class="number">0.87</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Inertia</span></span><br><span class="line">blobParams.filterByInertia = <span class="keyword">True</span></span><br><span class="line">blobParams.minInertiaRatio = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a detector with the parameters</span></span><br><span class="line">blobDetector = cv2.SimpleBlobDetector_create(blobParams)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the iteration criteria</span></span><br><span class="line">criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, <span class="number">30</span>, <span class="number">0.001</span>)</span><br><span class="line"><span class="comment">###################################################################################################</span></span><br></pre></td></tr></table></figure>
<h2 id="Finally"><a href="#Finally" class="headerlink" title="Finally"></a>Finally</h2><p>Estimate camera postures. Here, we are testing a sequence of images, rather than video streams. We first list all file names in sequence.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">imgDir = <span class="string">"imgSequence"</span>  <span class="comment"># Specify the image directory</span></span><br><span class="line">imgFileNames = [os.path.join(imgDir, fn) <span class="keyword">for</span> fn <span class="keyword">in</span> next(os.walk(imgDir))[<span class="number">2</span>]]</span><br><span class="line">nbOfImgs = len(imgFileNames)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, nbOfImgs<span class="number">-1</span>):</span><br><span class="line">    img = cv2.imread(imgFileNames[i], cv2.IMREAD_COLOR)</span><br><span class="line">    imgRemapped = cv2.remap(img, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT) <span class="comment"># for fisheye remapping</span></span><br><span class="line">    imgRemapped_gray = cv2.cvtColor(imgRemapped, cv2.COLOR_BGR2GRAY)    <span class="comment"># blobDetector.detect() requires gray image</span></span><br><span class="line"></span><br><span class="line">    keypoints = blobDetector.detect(imgRemapped_gray) <span class="comment"># Detect blobs.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Draw detected blobs as red circles. This helps cv2.findCirclesGrid() .</span></span><br><span class="line">    im_with_keypoints = cv2.drawKeypoints(imgRemapped, keypoints, np.array([]), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class="line">    im_with_keypoints_gray = cv2.cvtColor(im_with_keypoints, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    ret, corners = cv2.findCirclesGrid(im_with_keypoints, (<span class="number">4</span>,<span class="number">11</span>), <span class="keyword">None</span>, flags = cv2.CALIB_CB_ASYMMETRIC_GRID)   <span class="comment"># Find the circle grid</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="keyword">True</span>:</span><br><span class="line">        corners2 = cv2.cornerSubPix(im_with_keypoints_gray, corners, (<span class="number">11</span>,<span class="number">11</span>), (<span class="number">-1</span>,<span class="number">-1</span>), criteria)    <span class="comment"># Refines the corner locations.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Draw and display the corners.</span></span><br><span class="line">        im_with_keypoints = cv2.drawChessboardCorners(imLeftRemapped, (<span class="number">4</span>,<span class="number">11</span>), corners2, ret)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3D posture</span></span><br><span class="line">        <span class="keyword">if</span> len(corners2) == len(objectPoints):</span><br><span class="line">            retval, rvec, tvec = cv2.solvePnP(objectPoints, corners2, camera_matrix, dist_coeffs)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> retval:</span><br><span class="line">            projectedPoints, jac = cv2.projectPoints(objectPoints, rvec, tvec, camera_matrix, dist_coeffs)  <span class="comment"># project 3D points to image plane</span></span><br><span class="line">            projectedAxis, jacAsix = cv2.projectPoints(axis, rvec, tvec, camera_matrix, dist_coeffs)    <span class="comment"># project axis to image plane</span></span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> projectedPoints:</span><br><span class="line">                p = np.int32(p).reshape(<span class="number">-1</span>,<span class="number">2</span>)</span><br><span class="line">                cv2.circle(im_with_keypoints, (p[<span class="number">0</span>][<span class="number">0</span>], p[<span class="number">0</span>][<span class="number">1</span>]), <span class="number">3</span>, (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>))</span><br><span class="line">            origin = tuple(corners2[<span class="number">0</span>].ravel())</span><br><span class="line">            im_with_keypoints = cv2.line(im_with_keypoints, origin, tuple(projectedAxis[<span class="number">0</span>].ravel()), (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">            im_with_keypoints = cv2.line(im_with_keypoints, origin, tuple(projectedAxis[<span class="number">1</span>].ravel()), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">            im_with_keypoints = cv2.line(im_with_keypoints, origin, tuple(projectedAxis[<span class="number">2</span>].ravel()), (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    cv2.imshow(<span class="string">"circlegrid"</span>, im_with_keypoints) <span class="comment"># display</span></span><br><span class="line"></span><br><span class="line">    cv2.waitKey(<span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<p>The drawn axis is just the world coordinators and orientations estimated from the images taken by the testing camera.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/03/14/opencv-external-posture-estimation-circle-grid/" data-id="cjign9l0s000fnxy79faol1ed" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Camera-Posture-Estimation-Circle-Grid-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, Circle Grid, Marker, Pattern, OpenCV, Python</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/03/15/OpenCV Python ArUco Documentation/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          OpenCV Python ArUco Documentation
        
      </div>
    </a>
  
  
    <a href="/2017/03/13/opencv-external-posture-estimation-ChArUco-board/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Camera Posture Estimation Using A ChArUco Board</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ArUco-Marker-Pattern-OpenCV-Python/">ArUco, Marker, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Beaglebone-Beaglebone-Black-Linaro-GCC-U-Boot-Linux-Kernel-BSP/">Beaglebone, Beaglebone Black, Linaro GCC, U-Boot, Linux Kernel, BSP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN-PyTorch-Anaconda-Deep-Learning-Machine-Learning/">CNN, PyTorch, Anaconda, Deep Learning, Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Calibration-Chessboard-Marker-Pattern-OpenCV-Python/">Camera Calibration, Chessboard, Marker, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Calibration-Circle-Grid-Marker-Pattern-OpenCV-Python/">Camera Calibration, Circle Grid, Marker, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Posture-Estimation-ArUco-Board-Pattern-OpenCV-Python/">Camera Posture Estimation, ArUco Board, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Posture-Estimation-ArUco-Diamond-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, ArUco, Diamond Marker, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Posture-Estimation-ArUco-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, ArUco, Marker, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Posture-Estimation-ChArUco-Board-Pattern-OpenCV-Python/">Camera Posture Estimation, ChArUco Board, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Posture-Estimation-Circle-Grid-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, Circle Grid, Marker, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Longer-Vision-Technology-Computer-Vision-Machine-Vision/">Longer Vision Technology, Computer Vision, Machine Vision</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NanoPi-NEO-AllWinner-H3-Armbian-Debian-BSP/">NanoPi NEO, AllWinner H3, Armbian, Debian, BSP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Orange-Pi-Plus-2-AllWinner-H3-Armbian-Ubuntu-Mainline-Linux-Kernel-BSP/">Orange Pi Plus 2, AllWinner H3, Armbian, Ubuntu, Mainline Linux Kernel, BSP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dd-wrt-Wireless-Repeater-Bridge/">dd-wrt, Wireless, Repeater Bridge</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ArUco-Marker-Pattern-OpenCV-Python/" style="font-size: 10px;">ArUco, Marker, Pattern, OpenCV, Python</a> <a href="/tags/Beaglebone-Beaglebone-Black-Linaro-GCC-U-Boot-Linux-Kernel-BSP/" style="font-size: 10px;">Beaglebone, Beaglebone Black, Linaro GCC, U-Boot, Linux Kernel, BSP</a> <a href="/tags/CNN-PyTorch-Anaconda-Deep-Learning-Machine-Learning/" style="font-size: 10px;">CNN, PyTorch, Anaconda, Deep Learning, Machine Learning</a> <a href="/tags/Camera-Calibration-Chessboard-Marker-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Calibration, Chessboard, Marker, Pattern, OpenCV, Python</a> <a href="/tags/Camera-Calibration-Circle-Grid-Marker-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Calibration, Circle Grid, Marker, Pattern, OpenCV, Python</a> <a href="/tags/Camera-Posture-Estimation-ArUco-Board-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Posture Estimation, ArUco Board, Pattern, OpenCV, Python</a> <a href="/tags/Camera-Posture-Estimation-ArUco-Diamond-Marker-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Posture Estimation, ArUco, Diamond Marker, Pattern, OpenCV, Python</a> <a href="/tags/Camera-Posture-Estimation-ArUco-Marker-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Posture Estimation, ArUco, Marker, Pattern, OpenCV, Python</a> <a href="/tags/Camera-Posture-Estimation-ChArUco-Board-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Posture Estimation, ChArUco Board, Pattern, OpenCV, Python</a> <a href="/tags/Camera-Posture-Estimation-Circle-Grid-Marker-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Posture Estimation, Circle Grid, Marker, Pattern, OpenCV, Python</a> <a href="/tags/Longer-Vision-Technology-Computer-Vision-Machine-Vision/" style="font-size: 10px;">Longer Vision Technology, Computer Vision, Machine Vision</a> <a href="/tags/NanoPi-NEO-AllWinner-H3-Armbian-Debian-BSP/" style="font-size: 10px;">NanoPi NEO, AllWinner H3, Armbian, Debian, BSP</a> <a href="/tags/Orange-Pi-Plus-2-AllWinner-H3-Armbian-Ubuntu-Mainline-Linux-Kernel-BSP/" style="font-size: 10px;">Orange Pi Plus 2, AllWinner H3, Armbian, Ubuntu, Mainline Linux Kernel, BSP</a> <a href="/tags/dd-wrt-Wireless-Repeater-Bridge/" style="font-size: 10px;">dd-wrt, Wireless, Repeater Bridge</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/04/01/CNN-by-PyTorch-via-Anaconda/">CNN by PyTorch via Anaconda</a>
          </li>
        
          <li>
            <a href="/2018/03/02/setup-repeater-bridge-using-a-dd-wrt-router/">Setup Repeater Bridge Using A dd-wrt Router</a>
          </li>
        
          <li>
            <a href="/2018/02/27/orange-pi-plus-2-armbian/">Install Armbian Ubuntu Desktop with the Newest Supported Mainline Linux Kernel onto Orange Pi Plus 2</a>
          </li>
        
          <li>
            <a href="/2018/02/24/nanopi-neo-armbian/">Install Armbian Debian Server onto NanoPi NEO</a>
          </li>
        
          <li>
            <a href="/2018/01/10/beaglebone-black-uboot-kernel/">Build U-Boot and Linux Kernel for Beaglebone and Beaglebone Black</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>