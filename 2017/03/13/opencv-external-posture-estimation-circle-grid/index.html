<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Camera Posture Estimation Using Circle Grid Pattern | Longer Vision</title>
  <meta name="author" content="Nobody">
  
  <meta name="description" content="PreparationA widely used asymmetric circle grid pattern can be found in doc of OpenCV 2.4. Same as previous blogs, the camera needs to be calibrated b">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Camera Posture Estimation Using Circle Grid Pattern"/>
  <meta property="og:site_name" content="Longer Vision"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Longer Vision" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Longer Vision</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-13T19:34:54.000Z"><a href="/2017/03/13/opencv-external-posture-estimation-circle-grid/">2017-03-13</a></time>
      
      
  
    <h1 class="title">Camera Posture Estimation Using Circle Grid Pattern</h1>
  

    </header>
    <div class="entry">
      
        <p></p><h2>Preparation</h2><br>A widely used asymmetric circle grid pattern can be found in <a href="http://docs.opencv.org/2.4/_downloads/acircles_pattern.png" target="_blank" rel="external">doc of OpenCV 2.4</a>. Same as previous blogs, the camera needs to be calibrated beforehand. For this asymmetric circle grid example, a sequence of images (instead of a video stream) is tested.<p></p>
<p></p><h2>Coding</h2><br>The code can be found at <a href="https://github.com/LongerVision/OpenCV_Examples/blob/master/02_external_camera_posture_estimation/circle_grid.py" target="_blank" rel="external">OpenCV Examples</a>.<p></p>
<p></p><h3>First of all</h3><br>We need to ensure <strong>cv2.so</strong> is under our system path. <strong>cv2.so</strong> is specifically for OpenCV Python.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">import sys</div><div class="line">sys.path.append(&apos;/usr/local/python/3.5&apos;)</div></pre></td></tr></table></figure><p></p>
<p>Then, we import some packages to be used (<strong>NO ArUco</strong>).<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">import os</div><div class="line">import cv2</div><div class="line">import numpy as np</div></pre></td></tr></table></figure></p>
<p></p><h3>Secondly</h3><br>We now load all camera calibration parameters, including: <strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. For example, your code might look like the following:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">calibrationFile = &quot;calibrationFileName.xml&quot;</div><div class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</div><div class="line">camera_matrix = calibrationParams.getNode(&quot;cameraMatrix&quot;).mat()</div><div class="line">dist_coeffs = calibrationParams.getNode(&quot;distCoeffs&quot;).mat()</div></pre></td></tr></table></figure><p></p>
<p>Since we are testing a calibrated fisheye camera, two extra parameters are to be loaded from the calibration file.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">r = calibrationParams.getNode(&quot;R&quot;).mat()</div><div class="line">new_camera_matrix = calibrationParams.getNode(&quot;newCameraMatrix&quot;).mat()</div></pre></td></tr></table></figure></p>
<p>Afterwards, two mapping matrices are pre-calculated by calling function <a href="http://docs.opencv.org/trunk/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a" target="_blank" rel="external">cv2.fisheye.initUndistortRectifyMap()</a> as (supposing the images to be processed are of 1080P):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">image_size = (1920, 1080)</div><div class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</div></pre></td></tr></table></figure></p>
<p></p><h3>Thirdly</h3><br>The circle pattern is to be loaded.<br><img src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/pattern_acircles.png" alt="asymmetric_circle_grid" title="asymmetric_circle_grid"><br>Here in our case, this asymmetric circle grid pattern is manually loaded as follows:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"># Original blob coordinates</div><div class="line">objectPoints = np.zeros((44, 3))  # In this asymmetric circle grid, 44 circles are adopted.</div><div class="line">objectPoints[0]  = (0  , 0  , 0)</div><div class="line">objectPoints[1]  = (0  , 72 , 0)</div><div class="line">objectPoints[2]  = (0  , 144, 0)</div><div class="line">objectPoints[3]  = (0  , 216, 0)</div><div class="line">objectPoints[4]  = (36 , 36 , 0)</div><div class="line">objectPoints[5]  = (36 , 108, 0)</div><div class="line">objectPoints[6]  = (36 , 180, 0)</div><div class="line">objectPoints[7]  = (36 , 252, 0)</div><div class="line">objectPoints[8]  = (72 , 0  , 0)</div><div class="line">objectPoints[9]  = (72 , 72 , 0)</div><div class="line">objectPoints[10] = (72 , 144, 0)</div><div class="line">objectPoints[11] = (72 , 216, 0)</div><div class="line">objectPoints[12] = (108, 36,  0)</div><div class="line">objectPoints[13] = (108, 108, 0)</div><div class="line">objectPoints[14] = (108, 180, 0)</div><div class="line">objectPoints[15] = (108, 252, 0)</div><div class="line">objectPoints[16] = (144, 0  , 0)</div><div class="line">objectPoints[17] = (144, 72 , 0)</div><div class="line">objectPoints[18] = (144, 144, 0)</div><div class="line">objectPoints[19] = (144, 216, 0)</div><div class="line">objectPoints[20] = (180, 36 , 0)</div><div class="line">objectPoints[21] = (180, 108, 0)</div><div class="line">objectPoints[22] = (180, 180, 0)</div><div class="line">objectPoints[23] = (180, 252, 0)</div><div class="line">objectPoints[24] = (216, 0  , 0)</div><div class="line">objectPoints[25] = (216, 72 , 0)</div><div class="line">objectPoints[26] = (216, 144, 0)</div><div class="line">objectPoints[27] = (216, 216, 0)</div><div class="line">objectPoints[28] = (252, 36 , 0)</div><div class="line">objectPoints[29] = (252, 108, 0)</div><div class="line">objectPoints[30] = (252, 180, 0)</div><div class="line">objectPoints[31] = (252, 252, 0)</div><div class="line">objectPoints[32] = (288, 0  , 0)</div><div class="line">objectPoints[33] = (288, 72 , 0)</div><div class="line">objectPoints[34] = (288, 144, 0)</div><div class="line">objectPoints[35] = (288, 216, 0)</div><div class="line">objectPoints[36] = (324, 36 , 0)</div><div class="line">objectPoints[37] = (324, 108, 0)</div><div class="line">objectPoints[38] = (324, 180, 0)</div><div class="line">objectPoints[39] = (324, 252, 0)</div><div class="line">objectPoints[40] = (360, 0  , 0)</div><div class="line">objectPoints[41] = (360, 72 , 0)</div><div class="line">objectPoints[42] = (360, 144, 0)</div><div class="line">objectPoints[43] = (360, 216, 0)</div></pre></td></tr></table></figure><p></p>
<p>In our case, the distance between two neighbour circle centres (in the same column) is measured as 72 centimetres. Meanwhile, the axis at the origin is loaded as well, with respective length 300, 200, 100 centimetres.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">axis = np.float32([[360,0,0], [0,240,0], [0,0,-120]]).reshape(-1,3)</div></pre></td></tr></table></figure></p>
<p></p><h3>Fourthly</h3><br>Since we are going to use OpenCV’s SimpleBlobDetector for the blob detection, the SimpleBlobDetector’s parameters are to be created beforehand. The parameter values can be adjusted according to your own testing environments. The iteration <strong>criteria</strong> for the simple blob detection is also created at the same time.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"># Setup SimpleBlobDetector parameters.</div><div class="line">blobParams = cv2.SimpleBlobDetector_Params()</div><div class="line"></div><div class="line"># Change thresholds</div><div class="line">blobParams.minThreshold = 8</div><div class="line">blobParams.maxThreshold = 255</div><div class="line"></div><div class="line"># Filter by Area.</div><div class="line">blobParams.filterByArea = True</div><div class="line">blobParams.minArea = 64     # minArea may be adjusted to suit for your experiment</div><div class="line">blobParams.maxArea = 2500   # maxArea may be adjusted to suit for your experiment</div><div class="line"></div><div class="line"># Filter by Circularity</div><div class="line">blobParams.filterByCircularity = True</div><div class="line">blobParams.minCircularity = 0.1</div><div class="line"></div><div class="line"># Filter by Convexity</div><div class="line">blobParams.filterByConvexity = True</div><div class="line">blobParams.minConvexity = 0.87</div><div class="line"></div><div class="line"># Filter by Inertia</div><div class="line">blobParams.filterByInertia = True</div><div class="line">blobParams.minInertiaRatio = 0.01</div><div class="line"></div><div class="line"># Create a detector with the parameters</div><div class="line">blobDetector = cv2.SimpleBlobDetector_create(blobParams)</div><div class="line"></div><div class="line"># Create the iteration criteria</div><div class="line">criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)</div><div class="line">###################################################################################################</div></pre></td></tr></table></figure><p></p>
<p></p><h3>Finally</h3><br>Estimate camera postures. Here, we are testing a sequence of images, rather than video streams. We first list all file names in sequence.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">imgDir = &quot;imgSequence&quot;  # Specify the image directory</div><div class="line">imgFileNames = [os.path.join(imgDir, fn) for fn in next(os.walk(imgDir))[2]]</div><div class="line">nbOfImgs = len(imgFileNames)</div></pre></td></tr></table></figure><p></p>
<p>Then, we calculate the camera posture frame by frame:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">for i in range(0, nbOfImgs-1):</div><div class="line">    img = cv2.imread(imgFileNames[i], cv2.IMREAD_COLOR)</div><div class="line">    imgRemapped = cv2.remap(img, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT) # for fisheye remapping</div><div class="line">    imgRemapped_gray = cv2.cvtColor(imgRemapped, cv2.COLOR_BGR2GRAY)    # blobDetector.detect() requires gray image</div><div class="line"></div><div class="line">    keypoints = blobDetector.detect(imgRemapped_gray) # Detect blobs.</div><div class="line"></div><div class="line">    # Draw detected blobs as red circles. This helps cv2.findCirclesGrid() .</div><div class="line">    im_with_keypoints = cv2.drawKeypoints(imgRemapped, keypoints, np.array([]), (0,255,0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</div><div class="line">    im_with_keypoints_gray = cv2.cvtColor(im_with_keypoints, cv2.COLOR_BGR2GRAY)</div><div class="line">    ret, corners = cv2.findCirclesGrid(im_with_keypoints, (4,11), None, flags = cv2.CALIB_CB_ASYMMETRIC_GRID)   # Find the circle grid</div><div class="line"></div><div class="line">    if ret == True:</div><div class="line">        corners2 = cv2.cornerSubPix(im_with_keypoints_gray, corners, (11,11), (-1,-1), criteria)    # Refines the corner locations.</div><div class="line"></div><div class="line">        # Draw and display the corners.</div><div class="line">        im_with_keypoints = cv2.drawChessboardCorners(imLeftRemapped, (4,11), corners2, ret)</div><div class="line"></div><div class="line">        # 3D posture</div><div class="line">        if len(corners2) == len(objectPoints):</div><div class="line">            retval, rvec, tvec = cv2.solvePnP(objectPoints, corners2, camera_matrix, dist_coeffs)</div><div class="line"></div><div class="line">        if retval:</div><div class="line">            projectedPoints, jac = cv2.projectPoints(objectPoints, rvec, tvec, camera_matrix, dist_coeffs)  # project 3D points to image plane</div><div class="line">            projectedAxis, jacAsix = cv2.projectPoints(axis, rvec, tvec, camera_matrix, dist_coeffs)    # project axis to image plane</div><div class="line">            for p in projectedPoints:</div><div class="line">                p = np.int32(p).reshape(-1,2)</div><div class="line">                cv2.circle(im_with_keypoints, (p[0][0], p[0][1]), 3, (0,0,255))</div><div class="line">            origin = tuple(corners2[0].ravel())</div><div class="line">            im_with_keypoints = cv2.line(im_with_keypoints, origin, tuple(projectedAxis[0].ravel()), (255,0,0), 2)</div><div class="line">            im_with_keypoints = cv2.line(im_with_keypoints, origin, tuple(projectedAxis[1].ravel()), (0,255,0), 2)</div><div class="line">            im_with_keypoints = cv2.line(im_with_keypoints, origin, tuple(projectedAxis[2].ravel()), (0,0,255), 2)</div><div class="line"></div><div class="line">    cv2.imshow(&quot;circlegrid&quot;, im_with_keypoints) # display</div><div class="line"></div><div class="line">    cv2.waitKey(2)</div></pre></td></tr></table></figure></p>
<p>The drawn axis is just the world coordinators and orientations estimated from the images taken by the testing camera.</p>

      
    </div>
    <footer>
      
        
        
  
  <div class="tags">
    <a href="/tags/Camera-Posture-Estimation-Circle-Grid-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, Circle Grid, Marker, Pattern, OpenCV, Python</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">Kommentare</h1>

  
      <div id="fb-root"></div>
<script>
  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345";
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>

<div class="fb-comments" data-href="http://longervision.github.io/2017/03/13/opencv-external-posture-estimation-circle-grid/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div>
      
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Suche">
    <input type="hidden" name="q" value="site:longervision.github.io">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/tags/ArUco-Marker-Pattern-OpenCV-Python/">ArUco, Marker, Pattern, OpenCV, Python</a><small>1</small></li>
  
    <li><a href="/tags/Camera-Calibration-Chessboard-Marker-Pattern-OpenCV-Python/">Camera Calibration, Chessboard, Marker, Pattern, OpenCV, Python</a><small>1</small></li>
  
    <li><a href="/tags/Camera-Posture-Estimation-Circle-Grid-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, Circle Grid, Marker, Pattern, OpenCV, Python</a><small>1</small></li>
  
    <li><a href="/tags/Camera-Posture-Estimation-aruco-Board-Pattern-OpenCV-Python/">Camera Posture Estimation, aruco Board, Pattern, OpenCV, Python</a><small>1</small></li>
  
    <li><a href="/tags/Camera-Posture-Estimation-aruco-Diamond-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, aruco, Diamond Marker, Pattern, OpenCV, Python</a><small>1</small></li>
  
    <li><a href="/tags/Camera-Posture-Estimation-aruco-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, aruco, Marker, Pattern, OpenCV, Python</a><small>1</small></li>
  
    <li><a href="/tags/Camera-Posture-Estimation-charuco-Board-Pattern-OpenCV-Python/">Camera Posture Estimation, charuco Board, Pattern, OpenCV, Python</a><small>1</small></li>
  
    <li><a href="/tags/Longer-Vision-Technology-Computer-Vision-Machine-Vision/">Longer Vision Technology, Computer Vision, Machine Vision</a><small>1</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2017 Nobody
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>
