<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.0.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"longervision.ca","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.21.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Longer Vision Technology Github Blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Longer Vision Technology">
<meta property="og:url" content="http://longervision.ca/page/15/index.html">
<meta property="og:site_name" content="Longer Vision Technology">
<meta property="og:description" content="Longer Vision Technology Github Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Nobody">
<meta property="article:tag" content="Longer Vision, Computer Vision, AI, Machine Learning">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://longervision.ca/page/15/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/15/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Longer Vision Technology</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Longer Vision Technology</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Github Blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Nobody</p>
  <div class="site-description" itemprop="description">Longer Vision Technology Github Blog</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">150</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">41</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">139</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2018/01/10/SBCs/ARM/beaglebone-black-uboot-kernel/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Nobody">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Longer Vision Technology">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2018/01/10/SBCs/ARM/beaglebone-black-uboot-kernel/" class="post-title-link" itemprop="url">Build U-Boot and Linux Kernel for Beaglebone and Beaglebone Black</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2018-01-10 00:00:00" itemprop="dateCreated datePublished" datetime="2018-01-10T00:00:00-08:00">2018-01-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-28 17:33:45" itemprop="dateModified" datetime="2024-09-28T17:33:45-07:00">2024-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Single-Board-Computers/" itemprop="url" rel="index"><span itemprop="name">Single Board Computers</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Single-Board-Computers/ARM/" itemprop="url" rel="index"><span itemprop="name">ARM</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Happy new year everybody. How time flies. It is already 2018. <a
target="_blank" rel="noopener" href="http://www.longervision.com/">Longer Vision</a> has been
struggling on this tough road towards a successful enterprise.
Algorithms <strong>ONLY</strong> are <strong>NOT</strong> enough for
nowadays business. <a
target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Board_support_package">BSP (board
support package)</a> and <a
target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Integrated_circuit_design">IC
design</a> are a must for a successful business nowadays. Thus, ever
since 2018, <a target="_blank" rel="noopener" href="http://www.longervision.com/">Longer Vision</a> is
going to balance <strong>both</strong> hardware <strong>and</strong>
software, particularly, <a target="_blank" rel="noopener" href="http://www.arm.com/">ARM</a> based open
source embedded development board and computer vision algorithms.</p>
<p>In this blog, we are going to talk about how to build and flash <a
target="_blank" rel="noopener" href="http://www.denx.de/wiki/U-Boot/WebHome">U-Boot</a> and <a
target="_blank" rel="noopener" href="https://www.kernel.org/">Linux Kernel</a> onto a <a
target="_blank" rel="noopener" href="https://beagleboard.org/bone-original">Beaglebone</a> and <a
target="_blank" rel="noopener" href="https://beagleboard.org/black">Beaglebone Black</a>, which adopts
<a
target="_blank" rel="noopener" href="http://www.ti.com/processors/sitara/arm-cortex-a8/am335x/overview.html">TI
AM335x</a> as its CPU. The board looks like (cited from <a
target="_blank" rel="noopener" href="https://beagleboard.org/black">Beaglebone Black</a> ):</p>
<figure>
<img
src="https://raw.githubusercontent.com/LongerVision/Resource/master/Embedded/ti/omap/beaglebone/black/images/BBB.jpg"
alt="Beaglebone Black" />
<figcaption aria-hidden="true">Beaglebone Black</figcaption>
</figure>
<h1 id="part-a-cross-compile-u-boot-and-linux-kernel">PART A: Cross
Compile U-Boot and Linux Kernel</h1>
<h2 id="linaro-gcc">1. Linaro GCC</h2>
<p><a target="_blank" rel="noopener" href="https://www.linaro.org/">Linaro</a> is a popular platform
providing high-quality code for both <a
target="_blank" rel="noopener" href="https://www.kernel.org/">Linux kernel</a> and <a
target="_blank" rel="noopener" href="https://developer.arm.com/open-source/gnu-toolchain/gnu-rm">GCC
tool chain</a>. Linaro's GCC toolchain of varoius versions can be
directly found <a
target="_blank" rel="noopener" href="https://releases.linaro.org/components/toolchain/binaries/">here</a>.</p>
<p>Here, we download GCC latest-6 binary under <a
target="_blank" rel="noopener" href="https://releases.linaro.org/components/toolchain/binaries/latest-6/arm-linux-gnueabihf/">arm-linux-gnueabihf</a>.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ wget -c </span><br><span class="line">https://releases.linaro.org/components/toolchain/binaries/latest-6/arm-linux-gnueabihf/gcc-linaro-6.4.1-2017.11-x86_64_arm-linux-gnueabihf.tar.xz</span><br><span class="line">$ tar xf gcc-linaro-6.4.1-2017.11-x86_64_arm-linux-gnueabihf.tar.xz</span><br><span class="line">$ <span class="built_in">export</span> CC=`<span class="built_in">pwd</span>`/gcc-linaro-6.4.1-2017.11-x86_64_arm-linux-gnueabihf/bin/arm-linux-gnueabihf-</span><br></pre></td></tr></table></figure>
<p>Test the cross compiler:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="variable">$&#123;CC&#125;</span>gcc --version</span><br><span class="line">arm-linux-gnueabihf-gcc (Linaro GCC 6.4-2017.11) 6.4.1 20171012</span><br><span class="line">Copyright (C) 2017 Free Software Foundation, Inc.</span><br><span class="line">This is free software; see the <span class="built_in">source</span> <span class="keyword">for</span> copying conditions.  There is NO</span><br><span class="line">warranty; not even <span class="keyword">for</span> MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</span><br></pre></td></tr></table></figure>
<h2 id="u-boot">2. U-Boot</h2>
<p><a target="_blank" rel="noopener" href="http://www.denx.de/wiki/U-Boot">U-Boot</a> is a universal
boot loader. For <a
target="_blank" rel="noopener" href="https://beagleboard.org/bone-original">Beaglebone</a> and <a
target="_blank" rel="noopener" href="https://beagleboard.org/black">Beaglebone Black</a>, there are two
patches which has been maintained by <a
target="_blank" rel="noopener" href="http://eewiki.net/display/linuxonarm">eewiki Linux on ARM</a> on
<a target="_blank" rel="noopener" href="https://github.com/eewiki/u-boot-patches">github</a>. We first
download U-Boot and check out the latest release as follows:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/u-boot/u-boot</span><br><span class="line">$ <span class="built_in">cd</span> u-boot/</span><br><span class="line">$ git checkout v2018.01</span><br></pre></td></tr></table></figure>
<p>Then check out the latest <a
target="_blank" rel="noopener" href="https://github.com/eewiki/u-boot-patches">u-boot-patches</a> and
patch two files under the latest release <a
target="_blank" rel="noopener" href="https://github.com/eewiki/u-boot-patches/tree/master/v2018.01">v2018.01</a>:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ../</span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/eewiki/u-boot-patches.git</span><br><span class="line">$ <span class="built_in">cd</span> ./u-boot-patches/v2018.01</span><br><span class="line">$ <span class="built_in">cp</span> 0001-am335x_evm-uEnv.txt-bootz-n-fixes.patch ../../u-boot/</span><br><span class="line">$ <span class="built_in">cp</span> 0002-U-Boot-BeagleBone-Cape-Manager.patch ../../u-boot/</span><br><span class="line">$ <span class="built_in">cd</span> ../../u-boot</span><br><span class="line">$ patch -p1 &lt; 0001-am335x_evm-uEnv.txt-bootz-n-fixes.patch</span><br><span class="line">$ patch -p1 &lt; 0002-U-Boot-BeagleBone-Cape-Manager.patch</span><br></pre></td></tr></table></figure>
<p>Finally, we configure and build U-Boot for <a
target="_blank" rel="noopener" href="https://beagleboard.org/bone-original">Beaglebone</a> and <a
target="_blank" rel="noopener" href="https://beagleboard.org/black">Beaglebone Black</a> as
follows:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ make ARCH=arm CROSS_COMPILE=<span class="variable">$&#123;CC&#125;</span> distclean</span><br><span class="line">$ make ARCH=arm CROSS_COMPILE=<span class="variable">$&#123;CC&#125;</span> am335x_evm_defconfig</span><br><span class="line">$ make ARCH=arm CROSS_COMPILE=<span class="variable">$&#123;CC&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="linux-kernel">3. Linux Kernel</h2>
<p>Due to Robert Nelson's summary at <a
target="_blank" rel="noopener" href="http://eewiki.net/display/linuxonarm/BeagleBone+Black">eewiki</a>,
there are two ways to build <a
target="_blank" rel="noopener" href="https://beagleboard.org/bone-original">Beaglebone</a> and <a
target="_blank" rel="noopener" href="https://beagleboard.org/black">Beaglebone Black</a>: - <a
target="_blank" rel="noopener" href="https://github.com/RobertCNelson/bb-kernel">Mainline</a> - <a
target="_blank" rel="noopener" href="https://github.com/RobertCNelson/ti-linux-kernel-dev">TI
BSP</a></p>
<p>Their differences are: - bb-kernel: based on <a
target="_blank" rel="noopener" href="https://github.com/RobertCNelson/bb-kernel">mainline</a>, no-smp,
optimized for AM335x devices. - ti-linux-kernel-dev: based on <a
target="_blank" rel="noopener" href="https://github.com/RobertCNelson/ti-linux-kernel-dev">TI’s git
tree</a>, smp, optimized for AM335x/AM43xx/AM57x devices.</p>
<p>Here, we are going to use <a
target="_blank" rel="noopener" href="https://github.com/RobertCNelson/bb-kernel">Mainline</a> to build
our own Linux Kernel. We FIRST check out <a
target="_blank" rel="noopener" href="https://github.com/RobertCNelson/bb-kernel">Robert Nelson's
bb-kernel</a>.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/RobertCNelson/bb-kernel</span><br><span class="line">$ <span class="built_in">cd</span> bb-kernel/</span><br><span class="line">$ git checkout origin/am33x-v4.14 -b am33x-v4.14</span><br></pre></td></tr></table></figure>
<p>We then check out <a
target="_blank" rel="noopener" href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git">Linus
Torvalds' stable Linux Kernel</a>, which can be also tracked on <a
target="_blank" rel="noopener" href="https://github.com/torvalds/linux">github Torvalds Linux</a>. This
will take you quite a while.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git</span><br></pre></td></tr></table></figure>
<p>Now, it's the time to modify some of the configurations in .sh files
under the checked out branch <strong>am33x-v4.14</strong>.</p>
<h3 id="version.sh">1) version.sh</h3>
<p>Here, I'm using <strong>gcc_linaro_gnueabihf_6</strong> instead of
<strong>gcc_linaro_gnueabihf_7</strong>.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">toolchain=<span class="string">&quot;gcc_linaro_gnueabihf_6&quot;</span></span><br><span class="line"><span class="comment">#toolchain=&quot;gcc_linaro_gnueabihf_7&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="system.sh">2) system.sh</h3>
<p>A file named <strong>system.sh.sample</strong> has been provided for
us to configure accordingly. We FIRST do a copy.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cp</span> system.sh.sample system.sh</span><br></pre></td></tr></table></figure>
<p>Then, we manually re-specifying two MACROs: <strong>CC</strong> and
<strong>LINUX_GIT</strong>, respectively to two directories containing
the above downloaded Linaro GCC compiler and the current Torvalds' Linux
Kernel. We also specify <strong>MMC</strong> for TF/SD Card as
follows:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CC=.../gcc-linaro-6.4.1-2017.11-x86_64_arm-linux-gnueabihf/bin/arm-linux-gnueabihf-</span><br><span class="line">LINUX_GIT=.../linux-stable</span><br><span class="line">MMC=/dev/mmcblk0</span><br></pre></td></tr></table></figure>
<p>After the above configurations, we start building the Linux Kernel
using the following command line. This will probably take you one
hour.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./build_kernel.sh</span><br></pre></td></tr></table></figure>
<p>When you see this <strong>Kernel Configuration</strong> page,</p>
<figure>
<img
src="https://raw.githubusercontent.com/LongerVision/Resource/master/Embedded/ti/omap/beaglebone/black/images/kernelconfiguration.jpg"
alt="Kernel Configuration" />
<figcaption aria-hidden="true">Kernel Configuration</figcaption>
</figure>
<p><strong>Exit</strong> right away without any modification. And you
will see:</p>
<figure>
<img
src="https://raw.githubusercontent.com/LongerVision/Resource/master/Embedded/ti/omap/beaglebone/black/images/afterkernelconfiguration.jpg"
alt="After Kernel Configuration" />
<figcaption aria-hidden="true">After Kernel Configuration</figcaption>
</figure>
<p>After a while, you will see <strong>Linux Kernel</strong> has been
successfully built:</p>
<figure>
<img
src="https://raw.githubusercontent.com/LongerVision/Resource/master/Embedded/ti/omap/beaglebone/black/images/kernelbuilt.jpg"
alt="The Built Kernel" />
<figcaption aria-hidden="true">The Built Kernel</figcaption>
</figure>
<h2 id="root-file-system">4. Root File System</h2>
<p>We then install the latest Debian (for now, Debian 9.3) according to
Robert Nelson's minimal operating system. Three commands are to be
executed in a row for downloading, verifying, and extraction.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ wget -c https://rcn-ee.com/rootfs/eewiki/minfs/debian-9.3-minimal-armhf-2017-12-09.tar.xz</span><br><span class="line">$ <span class="built_in">sha256sum</span> debian-9.3-minimal-armhf-2017-12-09.tar.xz</span><br><span class="line">5120fcfb8ff8af013737fae52dc0a7ecc2f52563a9aa8f5aa288aff0f3943d61  debian-9.3-minimal-armhf-2017-12-09.tar.xz</span><br><span class="line">$ tar xf debian-9.3-minimal-armhf-2017-12-09.tar.xz</span><br></pre></td></tr></table></figure>
<p>Until now, most components for booting have been downloaded and
built. It is the time for us to flash our own OS onto a SD card.</p>
<h1 id="part-b-install-the-linux-os-onto-sd-card">PART B: Install the
Linux OS onto SD Card</h1>
<h2 id="setup-microsd-card">5. Setup microSD card</h2>
<h3 id="tf-card-preparation">1) TF Card Preparation</h3>
<p>We first check which block device that we are going to install our
built system onto by command <strong>lsblk</strong>.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ lsblk</span><br><span class="line">NAME    MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sdd       8:48   0 931.5G  0 disk </span><br><span class="line">└─sdd1    8:49   0 931.5G  0 part /media/jiapei/Data</span><br><span class="line">sdb       8:16   0 238.5G  0 disk </span><br><span class="line">├─sdb4    8:20   0   900M  0 part </span><br><span class="line">├─sdb2    8:18   0   128M  0 part </span><br><span class="line">├─sdb3    8:19   0 237.2G  0 part /media/jiapei/Win10</span><br><span class="line">└─sdb1    8:17   0   300M  0 part /boot/efi</span><br><span class="line">sr0      11:0    1  1024M  0 rom  </span><br><span class="line">sdc       8:32   0 238.5G  0 disk </span><br><span class="line">├─sdc2    8:34   0  30.5G  0 part [SWAP]</span><br><span class="line">├─sdc3    8:35   0 207.5G  0 part /</span><br><span class="line">└─sdc1    8:33   0   512M  0 part </span><br><span class="line">mmcblk0 179:0    0    15G  0 disk</span><br></pre></td></tr></table></figure>
<p>We then define a MACRO <strong>DISK</strong> to specify the TF card
device.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> DISK=/dev/mmcblk0</span><br></pre></td></tr></table></figure>
<p>Afterwards, erase partition table/labels on TF card by:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo <span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=<span class="variable">$&#123;DISK&#125;</span> bs=1M count=10</span><br></pre></td></tr></table></figure>
<h3 id="bootloader-installation">2) Bootloader installation</h3>
<p>Now, we install the built U-Boot onto the SD card:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo <span class="built_in">dd</span> <span class="keyword">if</span>=./u-boot/MLO of=<span class="variable">$&#123;DISK&#125;</span> count=1 seek=1 bs=128k</span><br><span class="line">$ sudo <span class="built_in">dd</span> <span class="keyword">if</span>=./u-boot/u-boot.img of=<span class="variable">$&#123;DISK&#125;</span> count=2 seek=1 bs=384k</span><br></pre></td></tr></table></figure>
<h3 id="partition-preparation">3) Partition Preparation</h3>
<p>We FIRST make sure which version of <strong>sfdisk</strong> is. In my
case, it is of version 2.27.1</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sfdisk --version</span><br><span class="line">sfdisk from util-linux 2.27.1</span><br></pre></td></tr></table></figure>
<p>Then we create the partition layout by:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sfdisk <span class="variable">$&#123;DISK&#125;</span> &lt;&lt;-<span class="string">__EOF__</span></span><br><span class="line"><span class="string">4M,,L,*</span></span><br><span class="line"><span class="string">__EOF__</span></span><br></pre></td></tr></table></figure>
<p>Afterwards, we need to format the created partition by
<strong>mkfs.ext4</strong>. We also need to make sure which version of
<strong>mkfs.ext4</strong> is. In my case, it is of version 1.42.13.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkfs.ext4 -V</span><br><span class="line">mke2fs 1.42.13 (17-May-2015)</span><br><span class="line">        Using EXT2FS Library version 1.42.13</span><br></pre></td></tr></table></figure>
<p>Then, we format the partition by:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mkfs.ext4 -L rootfs <span class="variable">$&#123;DISK&#125;</span>p1</span><br></pre></td></tr></table></figure>
<p>After formatting, the TF card should be able to be either
automatically mounted or manually mounted by the following command:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo <span class="built_in">mkdir</span> -p /media/rootfs/</span><br><span class="line">$ sudo mount <span class="variable">$&#123;DISK&#125;</span>p1 /media/rootfs/</span><br></pre></td></tr></table></figure>
<h3 id="backup-bootloader">4) Backup Bootloader</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo <span class="built_in">mkdir</span> -p /media/rootfs/opt/backup/uboot/</span><br><span class="line">$ sudo <span class="built_in">cp</span> -v ./u-boot/MLO /media/rootfs/opt/backup/uboot/</span><br><span class="line">$ sudo <span class="built_in">cp</span> -v ./u-boot/u-boot.img /media/rootfs/opt/backup/uboot/</span><br></pre></td></tr></table></figure>
<h3 id="dealing-with-old-bootloader-in-emmc-optional">5) Dealing with
old Bootloader in eMMC (Optional)</h3>
<p>If the old bootloader in eMMC is to be kept, please copy the
following file <strong>uEnv.txt</strong> to
/<strong>media/rootfs/</strong>.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##This will work with: Angstrom&#x27;s 2013.06.20 u-boot.</span></span><br><span class="line"> </span><br><span class="line">loadaddr=0x82000000</span><br><span class="line">fdtaddr=0x88000000</span><br><span class="line">rdaddr=0x88080000</span><br><span class="line"> </span><br><span class="line">initrd_high=0xffffffff</span><br><span class="line">fdt_high=0xffffffff</span><br><span class="line"> </span><br><span class="line"><span class="comment">#for single partitions:</span></span><br><span class="line">mmcroot=/dev/mmcblk0p1</span><br><span class="line"> </span><br><span class="line">loadximage=load mmc 0:1 <span class="variable">$&#123;loadaddr&#125;</span> /boot/vmlinuz-<span class="variable">$&#123;uname_r&#125;</span></span><br><span class="line">loadxfdt=load mmc 0:1 <span class="variable">$&#123;fdtaddr&#125;</span> /boot/dtbs/<span class="variable">$&#123;uname_r&#125;</span>/<span class="variable">$&#123;fdtfile&#125;</span></span><br><span class="line">loadxrd=load mmc 0:1 <span class="variable">$&#123;rdaddr&#125;</span> /boot/initrd.img-<span class="variable">$&#123;uname_r&#125;</span>; setenv rdsize <span class="variable">$&#123;filesize&#125;</span></span><br><span class="line">loaduEnvtxt=load mmc 0:1 <span class="variable">$&#123;loadaddr&#125;</span> /boot/uEnv.txt ; <span class="built_in">env</span> import -t <span class="variable">$&#123;loadaddr&#125;</span> <span class="variable">$&#123;filesize&#125;</span>;</span><br><span class="line">loadall=run loaduEnvtxt; run loadximage; run loadxfdt;</span><br><span class="line"> </span><br><span class="line">mmcargs=setenv bootargs console=tty0 console=<span class="variable">$&#123;console&#125;</span> <span class="variable">$&#123;optargs&#125;</span> <span class="variable">$&#123;cape_disable&#125;</span> <span class="variable">$&#123;cape_enable&#125;</span> root=<span class="variable">$&#123;mmcroot&#125;</span> rootfstype=<span class="variable">$&#123;mmcrootfstype&#125;</span> <span class="variable">$&#123;cmdline&#125;</span></span><br><span class="line"> </span><br><span class="line">uenvcmd=run loadall; run mmcargs; bootz <span class="variable">$&#123;loadaddr&#125;</span> - <span class="variable">$&#123;fdtaddr&#125;</span>;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">cp</span> -v ./uEnv.txt /media/rootfs/</span><br></pre></td></tr></table></figure>
<h2 id="kernel-installation">6. Kernel Installation</h2>
<h3 id="export-macro-kernel_version">1) Export MACRO kernel_version</h3>
<p>Under the folder <strong>bb-kernel</strong>, a file named
<strong>kernel_version</strong> was generated while building <a
target="_blank" rel="noopener" href="https://www.kernel.org/">Linux kernel</a>. In my case, I was
building the NEWEST kernel <strong>4.14.13-bone12</strong>. For
convenience, we export a new MACRO <strong>kernel_version</strong>.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cat</span> kernel_version </span><br><span class="line">4.14.13-bone12</span><br><span class="line">$ <span class="built_in">export</span> kernel_version=4.14.13-bone12</span><br></pre></td></tr></table></figure>
<h3 id="extract-debian-root-file-system-onto-tf-card">2) Extract Debian
Root File System onto TF Card</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo tar xfvp ./debian-9.3-minimal-armhf-2017-12-09/armhf-rootfs-debian-stretch.tar -C /media/rootfs/</span><br><span class="line">$ <span class="built_in">sync</span></span><br><span class="line">$ sudo <span class="built_in">chown</span> root:root /media/rootfs/</span><br><span class="line">$ sudo <span class="built_in">chmod</span> 755 /media/rootfs/</span><br></pre></td></tr></table></figure>
<h3 id="set-uname_r-in-bootuenv.txt">3) Set uname_r in
/boot/uEnv.txt</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sh -c <span class="string">&quot;echo &#x27;uname_r=<span class="variable">$&#123;kernel_version&#125;</span>&#x27; &gt;&gt; /media/rootfs/boot/uEnv.txt&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="copy-kernel-image">4) Copy Kernel Image</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo <span class="built_in">cp</span> -v ./bb-kernel/deploy/<span class="variable">$&#123;kernel_version&#125;</span>.zImage /media/rootfs/boot/vmlinuz-<span class="variable">$&#123;kernel_version&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="copy-kernel-device-tree-binaries">5) Copy Kernel Device Tree
Binaries</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo <span class="built_in">mkdir</span> -p /media/rootfs/boot/dtbs/<span class="variable">$&#123;kernel_version&#125;</span>/</span><br><span class="line">$ sudo tar xfv ./bb-kernel/deploy/<span class="variable">$&#123;kernel_version&#125;</span>-dtbs.tar.gz -C /media/rootfs/boot/dtbs/<span class="variable">$&#123;kernel_version&#125;</span>/</span><br></pre></td></tr></table></figure>
<h3 id="copy-kernel-modules">6) Copy Kernel Modules</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo tar xfv ./bb-kernel/deploy/<span class="variable">$&#123;kernel_version&#125;</span>-modules.tar.gz -C /media/rootfs/</span><br></pre></td></tr></table></figure>
<h3 id="set-file-systems-table-etcfstab">7) Set File Systems Table
(/etc/fstab)</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sh -c <span class="string">&quot;echo &#x27;/dev/mmcblk0p1  /  auto  errors=remount-ro  0  1&#x27; &gt;&gt; /media/rootfs/etc/fstab&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="networking">8) Networking</h3>
<p>To enable the Internet for the FIRST booting, we need to do the
network configuration:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo nano /media/rootfs/etc/network/interfaces</span><br></pre></td></tr></table></figure>
<p>Add the following content:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line"> </span><br><span class="line">auto eth0</span><br><span class="line">iface eth0 inet dhcp</span><br></pre></td></tr></table></figure>
<p>In order to use a shared SD card with multiple BeagleBones, and
always enable the Ethernet interface as <strong>eth0</strong>, we need
to add a particular <strong>udev rule</strong> as:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo nano /media/rootfs/etc/udev/rules.d/70-persistent-net.rules</span><br></pre></td></tr></table></figure>
<p>Add the following content:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># BeagleBone: net device ()</span></span><br><span class="line">SUBSYSTEM==<span class="string">&quot;net&quot;</span>, ACTION==<span class="string">&quot;add&quot;</span>, DRIVERS==<span class="string">&quot;?*&quot;</span>, ATTR&#123;dev_id&#125;==<span class="string">&quot;0x0&quot;</span>, ATTR&#123;<span class="built_in">type</span>&#125;==<span class="string">&quot;1&quot;</span>, KERNEL==<span class="string">&quot;eth*&quot;</span>, NAME=<span class="string">&quot;eth0&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="remove-tf-card">9) Remove TF Card</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">sync</span></span><br><span class="line">$ sudo umount /media/rootfs</span><br></pre></td></tr></table></figure>
<h1 id="part-c-configurations-after-booting-from-the-sd-card">PART C:
Configurations after Booting from the SD Card</h1>
<p>Insert TF card into a <a
target="_blank" rel="noopener" href="https://beagleboard.org/black">Beaglebone Black</a>, connect BBB
with an Internet cable, and connect a Micro HDMI cable on demand. After
the flashing of on-board LEDs, you should be able to find the IP address
of BBB via your router. All our future jobs are to be done via ssh
command through this IP address. My personal preference is to set a
static IP address for this particularly BBB in the router settings.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/18/ComputerVision/OpenCV/opencv-internal-calibration-circle-grid/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Nobody">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Longer Vision Technology">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/18/ComputerVision/OpenCV/opencv-internal-calibration-circle-grid/" class="post-title-link" itemprop="url">Camera Calibration Using a Circle Grid</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2017-03-18 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-18T00:00:00-07:00">2017-03-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-28 17:33:45" itemprop="dateModified" datetime="2024-09-28T17:33:45-07:00">2024-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="preparation">Preparation</h1>
<p>By reading two of our previous blogs <a
target="_blank" rel="noopener" href="https://longervision.github.io/2017/03/19/opencv-internal-calibration-chessboard/">Camera
Calibration Using a Chessboard</a> and <a
target="_blank" rel="noopener" href="https://longervision.github.io/2017/03/13/opencv-external-posture-estimation-circle-grid/">Camera
Posture Estimation Using Circle Grid Pattern</a>, it wouldn’t be hard to
replace the chessboard by a circle grid to calculate camera calibration
parameters.</p>
<h1 id="coding">Coding</h1>
<p>Our code can be found at <a
target="_blank" rel="noopener" href="https://github.com/LongerVision/OpenCV_Examples/blob/master/01_internal_camera_calibration/circle_grid.py">OpenCV
Examples</a>.</p>
<h2 id="first-of-all">First of all</h2>
<p>As mentioned in <a
target="_blank" rel="noopener" href="https://longervision.github.io/2017/03/19/opencv-internal-calibration-chessboard/">Camera
Calibration Using a Chessboard</a>, for intrinsic parameters estimation,
namely, camera calibration, there is <strong>NO</strong> need to measure
the circle unit size. And the circle gird is to be adopted is exactly
the same one as used in <a
target="_blank" rel="noopener" href="https://longervision.github.io/2017/03/13/opencv-external-posture-estimation-circle-grid/">Camera
Posture Estimation Using Circle Grid Pattern</a>:</p>
<figure>
<img
src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/pattern_acircles.png"
alt="asymmetric_circle_grid" />
<figcaption aria-hidden="true">asymmetric_circle_grid</figcaption>
</figure>
<h2 id="secondly">Secondly</h2>
<p>Required packages need to be imported.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> yam</span><br></pre></td></tr></table></figure>
<h2 id="thirdly">Thirdly</h2>
<p>Some initialization work need to be done, including: 1) define the
termination criteria when refine the corner sub-pixel later on; 2) blob
detection parameters; 3) object points coordinators initialization.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># termination criteria</span></span><br><span class="line">criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, <span class="number">30</span>, <span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">########################################Blob Detector##############################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup SimpleBlobDetector parameters.</span></span><br><span class="line">blobParams = cv2.SimpleBlobDetector_Params()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change thresholds</span></span><br><span class="line">blobParams.minThreshold = <span class="number">8</span></span><br><span class="line">blobParams.maxThreshold = <span class="number">255</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Area.</span></span><br><span class="line">blobParams.filterByArea = <span class="literal">True</span></span><br><span class="line">blobParams.minArea = <span class="number">64</span>     <span class="comment"># minArea may be adjusted to suit for your experiment</span></span><br><span class="line">blobParams.maxArea = <span class="number">2500</span>   <span class="comment"># maxArea may be adjusted to suit for your experiment</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Circularity</span></span><br><span class="line">blobParams.filterByCircularity = <span class="literal">True</span></span><br><span class="line">blobParams.minCircularity = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Convexity</span></span><br><span class="line">blobParams.filterByConvexity = <span class="literal">True</span></span><br><span class="line">blobParams.minConvexity = <span class="number">0.87</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Inertia</span></span><br><span class="line">blobParams.filterByInertia = <span class="literal">True</span></span><br><span class="line">blobParams.minInertiaRatio = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a detector with the parameters</span></span><br><span class="line">blobDetector = cv2.SimpleBlobDetector_create(blobParams)</span><br><span class="line"></span><br><span class="line"><span class="comment">###################################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###################################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Original blob coordinates, supposing all blobs are of z-coordinates 0</span></span><br><span class="line"><span class="comment"># And, the distance between every two neighbour blob circle centers is 72 centimetres</span></span><br><span class="line"><span class="comment"># In fact, any number can be used to replace 72.</span></span><br><span class="line"><span class="comment"># Namely, the real size of the circle is pointless while calculating camera calibration parameters.</span></span><br><span class="line">objp = np.zeros((<span class="number">44</span>, <span class="number">3</span>), np.float32)</span><br><span class="line">objp[<span class="number">0</span>]  = (<span class="number">0</span>  , <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">1</span>]  = (<span class="number">0</span>  , <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">2</span>]  = (<span class="number">0</span>  , <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">3</span>]  = (<span class="number">0</span>  , <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">4</span>]  = (<span class="number">36</span> , <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">5</span>]  = (<span class="number">36</span> , <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">6</span>]  = (<span class="number">36</span> , <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">7</span>]  = (<span class="number">36</span> , <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">8</span>]  = (<span class="number">72</span> , <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">9</span>]  = (<span class="number">72</span> , <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">10</span>] = (<span class="number">72</span> , <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">11</span>] = (<span class="number">72</span> , <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">12</span>] = (<span class="number">108</span>, <span class="number">36</span>,  <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">13</span>] = (<span class="number">108</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">14</span>] = (<span class="number">108</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">15</span>] = (<span class="number">108</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">16</span>] = (<span class="number">144</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">17</span>] = (<span class="number">144</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">18</span>] = (<span class="number">144</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">19</span>] = (<span class="number">144</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">20</span>] = (<span class="number">180</span>, <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">21</span>] = (<span class="number">180</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">22</span>] = (<span class="number">180</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">23</span>] = (<span class="number">180</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">24</span>] = (<span class="number">216</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">25</span>] = (<span class="number">216</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">26</span>] = (<span class="number">216</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">27</span>] = (<span class="number">216</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">28</span>] = (<span class="number">252</span>, <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">29</span>] = (<span class="number">252</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">30</span>] = (<span class="number">252</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">31</span>] = (<span class="number">252</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">32</span>] = (<span class="number">288</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">33</span>] = (<span class="number">288</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">34</span>] = (<span class="number">288</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">35</span>] = (<span class="number">288</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">36</span>] = (<span class="number">324</span>, <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">37</span>] = (<span class="number">324</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">38</span>] = (<span class="number">324</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">39</span>] = (<span class="number">324</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">40</span>] = (<span class="number">360</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">41</span>] = (<span class="number">360</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">42</span>] = (<span class="number">360</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objp[<span class="number">43</span>] = (<span class="number">360</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line"><span class="comment">###################################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Arrays to store object points and image points from all the images.</span></span><br><span class="line">objpoints = [] <span class="comment"># 3d point in real world space</span></span><br><span class="line">imgpoints = [] <span class="comment"># 2d points in image plane.</span></span><br></pre></td></tr></table></figure>
<h2 id="fourthly">Fourthly</h2>
<p>After localizing 10 frames (<strong>10</strong> can be changed to any
positive integer as you wish) of a grid of 2D circles, camera matrix and
distortion coefficients can be calculated by invoking the function
<strong>calibrateCamera</strong>. Here, we are testing on a real-time
camera stream. Similar to Camera Posture Estimation Using Circle Grid
Pattern, the trick is to do <strong>blobDetector.detect()</strong> and
draw the detected blobs using <strong>cv2.drawKeypoints()</strong>
before invoking <strong>cv2.findCirclesGrid()</strong>, so that the
entire grid is easier to be found.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line">found = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span>(found &lt; <span class="number">10</span>):  <span class="comment"># Here, 10 can be changed to whatever number you like to choose</span></span><br><span class="line">    ret, img = cap.read() <span class="comment"># Capture frame-by-frame</span></span><br><span class="line">    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">    keypoints = blobDetector.detect(gray) <span class="comment"># Detect blobs.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Draw detected blobs as red circles. This helps cv2.findCirclesGrid() .</span></span><br><span class="line">    im_with_keypoints = cv2.drawKeypoints(img, keypoints, np.array([]), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class="line">    im_with_keypoints_gray = cv2.cvtColor(im_with_keypoints, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    ret, corners = cv2.findCirclesGrid(im_with_keypoints, (<span class="number">4</span>,<span class="number">11</span>), <span class="literal">None</span>, flags = cv2.CALIB_CB_ASYMMETRIC_GRID)   <span class="comment"># Find the circle grid</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        objpoints.append(objp)  <span class="comment"># Certainly, every loop objp is the same, in 3D.</span></span><br><span class="line"></span><br><span class="line">        corners2 = cv2.cornerSubPix(im_with_keypoints_gray, corners, (<span class="number">11</span>,<span class="number">11</span>), (-<span class="number">1</span>,-<span class="number">1</span>), criteria)    <span class="comment"># Refines the corner locations.</span></span><br><span class="line">        imgpoints.append(corners2)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Draw and display the corners.</span></span><br><span class="line">        im_with_keypoints = cv2.drawChessboardCorners(img, (<span class="number">4</span>,<span class="number">11</span>), corners2, ret)</span><br><span class="line">        found += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    cv2.imshow(<span class="string">&quot;img&quot;</span>, im_with_keypoints) <span class="comment"># display</span></span><br><span class="line">    cv2.waitKey(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># When everything done, release the capture</span></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-<span class="number">1</span>], <span class="literal">None</span>, <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h2 id="finally">Finally</h2>
<p>Write the calculated calibration parameters into a yaml file. Here,
it is a bit tricky. Please bear in mind that you <strong>MUST</strong>
call function tolist() to transform a numpy array to a list.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># It&#x27;s very important to transform the matrix to list.</span></span><br><span class="line">data = &#123;<span class="string">&#x27;camera_matrix&#x27;</span>: np.asarray(mtx).tolist(), <span class="string">&#x27;dist_coeff&#x27;</span>: np.asarray(dist).tolist()&#125;</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;calibration.yaml&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    yaml.dump(data, f)</span><br></pre></td></tr></table></figure>
<h2 id="additionally">Additionally</h2>
<p>You may use the following piece of code to load the calibration
parameters from file “calibration.yaml”.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;calibration.yaml&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    loadeddict = yaml.load(f)</span><br><span class="line">mtxloaded = loadeddict.get(<span class="string">&#x27;camera_matrix&#x27;</span>)</span><br><span class="line">distloaded = loadeddict.get(<span class="string">&#x27;dist_coeff&#x27;</span>)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/16/ComputerVision/OpenCV/opencv-internal-calibration-chessboard/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Nobody">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Longer Vision Technology">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/16/ComputerVision/OpenCV/opencv-internal-calibration-chessboard/" class="post-title-link" itemprop="url">Camera Calibration Using a Chessboard</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2017-03-16 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-16T00:00:00-07:00">2017-03-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-28 17:33:45" itemprop="dateModified" datetime="2024-09-28T17:33:45-07:00">2024-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="preparation">Preparation</h1>
<p>Traditionally, a camera is calibrated using a chessboard. Existing
documentations are already out there and have discussed camera
calibration in detail, for example, <a
target="_blank" rel="noopener" href="http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html">OpenCV-Python
Tutorials</a>.</p>
<h1 id="coding">Coding</h1>
<p>Our code can be found at <a
target="_blank" rel="noopener" href="https://github.com/LongerVision/OpenCV_Examples/blob/master/01_internal_camera_calibration/chessboard.py">OpenCV
Examples</a>.</p>
<h2 id="first-of-all">First of all</h2>
<p>Unlike estimating camera postures which is dealing with the extrinsic
parameters, camera calibration is to calculate the intrinsic parameters.
In such a case, there is <strong>NO</strong> need for us to measure the
cell size of the chessboard. Anyway, the adopted chessboard is just an
ordinary chessboard as:</p>
<figure>
<img
src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/pattern_chessboard.png"
alt="pattern_chessboard" />
<figcaption aria-hidden="true">pattern_chessboard</figcaption>
</figure>
<h2 id="secondly">Secondly</h2>
<p>Required packages need to be imported.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> yaml</span><br></pre></td></tr></table></figure>
<h2 id="thirdly">Thirdly</h2>
<p>Some initialization work need to be done, including: 1) define the
termination criteria when refine the corner sub-pixel later on; 2)
object points coordinators initialization.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># termination criteria</span></span><br><span class="line">criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, <span class="number">30</span>, <span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)</span></span><br><span class="line">objp = np.zeros((<span class="number">6</span>*<span class="number">7</span>,<span class="number">3</span>), np.float32)</span><br><span class="line">objp[:,:<span class="number">2</span>] = np.mgrid[<span class="number">0</span>:<span class="number">7</span>,<span class="number">0</span>:<span class="number">6</span>].T.reshape(-<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Arrays to store object points and image points from all the images.</span></span><br><span class="line">objpoints = [] <span class="comment"># 3d point in real world space</span></span><br><span class="line">imgpoints = [] <span class="comment"># 2d points in image plane.</span></span><br></pre></td></tr></table></figure>
<h2 id="fourthly">Fourthly</h2>
<p>After localizing 10 frames (<strong>10</strong> can be changed to any
positive integer as you wish) of a grid of 2D chessboard cell corners,
camera matrix and distortion coefficients can be calculated by invoking
the function <strong>calibrateCamera</strong>. Here, we are testing on a
real-time camera stream.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line">found = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span>(found &lt; <span class="number">10</span>):  <span class="comment"># Here, 10 can be changed to whatever number you like to choose</span></span><br><span class="line">    ret, img = cap.read() <span class="comment"># Capture frame-by-frame</span></span><br><span class="line">    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Find the chess board corners</span></span><br><span class="line">    ret, corners = cv2.findChessboardCorners(gray, (<span class="number">7</span>,<span class="number">6</span>),<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># If found, add object points, image points (after refining them)</span></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        objpoints.append(objp)   <span class="comment"># Certainly, every loop objp is the same, in 3D.</span></span><br><span class="line">        corners2 = cv2.cornerSubPix(gray,corners,(<span class="number">11</span>,<span class="number">11</span>),(-<span class="number">1</span>,-<span class="number">1</span>),criteria)</span><br><span class="line">        imgpoints.append(corners2)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Draw and display the corners</span></span><br><span class="line">        img = cv2.drawChessboardCorners(img, (<span class="number">7</span>,<span class="number">6</span>), corners2, ret)</span><br><span class="line">        found += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    cv2.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line">    cv2.waitKey(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># When everything done, release the capture</span></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-<span class="number">1</span>], <span class="literal">None</span>, <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h2 id="finally">Finally</h2>
<p>Write the calculated calibration parameters into a yaml file. Here,
it is a bit tricky. Please bear in mind that you <strong>MUST</strong>
call function <strong>tolist()</strong> to transform a numpy array to a
list.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># It&#x27;s very important to transform the matrix to list.</span></span><br><span class="line"></span><br><span class="line">data = &#123;<span class="string">&#x27;camera_matrix&#x27;</span>: np.asarray(mtx).tolist(), <span class="string">&#x27;dist_coeff&#x27;</span>: np.asarray(dist).tolist()&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;calibration.yaml&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    yaml.dump(data, f)</span><br></pre></td></tr></table></figure>
<h2 id="additionally">Additionally</h2>
<p>You may use the following piece of code to load the calibration
parameters from file “calibration.yaml”.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;calibration.yaml&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    loadeddict = yaml.load(f)</span><br><span class="line"></span><br><span class="line">mtxloaded = loadeddict.get(<span class="string">&#x27;camera_matrix&#x27;</span>)</span><br><span class="line">distloaded = loadeddict.get(<span class="string">&#x27;dist_coeff&#x27;</span>)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/15/ComputerVision/OpenCV/opencv-python-arruco-doc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Nobody">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Longer Vision Technology">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/15/ComputerVision/OpenCV/opencv-python-arruco-doc/" class="post-title-link" itemprop="url">OpenCV Python ArUco Documentation</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2017-03-15 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-15T00:00:00-07:00">2017-03-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-28 17:33:45" itemprop="dateModified" datetime="2024-09-28T17:33:45-07:00">2024-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="preparation">Preparation</h1>
<p>Open a bash terminal, and type in the following commands:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ python</span><br><span class="line">Python 3.5.2 (default, Nov 17 2016, 17:05:23)</span><br><span class="line">[GCC 5.4.0 20160609] on linux</span><br><span class="line">Type <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> or <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line">&gt;&gt;&gt; import cv2</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">help</span> (cv2.aruco)</span><br></pre></td></tr></table></figure>
<p>Then, you will be able to see all the doc contents for
<strong>cv2.aruco</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line">Help on module cv2.aruco <span class="keyword">in</span> cv2:</span><br><span class="line"></span><br><span class="line">NAME</span><br><span class="line">    cv2.aruco</span><br><span class="line"></span><br><span class="line">FUNCTIONS</span><br><span class="line">    Board_create(...)</span><br><span class="line"></span><br><span class="line">        Board_create(objPoints, dictionary, ids) -&gt; retval</span><br><span class="line"></span><br><span class="line">    CharucoBoard_create(...)</span><br><span class="line"></span><br><span class="line">        CharucoBoard_create(squaresX, squaresY, squareLength, markerLength, dictionary) -&gt; retval</span><br><span class="line"></span><br><span class="line">    DetectorParameters_create(...)</span><br><span class="line"></span><br><span class="line">        DetectorParameters_create() -&gt; retval</span><br><span class="line"></span><br><span class="line">    Dictionary_create(...)</span><br><span class="line"></span><br><span class="line">        Dictionary_create(nMarkers, markerSize) -&gt; retval</span><br><span class="line"></span><br><span class="line">    Dictionary_create_from(...)</span><br><span class="line"></span><br><span class="line">        Dictionary_create_from(nMarkers, markerSize, baseDictionary) -&gt; retval</span><br><span class="line"></span><br><span class="line">    Dictionary_get(...)</span><br><span class="line"></span><br><span class="line">        Dictionary_get(<span class="built_in">dict</span>) -&gt; retval</span><br><span class="line"></span><br><span class="line">    GridBoard_create(...)</span><br><span class="line"></span><br><span class="line">        GridBoard_create(markersX, markersY, markerLength, markerSeparation, dictionary[, firstMarker]) -&gt; retval</span><br><span class="line"></span><br><span class="line">    calibrateCameraAruco(...)</span><br><span class="line"></span><br><span class="line">        calibrateCameraAruco(corners, ids, counter, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -&gt; retval, cameraMatrix, distCoeffs, rvecs, tvecs</span><br><span class="line"></span><br><span class="line">    calibrateCameraArucoExtended(...)</span><br><span class="line"></span><br><span class="line">        calibrateCameraArucoExtended(corners, ids, counter, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, perViewErrors[, flags[, criteria]</span><br><span class="line"></span><br><span class="line">]]]]]]) -&gt; retval, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors</span><br><span class="line"></span><br><span class="line">    calibrateCameraCharuco(...)</span><br><span class="line"></span><br><span class="line">        calibrateCameraCharuco(charucoCorners, charucoIds, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -&gt; retval, cameraMatrix, distCoeffs, rvecs, tvecs</span><br><span class="line"></span><br><span class="line">    calibrateCameraCharucoExtended(...)</span><br><span class="line"></span><br><span class="line">        calibrateCameraCharucoExtended(charucoCorners, charucoIds, board, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, stdDeviationsIntrinsics[, stdDeviationsExtrinsics[, perViewErrors[, flags[, cr</span><br><span class="line"></span><br><span class="line">iteria]]]]]]]) -&gt; retval, cameraMatrix, distCoeffs, rvecs, tvecs, stdDeviationsIntrinsics, stdDeviationsExtrinsics, perViewErrors</span><br><span class="line"></span><br><span class="line">    custom_dictionary(...)</span><br><span class="line"></span><br><span class="line">        custom_dictionary(nMarkers, markerSize) -&gt; retval</span><br><span class="line"></span><br><span class="line">    custom_dictionary_from(...)</span><br><span class="line"></span><br><span class="line">        custom_dictionary_from(nMarkers, markerSize, baseDictionary) -&gt; retval</span><br><span class="line"></span><br><span class="line">    detectCharucoDiamond(...)</span><br><span class="line"></span><br><span class="line">        detectCharucoDiamond(image, markerCorners, markerIds, squareMarkerLengthRate[, diamondCorners[, diamondIds[, cameraMatrix[, distCoeffs]]]]) -&gt; diamondCorners, diamondIds</span><br><span class="line"></span><br><span class="line">    detectMarkers(...)</span><br><span class="line"></span><br><span class="line">        detectMarkers(image, dictionary[, corners[, ids[, parameters[, rejectedImgPoints]]]]) -&gt; corners, ids, rejectedImgPoints</span><br><span class="line"></span><br><span class="line">    drawAxis(...)</span><br><span class="line"></span><br><span class="line">        drawAxis(image, cameraMatrix, distCoeffs, rvec, tvec, length) -&gt; image</span><br><span class="line"></span><br><span class="line">    drawDetectedCornersCharuco(...)</span><br><span class="line"></span><br><span class="line">        drawDetectedCornersCharuco(image, charucoCorners[, charucoIds[, cornerColor]]) -&gt; image</span><br><span class="line"></span><br><span class="line">    drawDetectedDiamonds(...)</span><br><span class="line"></span><br><span class="line">        drawDetectedDiamonds(image, diamondCorners[, diamondIds[, borderColor]]) -&gt; image</span><br><span class="line"></span><br><span class="line">    drawDetectedMarkers(...)</span><br><span class="line"></span><br><span class="line">        drawDetectedMarkers(image, corners[, ids[, borderColor]]) -&gt; image</span><br><span class="line"></span><br><span class="line">    drawMarker(...)</span><br><span class="line"></span><br><span class="line">        drawMarker(dictionary, <span class="built_in">id</span>, sidePixels[, img[, borderBits]]) -&gt; img</span><br><span class="line"></span><br><span class="line">    drawPlanarBoard(...)</span><br><span class="line"></span><br><span class="line">        drawPlanarBoard(board, outSize[, img[, marginSize[, borderBits]]]) -&gt; img</span><br><span class="line"></span><br><span class="line">    estimatePoseBoard(...)</span><br><span class="line"></span><br><span class="line">        estimatePoseBoard(corners, ids, board, cameraMatrix, distCoeffs[, rvec[, tvec[, useExtrinsicGuess]]]) -&gt; retval, rvec, tvec</span><br><span class="line"></span><br><span class="line">    estimatePoseCharucoBoard(...)</span><br><span class="line"></span><br><span class="line">        estimatePoseCharucoBoard(charucoCorners, charucoIds, board, cameraMatrix, distCoeffs[, rvec[, tvec[, useExtrinsicGuess]]]) -&gt; retval, rvec, tvec</span><br><span class="line"></span><br><span class="line">    estimatePoseSingleMarkers(...)</span><br><span class="line"></span><br><span class="line">        estimatePoseSingleMarkers(corners, markerLength, cameraMatrix, distCoeffs[, rvecs[, tvecs]]) -&gt; rvecs, tvecs</span><br><span class="line"></span><br><span class="line">    getPredefinedDictionary(...)</span><br><span class="line"></span><br><span class="line">        getPredefinedDictionary(<span class="built_in">dict</span>) -&gt; retval</span><br><span class="line"></span><br><span class="line">    interpolateCornersCharuco(...)</span><br><span class="line"></span><br><span class="line">        interpolateCornersCharuco(markerCorners, markerIds, image, board[, charucoCorners[, charucoIds[, cameraMatrix[, distCoeffs[, minMarkers]]]]]) -&gt; retval, charucoCorners, charucoIds</span><br><span class="line"></span><br><span class="line">    refineDetectedMarkers(...)</span><br><span class="line"></span><br><span class="line">        refineDetectedMarkers(image, board, detectedCorners, detectedIds, rejectedCorners[, cameraMatrix[, distCoeffs[, minRepDistance[, errorCorrectionRate[, checkAllOrders[, recoveredIdxs[, parameters]]]]]]]) -&gt; detectedCorners, detectedIds, rejectedCorners, recoveredIdxs</span><br><span class="line"></span><br><span class="line">DATA</span><br><span class="line">    DICT_4X4_100 = <span class="number">1</span></span><br><span class="line">    DICT_4X4_1000 = <span class="number">3</span></span><br><span class="line">    DICT_4X4_250 = <span class="number">2</span></span><br><span class="line">    DICT_4X4_50 = <span class="number">0</span></span><br><span class="line">    DICT_5X5_100 = <span class="number">5</span></span><br><span class="line">    DICT_5X5_1000 = <span class="number">7</span></span><br><span class="line">    DICT_5X5_250 = <span class="number">6</span></span><br><span class="line">    DICT_5X5_50 = <span class="number">4</span></span><br><span class="line">    DICT_6X6_100 = <span class="number">9</span></span><br><span class="line">    DICT_6X6_1000 = <span class="number">11</span></span><br><span class="line">    DICT_6X6_250 = <span class="number">10</span></span><br><span class="line">    DICT_6X6_50 = <span class="number">8</span></span><br><span class="line">    DICT_7X7_100 = <span class="number">13</span></span><br><span class="line">    DICT_7X7_1000 = <span class="number">15</span></span><br><span class="line">    DICT_7X7_250 = <span class="number">14</span></span><br><span class="line">    DICT_7X7_50 = <span class="number">12</span></span><br><span class="line">    DICT_ARUCO_ORIGINAL = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">FILE</span><br><span class="line">    (built-<span class="keyword">in</span>)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/14/ComputerVision/OpenCV/opencv-external-posture-estimation-circle-grid/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Nobody">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Longer Vision Technology">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/14/ComputerVision/OpenCV/opencv-external-posture-estimation-circle-grid/" class="post-title-link" itemprop="url">Camera Posture Estimation Using Circle Grid Pattern</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2017-03-14 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-14T00:00:00-07:00">2017-03-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-28 17:33:45" itemprop="dateModified" datetime="2024-09-28T17:33:45-07:00">2024-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="preparation">Preparation</h1>
<p>A widely used asymmetric circle grid pattern can be found in <a
target="_blank" rel="noopener" href="http://docs.opencv.org/2.4/_downloads/acircles_pattern.png">doc of
OpenCV 2.4</a>. Same as previous blogs, the camera needs to be
calibrated beforehand. For this asymmetric circle grid example, a
sequence of images (instead of a video stream) is tested.</p>
<h1 id="coding">Coding</h1>
<p>The code can be found at <a
target="_blank" rel="noopener" href="https://github.com/LongerVision/Examples_OpenCV/blob/master/01_internal_camera_calibration/circle_grid.py">OpenCV
Examples</a>.</p>
<h2 id="first-of-all">First of all</h2>
<p>We need to ensure <strong>cv2.so</strong> is under our system path.
<strong>cv2.so</strong> is specifically for OpenCV Python.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&#x27;/usr/local/python/3.5&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Then, we import some packages to be used (<strong>NO
ArUco</strong>).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h2 id="secondly">Secondly</h2>
<p>We now load all camera calibration parameters, including:
<strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. For
example, your code might look like the following:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">calibrationFile = <span class="string">&quot;calibrationFileName.xml&quot;</span></span><br><span class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</span><br><span class="line">camera_matrix = calibrationParams.getNode(<span class="string">&quot;cameraMatrix&quot;</span>).mat()</span><br><span class="line">dist_coeffs = calibrationParams.getNode(<span class="string">&quot;distCoeffs&quot;</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Since we are testing a calibrated fisheye camera, two extra
parameters are to be loaded from the calibration file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = calibrationParams.getNode(<span class="string">&quot;R&quot;</span>).mat()</span><br><span class="line">new_camera_matrix = calibrationParams.getNode(<span class="string">&quot;newCameraMatrix&quot;</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Afterwards, two mapping matrices are pre-calculated by calling
function <a
target="_blank" rel="noopener" href="http://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a">cv2.fisheye.initUndistortRectifyMap()</a>
as (supposing the images to be processed are of 1080P):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_size = (<span class="number">1920</span>, <span class="number">1080</span>)</span><br><span class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</span><br></pre></td></tr></table></figure>
<h2 id="thirdly">Thirdly</h2>
<p>The circle pattern is to be loaded.</p>
<figure>
<img
src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/pattern_acircles.png"
alt="asymmetric_circle_grid" />
<figcaption aria-hidden="true">asymmetric_circle_grid</figcaption>
</figure>
<p>Here in our case, this asymmetric circle grid pattern is manually
loaded as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Original blob coordinates</span></span><br><span class="line">objectPoints = np.zeros((<span class="number">44</span>, <span class="number">3</span>))  <span class="comment"># In this asymmetric circle grid, 44 circles are adopted.</span></span><br><span class="line">objectPoints[<span class="number">0</span>]  = (<span class="number">0</span>  , <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">1</span>]  = (<span class="number">0</span>  , <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">2</span>]  = (<span class="number">0</span>  , <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">3</span>]  = (<span class="number">0</span>  , <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">4</span>]  = (<span class="number">36</span> , <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">5</span>]  = (<span class="number">36</span> , <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">6</span>]  = (<span class="number">36</span> , <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">7</span>]  = (<span class="number">36</span> , <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">8</span>]  = (<span class="number">72</span> , <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">9</span>]  = (<span class="number">72</span> , <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">10</span>] = (<span class="number">72</span> , <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">11</span>] = (<span class="number">72</span> , <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">12</span>] = (<span class="number">108</span>, <span class="number">36</span>,  <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">13</span>] = (<span class="number">108</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">14</span>] = (<span class="number">108</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">15</span>] = (<span class="number">108</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">16</span>] = (<span class="number">144</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">17</span>] = (<span class="number">144</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">18</span>] = (<span class="number">144</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">19</span>] = (<span class="number">144</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">20</span>] = (<span class="number">180</span>, <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">21</span>] = (<span class="number">180</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">22</span>] = (<span class="number">180</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">23</span>] = (<span class="number">180</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">24</span>] = (<span class="number">216</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">25</span>] = (<span class="number">216</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">26</span>] = (<span class="number">216</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">27</span>] = (<span class="number">216</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">28</span>] = (<span class="number">252</span>, <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">29</span>] = (<span class="number">252</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">30</span>] = (<span class="number">252</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">31</span>] = (<span class="number">252</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">32</span>] = (<span class="number">288</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">33</span>] = (<span class="number">288</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">34</span>] = (<span class="number">288</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">35</span>] = (<span class="number">288</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">36</span>] = (<span class="number">324</span>, <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">37</span>] = (<span class="number">324</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">38</span>] = (<span class="number">324</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">39</span>] = (<span class="number">324</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">40</span>] = (<span class="number">360</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">41</span>] = (<span class="number">360</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">42</span>] = (<span class="number">360</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">43</span>] = (<span class="number">360</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>In our case, the distance between two neighbour circle centres (in
the same column) is measured as 72 centimetres. Meanwhile, the axis at
the origin is loaded as well, with respective length 300, 200, 100
centimetres.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">axis = np.float32([[<span class="number">360</span>,<span class="number">0</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">240</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">0</span>,-<span class="number">120</span>]]).reshape(-<span class="number">1</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<h2 id="fourthly">Fourthly</h2>
<p>Since we are going to use OpenCV’s SimpleBlobDetector for the blob
detection, the SimpleBlobDetector’s parameters are to be created
beforehand. The parameter values can be adjusted according to your own
testing environments. The iteration <strong>criteria</strong> for the
simple blob detection is also created at the same time.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup SimpleBlobDetector parameters.</span></span><br><span class="line">blobParams = cv2.SimpleBlobDetector_Params()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change thresholds</span></span><br><span class="line">blobParams.minThreshold = <span class="number">8</span></span><br><span class="line">blobParams.maxThreshold = <span class="number">255</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Area.</span></span><br><span class="line">blobParams.filterByArea = <span class="literal">True</span></span><br><span class="line">blobParams.minArea = <span class="number">64</span>     <span class="comment"># minArea may be adjusted to suit for your experiment</span></span><br><span class="line">blobParams.maxArea = <span class="number">2500</span>   <span class="comment"># maxArea may be adjusted to suit for your experiment</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Circularity</span></span><br><span class="line">blobParams.filterByCircularity = <span class="literal">True</span></span><br><span class="line">blobParams.minCircularity = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Convexity</span></span><br><span class="line">blobParams.filterByConvexity = <span class="literal">True</span></span><br><span class="line">blobParams.minConvexity = <span class="number">0.87</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Inertia</span></span><br><span class="line">blobParams.filterByInertia = <span class="literal">True</span></span><br><span class="line">blobParams.minInertiaRatio = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a detector with the parameters</span></span><br><span class="line">blobDetector = cv2.SimpleBlobDetector_create(blobParams)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the iteration criteria</span></span><br><span class="line">criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, <span class="number">30</span>, <span class="number">0.001</span>)</span><br><span class="line"><span class="comment">###################################################################################################</span></span><br></pre></td></tr></table></figure>
<h2 id="finally">Finally</h2>
<p>Estimate camera postures. Here, we are testing a sequence of images,
rather than video streams. We first list all file names in sequence.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">imgDir = <span class="string">&quot;imgSequence&quot;</span>  <span class="comment"># Specify the image directory</span></span><br><span class="line">imgFileNames = [os.path.join(imgDir, fn) <span class="keyword">for</span> fn <span class="keyword">in</span> <span class="built_in">next</span>(os.walk(imgDir))[<span class="number">2</span>]]</span><br><span class="line">nbOfImgs = <span class="built_in">len</span>(imgFileNames)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame:
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, nbOfImgs-<span class="number">1</span>):</span><br><span class="line">    img = cv2.imread(imgFileNames[i], cv2.IMREAD_COLOR)</span><br><span class="line">    imgRemapped = cv2.remap(img, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT) <span class="comment"># for fisheye remapping</span></span><br><span class="line">    imgRemapped_gray = cv2.cvtColor(imgRemapped, cv2.COLOR_BGR2GRAY)    <span class="comment"># blobDetector.detect() requires gray image</span></span><br><span class="line"></span><br><span class="line">    keypoints = blobDetector.detect(imgRemapped_gray) <span class="comment"># Detect blobs.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Draw detected blobs as red circles. This helps cv2.findCirclesGrid() .</span></span><br><span class="line">    im_with_keypoints = cv2.drawKeypoints(imgRemapped, keypoints, np.array([]), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class="line">    im_with_keypoints_gray = cv2.cvtColor(im_with_keypoints, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    ret, corners = cv2.findCirclesGrid(im_with_keypoints, (<span class="number">4</span>,<span class="number">11</span>), <span class="literal">None</span>, flags = cv2.CALIB_CB_ASYMMETRIC_GRID)   <span class="comment"># Find the circle grid</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        corners2 = cv2.cornerSubPix(im_with_keypoints_gray, corners, (<span class="number">11</span>,<span class="number">11</span>), (-<span class="number">1</span>,-<span class="number">1</span>), criteria)    <span class="comment"># Refines the corner locations.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Draw and display the corners.</span></span><br><span class="line">        im_with_keypoints = cv2.drawChessboardCorners(imLeftRemapped, (<span class="number">4</span>,<span class="number">11</span>), corners2, ret)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3D posture</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(corners2) == <span class="built_in">len</span>(objectPoints):</span><br><span class="line">            retval, rvec, tvec = cv2.solvePnP(objectPoints, corners2, camera_matrix, dist_coeffs)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> retval:</span><br><span class="line">            projectedPoints, jac = cv2.projectPoints(objectPoints, rvec, tvec, camera_matrix, dist_coeffs)  <span class="comment"># project 3D points to image plane</span></span><br><span class="line">            projectedAxis, jacAsix = cv2.projectPoints(axis, rvec, tvec, camera_matrix, dist_coeffs)    <span class="comment"># project axis to image plane</span></span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> projectedPoints:</span><br><span class="line">                p = np.int32(p).reshape(-<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">                cv2.circle(im_with_keypoints, (p[<span class="number">0</span>][<span class="number">0</span>], p[<span class="number">0</span>][<span class="number">1</span>]), <span class="number">3</span>, (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>))</span><br><span class="line">            origin = <span class="built_in">tuple</span>(corners2[<span class="number">0</span>].ravel())</span><br><span class="line">            im_with_keypoints = cv2.line(im_with_keypoints, origin, <span class="built_in">tuple</span>(projectedAxis[<span class="number">0</span>].ravel()), (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">            im_with_keypoints = cv2.line(im_with_keypoints, origin, <span class="built_in">tuple</span>(projectedAxis[<span class="number">1</span>].ravel()), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">            im_with_keypoints = cv2.line(im_with_keypoints, origin, <span class="built_in">tuple</span>(projectedAxis[<span class="number">2</span>].ravel()), (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    cv2.imshow(<span class="string">&quot;circlegrid&quot;</span>, im_with_keypoints) <span class="comment"># display</span></span><br><span class="line"></span><br><span class="line">    cv2.waitKey(<span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<p>The drawn axis is just the world coordinators and orientations
estimated from the images taken by the testing camera.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/13/ComputerVision/OpenCV/opencv-external-posture-estimation-ChArUco-board/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Nobody">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Longer Vision Technology">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/13/ComputerVision/OpenCV/opencv-external-posture-estimation-ChArUco-board/" class="post-title-link" itemprop="url">Camera Posture Estimation Using A ChArUco Board</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2017-03-13 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-13T00:00:00-07:00">2017-03-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-28 17:33:45" itemprop="dateModified" datetime="2024-09-28T17:33:45-07:00">2024-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="preparation">Preparation</h1>
<p>ChAruco is an integrated marker, which combines a chessboard with an
aruco marker. The code is also very similar to the code in our previous
blog <a
href="../../../../../../2017/03/12/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-board/">aruco
board</a>.</p>
<h1 id="coding">Coding</h1>
<p>The code can be found at <a
target="_blank" rel="noopener" href="https://github.com/LongerVision/OpenCV_Examples/blob/master/03_external_camera_posture_estimation/ChArUco_board.py">OpenCV
Examples</a>. And the code in the first two subsections are exactly the
same as what’s written in our previous blogs. We’ll neglect the first
two subsections ever since.</p>
<h2 id="first-of-all">First of all</h2>
<p>Exactly the same as in previous blogs.</p>
<h2 id="secondly">Secondly</h2>
<p>Exactly the same as in previous blogs.</p>
<h2 id="thirdly">Thirdly</h2>
<p>Dictionary <strong>aruco.DICT_6X6_1000</strong> is integrated with a
chessboard to construct a grid charuco board. The experimenting board is
of size <strong>5X7</strong>, which looks like:</p>
<figure>
<img
src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/board_charuco_57.png"
alt="charuco.DICT_6X6_1000.board57" />
<figcaption
aria-hidden="true">charuco.DICT_6X6_1000.board57</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aruco_dict = aruco.Dictionary_get( aruco.DICT_6X6_1000 )</span><br></pre></td></tr></table></figure>
<p>After having this aruco board marker printed, the edge lengths of
this chessboard and aruco marker (displayed in the white cell of the
chessboard) are to be measured and stored in two variables
<strong>squareLength</strong> and <strong>markerLength</strong>, which
are used to create the <strong>5X7</strong> grid board.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">squareLength = <span class="number">40</span>   <span class="comment"># Here, our measurement unit is centimetre.</span></span><br><span class="line">markerLength = <span class="number">30</span>   <span class="comment"># Here, our measurement unit is centimetre.</span></span><br><span class="line">board = aruco.CharucoBoard_create(<span class="number">5</span>, <span class="number">7</span>, squareLength, markerLength, aruco_dict)</span><br></pre></td></tr></table></figure>
<p>Meanwhile, create aruco detector with default parameters.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arucoParams = aruco.DetectorParameters_create()</span><br></pre></td></tr></table></figure>
<h2 id="finally">Finally</h2>
<p>Now, let’s test on a video stream, a .mp4 file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">videoFile = <span class="string">&quot;charuco_board_57.mp4&quot;</span></span><br><span class="line">cap = cv2.VideoCapture(videoFile)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    ret, frame = cap.read() <span class="comment"># Capture frame-by-frame</span></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        frame_remapped = cv2.remap(frame, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)    <span class="comment"># for fisheye remapping</span></span><br><span class="line">        frame_remapped_gray = cv2.cvtColor(frame_remapped, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">        corners, ids, rejectedImgPoints = aruco.detectMarkers(frame_remapped_gray, aruco_dict, parameters=arucoParams)  <span class="comment"># First, detect markers</span></span><br><span class="line">        aruco.refineDetectedMarkers(frame_remapped_gray, board, corners, ids, rejectedImgPoints)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ids != <span class="literal">None</span>: <span class="comment"># if there is at least one marker detected</span></span><br><span class="line">            charucoretval, charucoCorners, charucoIds = aruco.interpolateCornersCharuco(corners, ids, frame_remapped_gray, board)</span><br><span class="line">            im_with_charuco_board = aruco.drawDetectedCornersCharuco(frame_remapped, charucoCorners, charucoIds, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line">            retval, rvec, tvec = aruco.estimatePoseCharucoBoard(charucoCorners, charucoIds, board, camera_matrix, dist_coeffs)  <span class="comment"># posture estimation from a charuco board</span></span><br><span class="line">            <span class="keyword">if</span> retval == <span class="literal">True</span>:</span><br><span class="line">                im_with_charuco_board = aruco.drawAxis(im_with_charuco_board, camera_matrix, dist_coeffs, rvec, tvec, <span class="number">100</span>)  <span class="comment"># axis length 100 can be changed according to your requirement</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            im_with_charuco_left = frame_remapped</span><br><span class="line"></span><br><span class="line">        cv2.imshow(<span class="string">&quot;charucoboard&quot;</span>, im_with_charuco_board)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">2</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>The drawn axis is just the world coordinators and orientations
estimated from the images taken by the testing camera. At the end of the
code, we release the video capture handle and destroy all opening
windows.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cap.release()   <span class="comment"># When everything done, release the capture</span></span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/12/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-board/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Nobody">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Longer Vision Technology">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/12/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-board/" class="post-title-link" itemprop="url">Camera Posture Estimation Using An ArUco Board</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2017-03-12 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-12T00:00:00-08:00">2017-03-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-28 17:33:45" itemprop="dateModified" datetime="2024-09-28T17:33:45-07:00">2024-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="preparation">Preparation</h1>
<p>Today, let’s test on an aruco board, instead of a <a
target="_blank" rel="noopener" href="https://longervision.github.io/2017/03/10/opencv-external-posture-estimation-ArUco-single-marker/">single
marker</a> or a <a
target="_blank" rel="noopener" href="https://longervision.github.io/2017/03/11/opencv-external-posture-estimation-ArUco-diamond/">diamond
marker</a>. Again, you need to make sure your camera has already been
calibrated. In the coding section, it’s assumed that you can
successfully load the camera calibration parameters.</p>
<h1 id="coding">Coding</h1>
<p>The code can be found at <a
target="_blank" rel="noopener" href="https://github.com/LongerVision/OpenCV_Examples/blob/master/03_external_camera_posture_estimation/ArUco_single_marker.py">OpenCV
Examples</a>.</p>
<h2 id="first-of-all">First of all</h2>
<p>We need to ensure <strong>cv2.so</strong> is under our system path.
<strong>cv2.so</strong> is specifically for OpenCV Python.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">sys.path.append(<span class="string">&#x27;/usr/local/python/3.5&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Then, we import some packages to be used.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> cv2 <span class="keyword">import</span> aruco</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h2 id="secondly">Secondly</h2>
<p>Again, we need to load all camera calibration parameters, including:
<strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. :</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">calibrationFile = <span class="string">&quot;calibrationFileName.xml&quot;</span></span><br><span class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</span><br><span class="line">camera_matrix = calibrationParams.getNode(<span class="string">&quot;cameraMatrix&quot;</span>).mat()</span><br><span class="line">dist_coeffs = calibrationParams.getNode(<span class="string">&quot;distCoeffs&quot;</span>).mat()</span><br></pre></td></tr></table></figure>
<p>If you are using a calibrated fisheye camera like us, two extra
parameters are to be loaded from the calibration file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = calibrationParams.getNode(<span class="string">&quot;R&quot;</span>).mat()</span><br><span class="line">new_camera_matrix = calibrationParams.getNode(<span class="string">&quot;newCameraMatrix&quot;</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Afterwards, two mapping matrices are pre-calculated by calling
function <a
target="_blank" rel="noopener" href="http://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a">cv2.fisheye.initUndistortRectifyMap()</a>
as (supposing the images to be processed are of 1080P):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_size = (<span class="number">1920</span>, <span class="number">1080</span>)</span><br><span class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</span><br></pre></td></tr></table></figure>
<h2 id="thirdly">Thirdly</h2>
<p>In our test, the dictionary <strong>aruco.DICT_6X6_1000</strong> is
adopted as the unit pattern to construct a grid board. The board is of
size <strong>5X7</strong>, which looks like:</p>
<figure>
<img
src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/board_aruco_57.png"
alt="aruco.DICT_6X6_1000.board57" />
<figcaption aria-hidden="true">aruco.DICT_6X6_1000.board57</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aruco_dict = aruco.Dictionary_get( aruco.DICT_6X6_1000 )</span><br></pre></td></tr></table></figure>
<p>After having this aruco board marker printed, the edge lengths of
this particular aruco marker and the distance between two neighbour
markers are to be measured and stored in two variables
<strong>markerLength</strong> and <strong>markerSeparation</strong>,
which are used to create the <strong>5X7</strong> grid board.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">markerLength = <span class="number">40</span>   <span class="comment"># Here, our measurement unit is centimetre.</span></span><br><span class="line">markerSeparation = <span class="number">8</span>   <span class="comment"># Here, our measurement unit is centimetre.</span></span><br><span class="line">board = aruco.GridBoard_create(<span class="number">5</span>, <span class="number">7</span>, markerLength, markerSeparation, aruco_dict)</span><br></pre></td></tr></table></figure>
<p>Meanwhile, create aruco detector with default parameters.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arucoParams = aruco.DetectorParameters_create()</span><br></pre></td></tr></table></figure>
<h2 id="finally">Finally</h2>
<p>Now, let’s test on a video stream, a .mp4 file. We first load the
video file and initialize a video capture handle.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">videoFile = <span class="string">&quot;aruco\_board\_57.mp4&quot;</span></span><br><span class="line">cap = cv2.VideoCapture(videoFile)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    ret, frame = cap.read() <span class="comment"># Capture frame-by-frame</span></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        frame_remapped = cv2.remap(frame, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)     <span class="comment"># for fisheye remapping</span></span><br><span class="line">        frame_remapped_gray = cv2.cvtColor(frame_remapped, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">        corners, ids, rejectedImgPoints = aruco.detectMarkers(frame_remapped_gray, aruco_dict, parameters=arucoParams)  <span class="comment"># First, detect markers</span></span><br><span class="line">        aruco.refineDetectedMarkers(frame_remapped_gray, board, corners, ids, rejectedImgPoints)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ids != <span class="literal">None</span>: <span class="comment"># if there is at least one marker detected</span></span><br><span class="line">            im_with_aruco_board = aruco.drawDetectedMarkers(frame_remapped, corners, ids, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line">            retval, rvec, tvec = aruco.estimatePoseBoard(corners, ids, board, camera_matrix, dist_coeffs)  <span class="comment"># posture estimation from a diamond</span></span><br><span class="line">            <span class="keyword">if</span> retval != <span class="number">0</span>:</span><br><span class="line">                im_with_aruco_board = aruco.drawAxis(im_with_aruco_board, camera_matrix, dist_coeffs, rvec, tvec, <span class="number">100</span>)  <span class="comment"># axis length 100 can be changed according to your requirement</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            im_with_aruco_board = frame_remapped</span><br><span class="line"></span><br><span class="line">        cv2.imshow(<span class="string">&quot;arucoboard&quot;</span>, im_with_aruco_board)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">2</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>The drawn axis is just the world coordinators and orientations
estimated from the images taken by the testing camera. At the end of the
code, we release the video capture handle and destroy all opening
windows.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cap.release()   <span class="comment"># When everything done, release the capture</span></span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/11/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-diamond/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Nobody">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Longer Vision Technology">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/11/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-diamond/" class="post-title-link" itemprop="url">Camera Posture Estimation Using An ArUco Diamond Marker</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2017-03-11 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-11T00:00:00-08:00">2017-03-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-28 17:33:45" itemprop="dateModified" datetime="2024-09-28T17:33:45-07:00">2024-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="preparation">Preparation</h1>
<p>Very similar to our previous post <a
target="_blank" rel="noopener" href="https://longervision.github.io/2017/03/10/opencv-external-posture-estimation-ArUco-single-marker/">Camera
Posture Estimation Using A Single aruco Marker</a>, you need to make
sure your camera has already been calibrated. In the coding section,
it’s assumed that you can successfully load the camera calibration
parameters.</p>
<h1 id="coding">Coding</h1>
<p>The code can be found at <a
target="_blank" rel="noopener" href="https://github.com/LongerVision/OpenCV_Examples/blob/master/03_external_camera_posture_estimation/ArUco_diamond.py">OpenCV
Examples</a>.</p>
<h2 id="first-of-all">First of all</h2>
<p>We need to ensure <strong>cv2.so</strong> is under our system path.
<strong>cv2.so</strong> is specifically for OpenCV Python.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&#x27;/usr/local/python/3.5&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Then, we import some packages to be used.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> cv2 <span class="keyword">import</span> aruco</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h2 id="secondly">Secondly</h2>
<p>Again, we need to load all camera calibration parameters, including:
<strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. :</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">calibrationFile = <span class="string">&quot;calibrationFileName.xml&quot;</span></span><br><span class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</span><br><span class="line">camera_matrix = calibrationParams.getNode(<span class="string">&quot;cameraMatrix&quot;</span>).mat()</span><br><span class="line">dist_coeffs = calibrationParams.getNode(<span class="string">&quot;distCoeffs&quot;</span>).mat()</span><br></pre></td></tr></table></figure>
<p>If you are using a calibrated fisheye camera like us, two extra
parameters are to be loaded from the calibration file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = calibrationParams.getNode(<span class="string">&quot;R&quot;</span>).mat()</span><br><span class="line">new_camera_matrix = calibrationParams.getNode(<span class="string">&quot;newCameraMatrix&quot;</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Afterwards, two mapping matrices are pre-calculated by calling
function <a
target="_blank" rel="noopener" href="http://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a">cv2.fisheye.initUndistortRectifyMap()</a>
as (supposing the images to be processed are of 1080P):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_size = (<span class="number">1920</span>, <span class="number">1080</span>)</span><br><span class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</span><br></pre></td></tr></table></figure>
<h2 id="thirdly">Thirdly</h2>
<p>The dictionary <strong>aruco.DICT_6X6_250</strong> is to be loaded.
Although current OpenCV provides four groups of <a
target="_blank" rel="noopener" href="http://docs.opencv.org/master/d9/d6a/group__aruco.html">aruco</a>
patterns, <strong>4X4</strong>, <strong>5X5</strong>,
<strong>6X6</strong>, <strong>7X7</strong>, etc., it seems OpenCV Python
does NOT provide a function named <a
target="_blank" rel="noopener" href="http://docs.opencv.org/master/d9/d6a/group__aruco.html#gaf71fb897d5f03f7424c0c84715aa6228">drawCharucoDiamond()</a>.
Therefore, we have to refer to the C++ tutorial <a
target="_blank" rel="noopener" href="http://docs.opencv.org/master/d5/d07/tutorial_charuco_diamond_detection.html">Detection
of Diamond Markers</a>. And, we directly use this particular diamond
marker in the tutorial:</p>
<figure>
<img
src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/board_charuco_diamond.png"
alt="aruco.DICT_6X6_250.diamond" />
<figcaption aria-hidden="true">aruco.DICT_6X6_250.diamond</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aruco_dict = aruco.Dictionary_get( aruco.DICT_6X6_250 )</span><br></pre></td></tr></table></figure>
<p>After having this aruco diamond marker printed, the edge lengths of
this particular diamond marker are to be measured and stored in two
variables <strong>squareLength</strong> and
<strong>markerLength</strong>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">squareLength = <span class="number">40</span>   <span class="comment"># Here, our measurement unit is centimetre.</span></span><br><span class="line">markerLength = <span class="number">25</span>   <span class="comment"># Here, our measurement unit is centimetre.</span></span><br></pre></td></tr></table></figure>
<p>Meanwhile, create aruco detector with default parameters.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arucoParams = aruco.DetectorParameters_create()</span><br></pre></td></tr></table></figure>
<h2 id="finally">Finally</h2>
<p>This time, let’s test on a video stream, a .mp4 file. We first load
the video file and initialize a video capture handle.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">videoFile = <span class="string">&quot;aruco_diamond.mp4&quot;</span></span><br><span class="line">cap = cv2.VideoCapture(videoFile)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    ret, frame = cap.read() <span class="comment"># Capture frame-by-frame</span></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        frame_remapped = cv2.remap(frame, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)     <span class="comment"># for fisheye remapping</span></span><br><span class="line">        frame_remapped_gray = cv2.cvtColor(frame_remapped, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">        corners, ids, rejectedImgPoints = aruco.detectMarkers(frame_remapped_gray, aruco_dict, parameters=arucoParams)  <span class="comment"># First, detect markers</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ids != <span class="literal">None</span>: <span class="comment"># if there is at least one marker detected</span></span><br><span class="line">            diamondCorners, diamondIds = aruco.detectCharucoDiamond(frame_remapped_gray, corners, ids, squareLength/markerLength)   <span class="comment"># Second, detect diamond markers</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(diamondCorners) &gt;= <span class="number">1</span>:    <span class="comment"># if there is at least one diamond detected</span></span><br><span class="line">                im_with_diamond = aruco.drawDetectedDiamonds(frame_remapped, diamondCorners, diamondIds, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line">                rvec, tvec = aruco.estimatePoseSingleMarkers(diamondCorners, squareLength, camera_matrix, dist_coeffs)  <span class="comment"># posture estimation from a diamond</span></span><br><span class="line">                im_with_diamond = aruco.drawAxis(im_with_diamond, camera_matrix, dist_coeffs, rvec, tvec, <span class="number">100</span>)  <span class="comment"># axis length 100 can be changed according to your requirement</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            im_with_diamond = frame_remapped</span><br><span class="line"></span><br><span class="line">        cv2.imshow(<span class="string">&quot;diamondLeft&quot;</span>, im_with_diamond)   <span class="comment"># display</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">2</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):   <span class="comment"># press &#x27;q&#x27; to quit</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>The drawn axis is just the world coordinators and orientations
estimated from the images taken by the testing camera. At the end of the
code, we release the video capture handle and destroy all opening
windows.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cap.release()   <span class="comment"># When everything done, release the capture</span></span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/10/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-single-marker/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Nobody">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Longer Vision Technology">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/10/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-single-marker/" class="post-title-link" itemprop="url">Camera Posture Estimation Using A Single ArUco Marker</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2017-03-10 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-10T00:00:00-08:00">2017-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-28 17:33:45" itemprop="dateModified" datetime="2024-09-28T17:33:45-07:00">2024-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="preparation">Preparation</h1>
<p>Before start coding, you need to ensure your camera has already been
calibrated. (Camera calibration is covered in our blog as well.) In the
coding section, it’s assumed that you can successfully load the camera
calibration parameters.</p>
<h1 id="coding">Coding</h1>
<p>The code can be found at <a
target="_blank" rel="noopener" href="https://github.com/LongerVision/OpenCV_Examples/blob/master/03_external_camera_posture_estimation/ArUco_single_marker.py">OpenCV
Examples</a>.</p>
<h2 id="first-of-all">First of all</h2>
<p>We need to ensure <strong>cv2.so</strong> is under our system path.
<strong>cv2.so</strong> is specifically for OpenCV Python.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&#x27;/usr/local/python/3.5&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Then, we import some packages to be used.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> cv2 <span class="keyword">import</span> aruco</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h2 id="secondly">Secondly</h2>
<p>We now load all camera calibration parameters, including:
<strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. For
example, your code might look like the following:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">calibrationFile = <span class="string">&quot;calibrationFileName.xml&quot;</span></span><br><span class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</span><br><span class="line">camera_matrix = calibrationParams.getNode(<span class="string">&quot;cameraMatrix&quot;</span>).mat()</span><br><span class="line">dist_coeffs = calibrationParams.getNode(<span class="string">&quot;distCoeffs&quot;</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Since we are testing a calibrated fisheye camera, two extra
parameters are to be loaded from the calibration file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = calibrationParams.getNode(<span class="string">&quot;R&quot;</span>).mat()</span><br><span class="line">new_camera_matrix = calibrationParams.getNode(<span class="string">&quot;newCameraMatrix&quot;</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Afterwards, two mapping matrices are pre-calculated by calling
function <a
target="_blank" rel="noopener" href="http://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a">cv2.fisheye.initUndistortRectifyMap()</a>
as (supposing the images to be processed are of 1080P):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_size = (<span class="number">1920</span>, <span class="number">1080</span>)</span><br><span class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</span><br></pre></td></tr></table></figure>
<h2 id="thirdly">Thirdly</h2>
<p>A dictionary is to be loaded. Current OpenCV provides four groups of
<a
target="_blank" rel="noopener" href="http://docs.opencv.org/master/d9/d6a/group__aruco.html">aruco</a>
patterns, <strong>4X4</strong>, <strong>5X5</strong>,
<strong>6X6</strong>, <strong>7X7</strong>, etc. Here,
<strong>aruco.DICT_6X6_1000</strong> is randomly selected as our
example, which looks like:</p>
<figure>
<img
src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/marker_66.jpg"
alt="aruco.DICT_6X6_1000" />
<figcaption aria-hidden="true">aruco.DICT_6X6_1000</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aruco_dict = aruco.Dictionary_get( aruco.DICT_6X6_1000 )</span><br></pre></td></tr></table></figure>
<p>After having this aruco square marker printed, the edge length of
this particular marker is to be measured and stored in a variable
<strong>markerLength</strong>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">markerLength = <span class="number">20</span> <span class="comment"># Here, our measurement unit is centimetre.</span></span><br></pre></td></tr></table></figure>
<p>Meanwhile, create aruco detector with default parameters.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arucoParams = aruco.DetectorParameters_create()</span><br></pre></td></tr></table></figure>
<h2 id="finally">Finally</h2>
<p>Estimate camera postures. Here, we are testing a sequence of images,
rather than video streams. We first list all file names in sequence.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">imgDir = <span class="string">&quot;imgSequence&quot;</span>  <span class="comment"># Specify the image directory</span></span><br><span class="line">imgFileNames = [os.path.join(imgDir, fn) <span class="keyword">for</span> fn <span class="keyword">in</span> <span class="built_in">next</span>(os.walk(imgDir))[<span class="number">2</span>]]</span><br><span class="line">nbOfImgs = <span class="built_in">len</span>(imgFileNames)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, nbOfImgs):</span><br><span class="line">    img = cv2.imread(imgFileNames[i], cv2.IMREAD_COLOR)</span><br><span class="line">    imgRemapped = cv2.remap(img, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT) <span class="comment"># for fisheye remapping</span></span><br><span class="line">    imgRemapped_gray = cv2.cvtColor(imgRemapped, cv2.COLOR_BGR2GRAY)    <span class="comment"># aruco.etectMarkers() requires gray image</span></span><br><span class="line">    corners, ids, rejectedImgPoints = aruco.detectMarkers(imgRemapped_gray, aruco_dict, parameters=arucoParams) <span class="comment"># Detect aruco</span></span><br><span class="line">    <span class="keyword">if</span> ids != <span class="literal">None</span>: <span class="comment"># if aruco marker detected</span></span><br><span class="line">        rvec, tvec = aruco.estimatePoseSingleMarkers(corners, markerLength, camera_matrix, dist_coeffs) <span class="comment"># For a single marker</span></span><br><span class="line">        imgWithAruco = aruco.drawDetectedMarkers(imgRemapped, corners, ids, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line">        imgWithAruco = aruco.drawAxis(imgWithAruco, camera_matrix, dist_coeffs, rvec, tvec, <span class="number">100</span>)    <span class="comment"># axis length 100 can be changed according to your requirement</span></span><br><span class="line">    <span class="keyword">else</span>:   <span class="comment"># if aruco marker is NOT detected</span></span><br><span class="line">        imgWithAruco = imgRemapped  <span class="comment"># assign imRemapped_color to imgWithAruco directly</span></span><br><span class="line"></span><br><span class="line">    cv2.imshow(<span class="string">&quot;aruco&quot;</span>, imgWithAruco)   <span class="comment"># display</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">2</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):   <span class="comment"># if &#x27;q&#x27; is pressed, quit.</span></span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>The drawn axis is just the world coordinators and orientations
estimated from the images taken by the testing camera.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/09/Personal/hi-nobody/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Nobody">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Longer Vision Technology">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/09/Personal/hi-nobody/" class="post-title-link" itemprop="url">Hi, Everyone...</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2017-03-09 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-09T00:00:00-08:00">2017-03-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-09-28 17:33:45" itemprop="dateModified" datetime="2024-09-28T17:33:45-07:00">2024-09-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Personal/" itemprop="url" rel="index"><span itemprop="name">Personal</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Hi, everyone. This is Nobody from <a
target="_blank" rel="noopener" href="http://www.longervision.ca/">Longer Vision Technology</a>. I come
back to life, at least, half life. And finally, I decided to write
something, either useful, or useless. Hope my blogs will be able to help
some of the pure researchers, as well as the students, in the field of
Computer Vision &amp; Machine Vision. By the way, our products will be
put on sale soon. Keep an eye on our blogs please. Thank you…</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/14/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><span class="page-number current">15</span>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Nobody</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
