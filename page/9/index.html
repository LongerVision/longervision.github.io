<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="English">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/logo3d.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/logo3d_32X32.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/logo3d_16x16.png?v=6.3.0">


  <link rel="mask-icon" href="/images/logo3d.svg?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Longer Vision Technology Github Blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Longer Vision Technology">
<meta property="og:url" content="http://longervision.ca/page/9/index.html">
<meta property="og:site_name" content="Longer Vision Technology">
<meta property="og:description" content="Longer Vision Technology Github Blog">
<meta property="article:author" content="Nobody">
<meta property="article:tag" content="Longer Vision">
<meta property="article:tag" content=" Computer Vision">
<meta property="article:tag" content=" AI">
<meta property="article:tag" content=" Machine Learning">
<meta name="twitter:card" content="summary">






  <link rel="canonical" href="http://longervision.ca/page/9/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Longer Vision Technology</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="English">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Longer Vision Technology</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Github Blog</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />Archives</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />Categories</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />Tags</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />About</a>
  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/14/ComputerVision/OpenCV/opencv-external-posture-estimation-circle-grid/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/14/ComputerVision/OpenCV/opencv-external-posture-estimation-circle-grid/" itemprop="url">
                  Camera Posture Estimation Using Circle Grid Pattern
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2017-03-14 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-14T00:00:00-07:00">2017-03-14</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-04-23 04:45:54" itemprop="dateModified" datetime="2020-04-23T04:45:54-07:00">2020-04-23</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="preparation"><a class="markdownIt-Anchor" href="#preparation"></a> Preparation</h1>
<p>A widely used asymmetric circle grid pattern can be found in <a href="http://docs.opencv.org/2.4/_downloads/acircles_pattern.png" target="_blank" rel="noopener">doc of OpenCV 2.4</a>. Same as previous blogs, the camera needs to be calibrated beforehand. For this asymmetric circle grid example, a sequence of images (instead of a video stream) is tested.</p>
<h1 id="coding"><a class="markdownIt-Anchor" href="#coding"></a> Coding</h1>
<p>The code can be found at <a href="https://github.com/LongerVision/Examples_OpenCV/blob/master/01_internal_camera_calibration/circle_grid.py" target="_blank" rel="noopener">OpenCV Examples</a>.</p>
<h2 id="first-of-all"><a class="markdownIt-Anchor" href="#first-of-all"></a> First of all</h2>
<p>We need to ensure <strong><a href="http://cv2.so" target="_blank" rel="noopener">cv2.so</a></strong> is under our system path. <strong><a href="http://cv2.so" target="_blank" rel="noopener">cv2.so</a></strong> is specifically for OpenCV Python.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">'/usr/local/python/3.5'</span>)</span><br></pre></td></tr></table></figure>
<p>Then, we import some packages to be used (<strong>NO ArUco</strong>).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h2 id="secondly"><a class="markdownIt-Anchor" href="#secondly"></a> Secondly</h2>
<p>We now load all camera calibration parameters, including: <strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. For example, your code might look like the following:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">calibrationFile = <span class="string">"calibrationFileName.xml"</span></span><br><span class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</span><br><span class="line">camera_matrix = calibrationParams.getNode(<span class="string">"cameraMatrix"</span>).mat()</span><br><span class="line">dist_coeffs = calibrationParams.getNode(<span class="string">"distCoeffs"</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Since we are testing a calibrated fisheye camera, two extra parameters are to be loaded from the calibration file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = calibrationParams.getNode(<span class="string">"R"</span>).mat()</span><br><span class="line">new_camera_matrix = calibrationParams.getNode(<span class="string">"newCameraMatrix"</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Afterwards, two mapping matrices are pre-calculated by calling function <a href="http://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a" target="_blank" rel="noopener">cv2.fisheye.initUndistortRectifyMap()</a> as (supposing the images to be processed are of 1080P):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_size = (<span class="number">1920</span>, <span class="number">1080</span>)</span><br><span class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</span><br></pre></td></tr></table></figure>
<h2 id="thirdly"><a class="markdownIt-Anchor" href="#thirdly"></a> Thirdly</h2>
<p>The circle pattern is to be loaded.</p>
<p><img src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/pattern_acircles.png" alt="asymmetric_circle_grid" /></p>
<p>Here in our case, this asymmetric circle grid pattern is manually loaded as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Original blob coordinates</span></span><br><span class="line">objectPoints = np.zeros((<span class="number">44</span>, <span class="number">3</span>))  <span class="comment"># In this asymmetric circle grid, 44 circles are adopted.</span></span><br><span class="line">objectPoints[<span class="number">0</span>]  = (<span class="number">0</span>  , <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">1</span>]  = (<span class="number">0</span>  , <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">2</span>]  = (<span class="number">0</span>  , <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">3</span>]  = (<span class="number">0</span>  , <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">4</span>]  = (<span class="number">36</span> , <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">5</span>]  = (<span class="number">36</span> , <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">6</span>]  = (<span class="number">36</span> , <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">7</span>]  = (<span class="number">36</span> , <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">8</span>]  = (<span class="number">72</span> , <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">9</span>]  = (<span class="number">72</span> , <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">10</span>] = (<span class="number">72</span> , <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">11</span>] = (<span class="number">72</span> , <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">12</span>] = (<span class="number">108</span>, <span class="number">36</span>,  <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">13</span>] = (<span class="number">108</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">14</span>] = (<span class="number">108</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">15</span>] = (<span class="number">108</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">16</span>] = (<span class="number">144</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">17</span>] = (<span class="number">144</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">18</span>] = (<span class="number">144</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">19</span>] = (<span class="number">144</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">20</span>] = (<span class="number">180</span>, <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">21</span>] = (<span class="number">180</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">22</span>] = (<span class="number">180</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">23</span>] = (<span class="number">180</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">24</span>] = (<span class="number">216</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">25</span>] = (<span class="number">216</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">26</span>] = (<span class="number">216</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">27</span>] = (<span class="number">216</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">28</span>] = (<span class="number">252</span>, <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">29</span>] = (<span class="number">252</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">30</span>] = (<span class="number">252</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">31</span>] = (<span class="number">252</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">32</span>] = (<span class="number">288</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">33</span>] = (<span class="number">288</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">34</span>] = (<span class="number">288</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">35</span>] = (<span class="number">288</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">36</span>] = (<span class="number">324</span>, <span class="number">36</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">37</span>] = (<span class="number">324</span>, <span class="number">108</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">38</span>] = (<span class="number">324</span>, <span class="number">180</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">39</span>] = (<span class="number">324</span>, <span class="number">252</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">40</span>] = (<span class="number">360</span>, <span class="number">0</span>  , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">41</span>] = (<span class="number">360</span>, <span class="number">72</span> , <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">42</span>] = (<span class="number">360</span>, <span class="number">144</span>, <span class="number">0</span>)</span><br><span class="line">objectPoints[<span class="number">43</span>] = (<span class="number">360</span>, <span class="number">216</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>In our case, the distance between two neighbour circle centres (in the same column) is measured as 72 centimetres. Meanwhile, the axis at the origin is loaded as well, with respective length 300, 200, 100 centimetres.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">axis = np.float32([[<span class="number">360</span>,<span class="number">0</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">240</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">0</span>,<span class="number">-120</span>]]).reshape(<span class="number">-1</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<h2 id="fourthly"><a class="markdownIt-Anchor" href="#fourthly"></a> Fourthly</h2>
<p>Since we are going to use OpenCV’s SimpleBlobDetector for the blob detection, the SimpleBlobDetector’s parameters are to be created beforehand. The parameter values can be adjusted according to your own testing environments. The iteration <strong>criteria</strong> for the simple blob detection is also created at the same time.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup SimpleBlobDetector parameters.</span></span><br><span class="line">blobParams = cv2.SimpleBlobDetector_Params()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change thresholds</span></span><br><span class="line">blobParams.minThreshold = <span class="number">8</span></span><br><span class="line">blobParams.maxThreshold = <span class="number">255</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Area.</span></span><br><span class="line">blobParams.filterByArea = <span class="literal">True</span></span><br><span class="line">blobParams.minArea = <span class="number">64</span>     <span class="comment"># minArea may be adjusted to suit for your experiment</span></span><br><span class="line">blobParams.maxArea = <span class="number">2500</span>   <span class="comment"># maxArea may be adjusted to suit for your experiment</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Circularity</span></span><br><span class="line">blobParams.filterByCircularity = <span class="literal">True</span></span><br><span class="line">blobParams.minCircularity = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Convexity</span></span><br><span class="line">blobParams.filterByConvexity = <span class="literal">True</span></span><br><span class="line">blobParams.minConvexity = <span class="number">0.87</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter by Inertia</span></span><br><span class="line">blobParams.filterByInertia = <span class="literal">True</span></span><br><span class="line">blobParams.minInertiaRatio = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a detector with the parameters</span></span><br><span class="line">blobDetector = cv2.SimpleBlobDetector_create(blobParams)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the iteration criteria</span></span><br><span class="line">criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, <span class="number">30</span>, <span class="number">0.001</span>)</span><br><span class="line"><span class="comment">###################################################################################################</span></span><br></pre></td></tr></table></figure>
<h2 id="finally"><a class="markdownIt-Anchor" href="#finally"></a> Finally</h2>
<p>Estimate camera postures. Here, we are testing a sequence of images, rather than video streams. We first list all file names in sequence.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">imgDir = <span class="string">"imgSequence"</span>  <span class="comment"># Specify the image directory</span></span><br><span class="line">imgFileNames = [os.path.join(imgDir, fn) <span class="keyword">for</span> fn <span class="keyword">in</span> next(os.walk(imgDir))[<span class="number">2</span>]]</span><br><span class="line">nbOfImgs = len(imgFileNames)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, nbOfImgs<span class="number">-1</span>):</span><br><span class="line">    img = cv2.imread(imgFileNames[i], cv2.IMREAD_COLOR)</span><br><span class="line">    imgRemapped = cv2.remap(img, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT) <span class="comment"># for fisheye remapping</span></span><br><span class="line">    imgRemapped_gray = cv2.cvtColor(imgRemapped, cv2.COLOR_BGR2GRAY)    <span class="comment"># blobDetector.detect() requires gray image</span></span><br><span class="line"></span><br><span class="line">    keypoints = blobDetector.detect(imgRemapped_gray) <span class="comment"># Detect blobs.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Draw detected blobs as red circles. This helps cv2.findCirclesGrid() .</span></span><br><span class="line">    im_with_keypoints = cv2.drawKeypoints(imgRemapped, keypoints, np.array([]), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class="line">    im_with_keypoints_gray = cv2.cvtColor(im_with_keypoints, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    ret, corners = cv2.findCirclesGrid(im_with_keypoints, (<span class="number">4</span>,<span class="number">11</span>), <span class="literal">None</span>, flags = cv2.CALIB_CB_ASYMMETRIC_GRID)   <span class="comment"># Find the circle grid</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        corners2 = cv2.cornerSubPix(im_with_keypoints_gray, corners, (<span class="number">11</span>,<span class="number">11</span>), (<span class="number">-1</span>,<span class="number">-1</span>), criteria)    <span class="comment"># Refines the corner locations.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Draw and display the corners.</span></span><br><span class="line">        im_with_keypoints = cv2.drawChessboardCorners(imLeftRemapped, (<span class="number">4</span>,<span class="number">11</span>), corners2, ret)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3D posture</span></span><br><span class="line">        <span class="keyword">if</span> len(corners2) == len(objectPoints):</span><br><span class="line">            retval, rvec, tvec = cv2.solvePnP(objectPoints, corners2, camera_matrix, dist_coeffs)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> retval:</span><br><span class="line">            projectedPoints, jac = cv2.projectPoints(objectPoints, rvec, tvec, camera_matrix, dist_coeffs)  <span class="comment"># project 3D points to image plane</span></span><br><span class="line">            projectedAxis, jacAsix = cv2.projectPoints(axis, rvec, tvec, camera_matrix, dist_coeffs)    <span class="comment"># project axis to image plane</span></span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> projectedPoints:</span><br><span class="line">                p = np.int32(p).reshape(<span class="number">-1</span>,<span class="number">2</span>)</span><br><span class="line">                cv2.circle(im_with_keypoints, (p[<span class="number">0</span>][<span class="number">0</span>], p[<span class="number">0</span>][<span class="number">1</span>]), <span class="number">3</span>, (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>))</span><br><span class="line">            origin = tuple(corners2[<span class="number">0</span>].ravel())</span><br><span class="line">            im_with_keypoints = cv2.line(im_with_keypoints, origin, tuple(projectedAxis[<span class="number">0</span>].ravel()), (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">            im_with_keypoints = cv2.line(im_with_keypoints, origin, tuple(projectedAxis[<span class="number">1</span>].ravel()), (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line">            im_with_keypoints = cv2.line(im_with_keypoints, origin, tuple(projectedAxis[<span class="number">2</span>].ravel()), (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    cv2.imshow(<span class="string">"circlegrid"</span>, im_with_keypoints) <span class="comment"># display</span></span><br><span class="line"></span><br><span class="line">    cv2.waitKey(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>The drawn axis is just the world coordinators and orientations estimated from the images taken by the testing camera.</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/13/ComputerVision/OpenCV/opencv-external-posture-estimation-ChArUco-board/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/13/ComputerVision/OpenCV/opencv-external-posture-estimation-ChArUco-board/" itemprop="url">
                  Camera Posture Estimation Using A ChArUco Board
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2017-03-13 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-13T00:00:00-07:00">2017-03-13</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-04-23 02:14:31" itemprop="dateModified" datetime="2020-04-23T02:14:31-07:00">2020-04-23</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="preparation"><a class="markdownIt-Anchor" href="#preparation"></a> Preparation</h1>
<p>ChAruco is an integrated marker, which combines a chessboard with an aruco marker. The code is also very similar to the code in our previous blog <a href="../../../../../../2017/03/12/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-board/">aruco board</a>.</p>
<h1 id="coding"><a class="markdownIt-Anchor" href="#coding"></a> Coding</h1>
<p>The code can be found at <a href="https://github.com/LongerVision/OpenCV_Examples/blob/master/03_external_camera_posture_estimation/ChArUco_board.py" target="_blank" rel="noopener">OpenCV Examples</a>. And the code in the first two subsections are exactly the same as what’s written in our previous blogs. We’ll neglect the first two subsections ever since.</p>
<h2 id="first-of-all"><a class="markdownIt-Anchor" href="#first-of-all"></a> First of all</h2>
<p>Exactly the same as in previous blogs.</p>
<h2 id="secondly"><a class="markdownIt-Anchor" href="#secondly"></a> Secondly</h2>
<p>Exactly the same as in previous blogs.</p>
<h2 id="thirdly"><a class="markdownIt-Anchor" href="#thirdly"></a> Thirdly</h2>
<p>Dictionary <strong>aruco.DICT_6X6_1000</strong> is integrated with a chessboard to construct a grid charuco board. The experimenting board is of size <strong>5X7</strong>, which looks like:</p>
<p><img src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/board_charuco_57.png" alt="charuco.DICT_6X6_1000.board57" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aruco_dict = aruco.Dictionary_get( aruco.DICT_6X6_1000 )</span><br></pre></td></tr></table></figure>
<p>After having this aruco board marker printed, the edge lengths of this chessboard and aruco marker (displayed in the white cell of the chessboard) are to be measured and stored in two variables <strong>squareLength</strong> and <strong>markerLength</strong>, which are used to create the <strong>5X7</strong> grid board.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">squareLength = <span class="number">40</span>   <span class="comment"># Here, our measurement unit is centimetre.</span></span><br><span class="line">markerLength = <span class="number">30</span>   <span class="comment"># Here, our measurement unit is centimetre.</span></span><br><span class="line">board = aruco.CharucoBoard_create(<span class="number">5</span>, <span class="number">7</span>, squareLength, markerLength, aruco_dict)</span><br></pre></td></tr></table></figure>
<p>Meanwhile, create aruco detector with default parameters.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arucoParams = aruco.DetectorParameters_create()</span><br></pre></td></tr></table></figure>
<h2 id="finally"><a class="markdownIt-Anchor" href="#finally"></a> Finally</h2>
<p>Now, let’s test on a video stream, a .mp4 file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">videoFile = <span class="string">"charuco_board_57.mp4"</span></span><br><span class="line">cap = cv2.VideoCapture(videoFile)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    ret, frame = cap.read() <span class="comment"># Capture frame-by-frame</span></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        frame_remapped = cv2.remap(frame, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)    <span class="comment"># for fisheye remapping</span></span><br><span class="line">        frame_remapped_gray = cv2.cvtColor(frame_remapped, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">        corners, ids, rejectedImgPoints = aruco.detectMarkers(frame_remapped_gray, aruco_dict, parameters=arucoParams)  <span class="comment"># First, detect markers</span></span><br><span class="line">        aruco.refineDetectedMarkers(frame_remapped_gray, board, corners, ids, rejectedImgPoints)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ids != <span class="literal">None</span>: <span class="comment"># if there is at least one marker detected</span></span><br><span class="line">            charucoretval, charucoCorners, charucoIds = aruco.interpolateCornersCharuco(corners, ids, frame_remapped_gray, board)</span><br><span class="line">            im_with_charuco_board = aruco.drawDetectedCornersCharuco(frame_remapped, charucoCorners, charucoIds, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line">            retval, rvec, tvec = aruco.estimatePoseCharucoBoard(charucoCorners, charucoIds, board, camera_matrix, dist_coeffs)  <span class="comment"># posture estimation from a charuco board</span></span><br><span class="line">            <span class="keyword">if</span> retval == <span class="literal">True</span>:</span><br><span class="line">                im_with_charuco_board = aruco.drawAxis(im_with_charuco_board, camera_matrix, dist_coeffs, rvec, tvec, <span class="number">100</span>)  <span class="comment"># axis length 100 can be changed according to your requirement</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            im_with_charuco_left = frame_remapped</span><br><span class="line"></span><br><span class="line">        cv2.imshow(<span class="string">"charucoboard"</span>, im_with_charuco_board)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">2</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>The drawn axis is just the world coordinators and orientations estimated from the images taken by the testing camera.<br />
At the end of the code, we release the video capture handle and destroy all opening windows.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cap.release()   <span class="comment"># When everything done, release the capture</span></span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/12/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-board/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/12/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-board/" itemprop="url">
                  Camera Posture Estimation Using An ArUco Board
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2017-03-12 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-12T00:00:00-08:00">2017-03-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-04-23 04:45:17" itemprop="dateModified" datetime="2020-04-23T04:45:17-07:00">2020-04-23</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="preparation"><a class="markdownIt-Anchor" href="#preparation"></a> Preparation</h1>
<p>Today, let’s test on an aruco board, instead of a <a href="https://longervision.github.io/2017/03/10/opencv-external-posture-estimation-ArUco-single-marker/" target="_blank" rel="noopener">single marker</a> or a <a href="https://longervision.github.io/2017/03/11/opencv-external-posture-estimation-ArUco-diamond/" target="_blank" rel="noopener">diamond marker</a>. Again, you need to make sure your camera has already been calibrated. In the coding section, it’s assumed that you can successfully load the camera calibration parameters.</p>
<h1 id="coding"><a class="markdownIt-Anchor" href="#coding"></a> Coding</h1>
<p>The code can be found at <a href="https://github.com/LongerVision/OpenCV_Examples/blob/master/03_external_camera_posture_estimation/ArUco_single_marker.py" target="_blank" rel="noopener">OpenCV Examples</a>.</p>
<h2 id="first-of-all"><a class="markdownIt-Anchor" href="#first-of-all"></a> First of all</h2>
<p>We need to ensure <strong><a href="http://cv2.so" target="_blank" rel="noopener">cv2.so</a></strong> is under our system path. <strong><a href="http://cv2.so" target="_blank" rel="noopener">cv2.so</a></strong> is specifically for OpenCV Python.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">sys.path.append(<span class="string">'/usr/local/python/3.5'</span>)</span><br></pre></td></tr></table></figure>
<p>Then, we import some packages to be used.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> cv2 <span class="keyword">import</span> aruco</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h2 id="secondly"><a class="markdownIt-Anchor" href="#secondly"></a> Secondly</h2>
<p>Again, we need to load all camera calibration parameters, including: <strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. :</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">calibrationFile = <span class="string">"calibrationFileName.xml"</span></span><br><span class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</span><br><span class="line">camera_matrix = calibrationParams.getNode(<span class="string">"cameraMatrix"</span>).mat()</span><br><span class="line">dist_coeffs = calibrationParams.getNode(<span class="string">"distCoeffs"</span>).mat()</span><br></pre></td></tr></table></figure>
<p>If you are using a calibrated fisheye camera like us, two extra parameters are to be loaded from the calibration file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = calibrationParams.getNode(<span class="string">"R"</span>).mat()</span><br><span class="line">new_camera_matrix = calibrationParams.getNode(<span class="string">"newCameraMatrix"</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Afterwards, two mapping matrices are pre-calculated by calling function <a href="http://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a" target="_blank" rel="noopener">cv2.fisheye.initUndistortRectifyMap()</a> as (supposing the images to be processed are of 1080P):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_size = (<span class="number">1920</span>, <span class="number">1080</span>)</span><br><span class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</span><br></pre></td></tr></table></figure>
<h2 id="thirdly"><a class="markdownIt-Anchor" href="#thirdly"></a> Thirdly</h2>
<p>In our test, the dictionary <strong>aruco.DICT_6X6_1000</strong> is adopted as the unit pattern to construct a grid board. The board is of size <strong>5X7</strong>, which looks like:</p>
<p><img src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/board_aruco_57.png" alt="aruco.DICT_6X6_1000.board57" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aruco_dict = aruco.Dictionary_get( aruco.DICT_6X6_1000 )</span><br></pre></td></tr></table></figure>
<p>After having this aruco board marker printed, the edge lengths of this particular aruco marker and the distance between two neighbour markers are to be measured and stored in two variables <strong>markerLength</strong> and <strong>markerSeparation</strong>, which are used to create the <strong>5X7</strong> grid board.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">markerLength = <span class="number">40</span>   <span class="comment"># Here, our measurement unit is centimetre.</span></span><br><span class="line">markerSeparation = <span class="number">8</span>   <span class="comment"># Here, our measurement unit is centimetre.</span></span><br><span class="line">board = aruco.GridBoard_create(<span class="number">5</span>, <span class="number">7</span>, markerLength, markerSeparation, aruco_dict)</span><br></pre></td></tr></table></figure>
<p>Meanwhile, create aruco detector with default parameters.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arucoParams = aruco.DetectorParameters_create()</span><br></pre></td></tr></table></figure>
<h2 id="finally"><a class="markdownIt-Anchor" href="#finally"></a> Finally</h2>
<p>Now, let’s test on a video stream, a .mp4 file. We first load the video file and initialize a video capture handle.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">videoFile = <span class="string">"aruco\_board\_57.mp4"</span></span><br><span class="line">cap = cv2.VideoCapture(videoFile)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    ret, frame = cap.read() <span class="comment"># Capture frame-by-frame</span></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        frame_remapped = cv2.remap(frame, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)     <span class="comment"># for fisheye remapping</span></span><br><span class="line">        frame_remapped_gray = cv2.cvtColor(frame_remapped, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">        corners, ids, rejectedImgPoints = aruco.detectMarkers(frame_remapped_gray, aruco_dict, parameters=arucoParams)  <span class="comment"># First, detect markers</span></span><br><span class="line">        aruco.refineDetectedMarkers(frame_remapped_gray, board, corners, ids, rejectedImgPoints)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ids != <span class="literal">None</span>: <span class="comment"># if there is at least one marker detected</span></span><br><span class="line">            im_with_aruco_board = aruco.drawDetectedMarkers(frame_remapped, corners, ids, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line">            retval, rvec, tvec = aruco.estimatePoseBoard(corners, ids, board, camera_matrix, dist_coeffs)  <span class="comment"># posture estimation from a diamond</span></span><br><span class="line">            <span class="keyword">if</span> retval != <span class="number">0</span>:</span><br><span class="line">                im_with_aruco_board = aruco.drawAxis(im_with_aruco_board, camera_matrix, dist_coeffs, rvec, tvec, <span class="number">100</span>)  <span class="comment"># axis length 100 can be changed according to your requirement</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            im_with_aruco_board = frame_remapped</span><br><span class="line"></span><br><span class="line">        cv2.imshow(<span class="string">"arucoboard"</span>, im_with_aruco_board)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">2</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>The drawn axis is just the world coordinators and orientations estimated from the images taken by the testing camera.<br />
At the end of the code, we release the video capture handle and destroy all opening windows.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cap.release()   <span class="comment"># When everything done, release the capture</span></span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/11/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-diamond/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/11/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-diamond/" itemprop="url">
                  Camera Posture Estimation Using An ArUco Diamond Marker
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2017-03-11 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-11T00:00:00-08:00">2017-03-11</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-04-23 04:45:36" itemprop="dateModified" datetime="2020-04-23T04:45:36-07:00">2020-04-23</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="preparation"><a class="markdownIt-Anchor" href="#preparation"></a> Preparation</h1>
<p>Very similar to our previous post <a href="https://longervision.github.io/2017/03/10/opencv-external-posture-estimation-ArUco-single-marker/" target="_blank" rel="noopener">Camera Posture Estimation Using A Single aruco Marker</a>, you need to make sure your camera has already been calibrated. In the coding section, it’s assumed that you can successfully load the camera calibration parameters.</p>
<h1 id="coding"><a class="markdownIt-Anchor" href="#coding"></a> Coding</h1>
<p>The code can be found at <a href="https://github.com/LongerVision/OpenCV_Examples/blob/master/03_external_camera_posture_estimation/ArUco_diamond.py" target="_blank" rel="noopener">OpenCV Examples</a>.</p>
<h2 id="first-of-all"><a class="markdownIt-Anchor" href="#first-of-all"></a> First of all</h2>
<p>We need to ensure <strong><a href="http://cv2.so" target="_blank" rel="noopener">cv2.so</a></strong> is under our system path. <strong><a href="http://cv2.so" target="_blank" rel="noopener">cv2.so</a></strong> is specifically for OpenCV Python.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">'/usr/local/python/3.5'</span>)</span><br></pre></td></tr></table></figure>
<p>Then, we import some packages to be used.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> cv2 <span class="keyword">import</span> aruco</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h2 id="secondly"><a class="markdownIt-Anchor" href="#secondly"></a> Secondly</h2>
<p>Again, we need to load all camera calibration parameters, including: <strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. :</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">calibrationFile = <span class="string">"calibrationFileName.xml"</span></span><br><span class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</span><br><span class="line">camera_matrix = calibrationParams.getNode(<span class="string">"cameraMatrix"</span>).mat()</span><br><span class="line">dist_coeffs = calibrationParams.getNode(<span class="string">"distCoeffs"</span>).mat()</span><br></pre></td></tr></table></figure>
<p>If you are using a calibrated fisheye camera like us, two extra parameters are to be loaded from the calibration file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = calibrationParams.getNode(<span class="string">"R"</span>).mat()</span><br><span class="line">new_camera_matrix = calibrationParams.getNode(<span class="string">"newCameraMatrix"</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Afterwards, two mapping matrices are pre-calculated by calling function <a href="http://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a" target="_blank" rel="noopener">cv2.fisheye.initUndistortRectifyMap()</a> as (supposing the images to be processed are of 1080P):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_size = (<span class="number">1920</span>, <span class="number">1080</span>)</span><br><span class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</span><br></pre></td></tr></table></figure>
<h2 id="thirdly"><a class="markdownIt-Anchor" href="#thirdly"></a> Thirdly</h2>
<p>The dictionary <strong>aruco.DICT_6X6_250</strong> is to be loaded. Although current OpenCV provides four groups of <a href="http://docs.opencv.org/master/d9/d6a/group__aruco.html" target="_blank" rel="noopener">aruco</a> patterns, <strong>4X4</strong>, <strong>5X5</strong>, <strong>6X6</strong>, <strong>7X7</strong>, etc., it seems OpenCV Python does NOT provide a function named <a href="http://docs.opencv.org/master/d9/d6a/group__aruco.html#gaf71fb897d5f03f7424c0c84715aa6228" target="_blank" rel="noopener">drawCharucoDiamond()</a>. Therefore, we have to refer to the C++ tutorial <a href="http://docs.opencv.org/master/d5/d07/tutorial_charuco_diamond_detection.html" target="_blank" rel="noopener">Detection of Diamond Markers</a>. And, we directly use this particular diamond marker in the tutorial:</p>
<p><img src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/board_charuco_diamond.png" alt="aruco.DICT_6X6_250.diamond" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aruco_dict = aruco.Dictionary_get( aruco.DICT_6X6_250 )</span><br></pre></td></tr></table></figure>
<p>After having this aruco diamond marker printed, the edge lengths of this particular diamond marker are to be measured and stored in two variables <strong>squareLength</strong> and <strong>markerLength</strong>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">squareLength = <span class="number">40</span>   <span class="comment"># Here, our measurement unit is centimetre.</span></span><br><span class="line">markerLength = <span class="number">25</span>   <span class="comment"># Here, our measurement unit is centimetre.</span></span><br></pre></td></tr></table></figure>
<p>Meanwhile, create aruco detector with default parameters.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arucoParams = aruco.DetectorParameters_create()</span><br></pre></td></tr></table></figure>
<h2 id="finally"><a class="markdownIt-Anchor" href="#finally"></a> Finally</h2>
<p>This time, let’s test on a video stream, a .mp4 file. We first load the video file and initialize a video capture handle.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">videoFile = <span class="string">"aruco_diamond.mp4"</span></span><br><span class="line">cap = cv2.VideoCapture(videoFile)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    ret, frame = cap.read() <span class="comment"># Capture frame-by-frame</span></span><br><span class="line">    <span class="keyword">if</span> ret == <span class="literal">True</span>:</span><br><span class="line">        frame_remapped = cv2.remap(frame, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)     <span class="comment"># for fisheye remapping</span></span><br><span class="line">        frame_remapped_gray = cv2.cvtColor(frame_remapped, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">        corners, ids, rejectedImgPoints = aruco.detectMarkers(frame_remapped_gray, aruco_dict, parameters=arucoParams)  <span class="comment"># First, detect markers</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ids != <span class="literal">None</span>: <span class="comment"># if there is at least one marker detected</span></span><br><span class="line">            diamondCorners, diamondIds = aruco.detectCharucoDiamond(frame_remapped_gray, corners, ids, squareLength/markerLength)   <span class="comment"># Second, detect diamond markers</span></span><br><span class="line">            <span class="keyword">if</span> len(diamondCorners) &gt;= <span class="number">1</span>:    <span class="comment"># if there is at least one diamond detected</span></span><br><span class="line">                im_with_diamond = aruco.drawDetectedDiamonds(frame_remapped, diamondCorners, diamondIds, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line">                rvec, tvec = aruco.estimatePoseSingleMarkers(diamondCorners, squareLength, camera_matrix, dist_coeffs)  <span class="comment"># posture estimation from a diamond</span></span><br><span class="line">                im_with_diamond = aruco.drawAxis(im_with_diamond, camera_matrix, dist_coeffs, rvec, tvec, <span class="number">100</span>)  <span class="comment"># axis length 100 can be changed according to your requirement</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            im_with_diamond = frame_remapped</span><br><span class="line"></span><br><span class="line">        cv2.imshow(<span class="string">"diamondLeft"</span>, im_with_diamond)   <span class="comment"># display</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">2</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):   <span class="comment"># press 'q' to quit</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>The drawn axis is just the world coordinators and orientations estimated from the images taken by the testing camera.<br />
At the end of the code, we release the video capture handle and destroy all opening windows.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cap.release()   <span class="comment"># When everything done, release the capture</span></span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/10/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-single-marker/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/10/ComputerVision/OpenCV/opencv-external-posture-estimation-ArUco-single-marker/" itemprop="url">
                  Camera Posture Estimation Using A Single ArUco Marker
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2017-03-10 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-10T00:00:00-08:00">2017-03-10</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-04-23 04:45:46" itemprop="dateModified" datetime="2020-04-23T04:45:46-07:00">2020-04-23</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Computer-Vision/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="preparation"><a class="markdownIt-Anchor" href="#preparation"></a> Preparation</h1>
<p>Before start coding, you need to ensure your camera has already been calibrated. (Camera calibration is covered in our blog as well.) In the coding section, it’s assumed that you can successfully load the camera calibration parameters.</p>
<h1 id="coding"><a class="markdownIt-Anchor" href="#coding"></a> Coding</h1>
<p>The code can be found at <a href="https://github.com/LongerVision/OpenCV_Examples/blob/master/03_external_camera_posture_estimation/ArUco_single_marker.py" target="_blank" rel="noopener">OpenCV Examples</a>.</p>
<h2 id="first-of-all"><a class="markdownIt-Anchor" href="#first-of-all"></a> First of all</h2>
<p>We need to ensure <strong><a href="http://cv2.so" target="_blank" rel="noopener">cv2.so</a></strong> is under our system path. <strong><a href="http://cv2.so" target="_blank" rel="noopener">cv2.so</a></strong> is specifically for OpenCV Python.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">'/usr/local/python/3.5'</span>)</span><br></pre></td></tr></table></figure>
<p>Then, we import some packages to be used.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> cv2 <span class="keyword">import</span> aruco</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h2 id="secondly"><a class="markdownIt-Anchor" href="#secondly"></a> Secondly</h2>
<p>We now load all camera calibration parameters, including: <strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. For example, your code might look like the following:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">calibrationFile = <span class="string">"calibrationFileName.xml"</span></span><br><span class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</span><br><span class="line">camera_matrix = calibrationParams.getNode(<span class="string">"cameraMatrix"</span>).mat()</span><br><span class="line">dist_coeffs = calibrationParams.getNode(<span class="string">"distCoeffs"</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Since we are testing a calibrated fisheye camera, two extra parameters are to be loaded from the calibration file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = calibrationParams.getNode(<span class="string">"R"</span>).mat()</span><br><span class="line">new_camera_matrix = calibrationParams.getNode(<span class="string">"newCameraMatrix"</span>).mat()</span><br></pre></td></tr></table></figure>
<p>Afterwards, two mapping matrices are pre-calculated by calling function <a href="http://docs.opencv.org/master/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a" target="_blank" rel="noopener">cv2.fisheye.initUndistortRectifyMap()</a> as (supposing the images to be processed are of 1080P):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_size = (<span class="number">1920</span>, <span class="number">1080</span>)</span><br><span class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</span><br></pre></td></tr></table></figure>
<h2 id="thirdly"><a class="markdownIt-Anchor" href="#thirdly"></a> Thirdly</h2>
<p>A dictionary is to be loaded. Current OpenCV provides four groups of <a href="http://docs.opencv.org/master/d9/d6a/group__aruco.html" target="_blank" rel="noopener">aruco</a> patterns, <strong>4X4</strong>, <strong>5X5</strong>, <strong>6X6</strong>, <strong>7X7</strong>, etc. Here, <strong>aruco.DICT_6X6_1000</strong> is randomly selected as our example, which looks like:</p>
<p><img src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/marker_66.jpg" alt="aruco.DICT_6X6_1000" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aruco_dict = aruco.Dictionary_get( aruco.DICT_6X6_1000 )</span><br></pre></td></tr></table></figure>
<p>After having this aruco square marker printed, the edge length of this particular marker is to be measured and stored in a variable <strong>markerLength</strong>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">markerLength = <span class="number">20</span> <span class="comment"># Here, our measurement unit is centimetre.</span></span><br></pre></td></tr></table></figure>
<p>Meanwhile, create aruco detector with default parameters.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arucoParams = aruco.DetectorParameters_create()</span><br></pre></td></tr></table></figure>
<h2 id="finally"><a class="markdownIt-Anchor" href="#finally"></a> Finally</h2>
<p>Estimate camera postures. Here, we are testing a sequence of images, rather than video streams. We first list all file names in sequence.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">imgDir = <span class="string">"imgSequence"</span>  <span class="comment"># Specify the image directory</span></span><br><span class="line">imgFileNames = [os.path.join(imgDir, fn) <span class="keyword">for</span> fn <span class="keyword">in</span> next(os.walk(imgDir))[<span class="number">2</span>]]</span><br><span class="line">nbOfImgs = len(imgFileNames)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, nbOfImgs):</span><br><span class="line">    img = cv2.imread(imgFileNames[i], cv2.IMREAD_COLOR)</span><br><span class="line">    imgRemapped = cv2.remap(img, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT) <span class="comment"># for fisheye remapping</span></span><br><span class="line">    imgRemapped_gray = cv2.cvtColor(imgRemapped, cv2.COLOR_BGR2GRAY)    <span class="comment"># aruco.etectMarkers() requires gray image</span></span><br><span class="line">    corners, ids, rejectedImgPoints = aruco.detectMarkers(imgRemapped_gray, aruco_dict, parameters=arucoParams) <span class="comment"># Detect aruco</span></span><br><span class="line">    <span class="keyword">if</span> ids != <span class="literal">None</span>: <span class="comment"># if aruco marker detected</span></span><br><span class="line">        rvec, tvec = aruco.estimatePoseSingleMarkers(corners, markerLength, camera_matrix, dist_coeffs) <span class="comment"># For a single marker</span></span><br><span class="line">        imgWithAruco = aruco.drawDetectedMarkers(imgRemapped, corners, ids, (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>))</span><br><span class="line">        imgWithAruco = aruco.drawAxis(imgWithAruco, camera_matrix, dist_coeffs, rvec, tvec, <span class="number">100</span>)    <span class="comment"># axis length 100 can be changed according to your requirement</span></span><br><span class="line">    <span class="keyword">else</span>:   <span class="comment"># if aruco marker is NOT detected</span></span><br><span class="line">        imgWithAruco = imgRemapped  <span class="comment"># assign imRemapped_color to imgWithAruco directly</span></span><br><span class="line"></span><br><span class="line">    cv2.imshow(<span class="string">"aruco"</span>, imgWithAruco)   <span class="comment"># display</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">2</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):   <span class="comment"># if 'q' is pressed, quit.</span></span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>The drawn axis is just the world coordinators and orientations estimated from the images taken by the testing camera.</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2017/03/09/Personal/hi-nobody/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/03/09/Personal/hi-nobody/" itemprop="url">
                  Hi, Everyone...
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2017-03-09 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-09T00:00:00-08:00">2017-03-09</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-08-18 14:37:48" itemprop="dateModified" datetime="2019-08-18T14:37:48-07:00">2019-08-18</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Personal/" itemprop="url" rel="index"><span itemprop="name">Personal</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Hi, everyone. This is Nobody from <a href="http://www.longervision.ca/" target="_blank" rel="noopener">Longer Vision Technology</a>. I come back to life, at least, half life. And finally, I decided to write something, either useful, or useless. Hope my blogs will be able to help some of the pure researchers, as well as the students, in the field of Computer Vision &amp; Machine Vision. By the way, our products will be put on sale soon. Keep an eye on our blogs please. Thank you…</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/8/">&lt;i class&#x3D;&quot;fa fa-angle-left&quot; aria-label&#x3D;&quot;Previous page&quot;&gt;&lt;&#x2F;i&gt;</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Nobody</p>
              <p class="site-description motion-element" itemprop="description">Longer Vision Technology Github Blog</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/%20%7C%7C%20archive">
                
                    <span class="site-state-item-count">86</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">29</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">82</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Nobody</span>

  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> v4.2.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Muse</a> v6.3.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



	





  





  










  





  

  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" type="text/css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

   
  


  
  

  

  

  

  

  

</body>
</html>
