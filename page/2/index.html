<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Longer Vision Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Blogs from Longer Vision, focusing on Computer Vision, Deep Learning, Image Processing, etc.">
<meta property="og:type" content="website">
<meta property="og:title" content="Longer Vision Blog">
<meta property="og:url" content="https://longervision.github.io/page/2/index.html">
<meta property="og:site_name" content="Longer Vision Blog">
<meta property="og:description" content="Blogs from Longer Vision, focusing on Computer Vision, Deep Learning, Image Processing, etc.">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Longer Vision Blog">
<meta name="twitter:description" content="Blogs from Longer Vision, focusing on Computer Vision, Deep Learning, Image Processing, etc.">
  
    <link rel="alternate" href="/atom.xml" title="Longer Vision Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Longer Vision Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://longervision.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-opencv-external-posture-estimation-ArUco-board" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/12/opencv-external-posture-estimation-ArUco-board/" class="article-date">
  <time datetime="2017-03-12T18:11:11.000Z" itemprop="datePublished">2017-03-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/12/opencv-external-posture-estimation-ArUco-board/">Camera Posture Estimation Using An ArUco Board</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="preparation">Preparation</h2>
<p>Today, let&#x2019;s test on an aruco board, instead of a <a href="https://longervision.github.io/2017/03/10/opencv-external-posture-estimation-ArUco-single-marker/">single marker</a> or a <a href="https://longervision.github.io/2017/03/11/opencv-external-posture-estimation-ArUco-diamond/">diamond marker</a>. Again, you need to make sure your camera has already been calibrated. In the coding section, it&#x2019;s assumed that you can successfully load the camera calibration parameters.</p>
<h2 id="coding">Coding</h2>
<p>The code can be found at <a href="https://github.com/LongerVision/OpenCV_Examples/blob/master/02_external_camera_posture_estimation/ArUco_board.py" target="_blank" rel="noopener">OpenCV Examples</a>.</p>
<h3 id="first-of-all">First of all</h3>
<p>We need to ensure <strong>cv2.so</strong> is under our system path. <strong>cv2.so</strong> is specifically for OpenCV Python.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">sys.path.append(&apos;/usr/local/python/3.5&apos;)</span><br></pre></td></tr></table></figure>
<p>Then, we import some packages to be used. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import cv2</span><br><span class="line">from cv2 import aruco</span><br><span class="line">import numpy as np</span><br></pre></td></tr></table></figure></p>
<h3 id="secondly">Secondly</h3>
<p>Again, we need to load all camera calibration parameters, including: <strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">calibrationFile = &quot;calibrationFileName.xml&quot;</span><br><span class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE\_STORAGE\_READ)</span><br><span class="line">camera_matrix = calibrationParams.getNode(&quot;cameraMatrix&quot;).mat()</span><br><span class="line">dist_coeffs = calibrationParams.getNode(&quot;distCoeffs&quot;).mat()</span><br></pre></td></tr></table></figure>
<p>If you are using a calibrated fisheye camera like us, two extra parameters are to be loaded from the calibration file.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = calibrationParams.getNode(&quot;R&quot;).mat()</span><br><span class="line">new\_camera\_matrix = calibrationParams.getNode(&quot;newCameraMatrix&quot;).mat()</span><br></pre></td></tr></table></figure>
<p>Afterwards, two mapping matrices are pre-calculated by calling function <a href="http://docs.opencv.org/trunk/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a" target="_blank" rel="noopener">cv2.fisheye.initUndistortRectifyMap()</a> as (supposing the images to be processed are of 1080P):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_size = (1920, 1080)</span><br><span class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</span><br></pre></td></tr></table></figure>
<h3 id="thirdly">Thirdly</h3>
<p>In our test, the dictionary <strong>aruco.DICT_6X6_1000</strong> is adopted as the unit pattern to construct a grid board. The board is of size **5*7**, which looks like:<br>
<img src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/board_aruco_57.png" title="aruco.DICT_6X6_1000.board57" alt="aruco.DICT_6X6_1000.board57"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aruco_dict = aruco.Dictionary_get( aruco.DICT_6X6_1000 )</span><br></pre></td></tr></table></figure>
<p>After having this aruco board marker printed, the edge lengths of this particular aruco marker and the distance between two neighbour markers are to be measured and stored in two variables <strong>markerLength</strong> and <strong>markerSeparation</strong>, which are used to create the **5*7** grid board.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">markerLength = 40   # Here, our measurement unit is centimetre.</span><br><span class="line">markerSeparation = 8   # Here, our measurement unit is centimetre.</span><br><span class="line">board = aruco.GridBoard\_create(5, 7, markerLength, markerSeparation, aruco\_dict)</span><br></pre></td></tr></table></figure>
<p>Meanwhile, create aruco detector with default parameters.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arucoParams = aruco.DetectorParameters_create()</span><br></pre></td></tr></table></figure>
<h3 id="finally">Finally</h3>
<p>Now, let&#x2019;s test on a video stream, a .mp4 file. We first load the video file and initialize a video capture handle.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">videoFile = &quot;aruco\_board\_57.mp4&quot;</span><br><span class="line">cap = cv2.VideoCapture(videoFile)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame: <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">while(True):</span><br><span class="line">    ret, frame = cap.read() # Capture frame-by-frame</span><br><span class="line">    if ret == True:</span><br><span class="line">        frame\_remapped = cv2.remap(frame, map1, map2, cv2.INTER\_LINEAR, cv2.BORDER_CONSTANT)     # for fisheye remapping</span><br><span class="line">        frame\_remapped\_gray = cv2.cvtColor(frame\_remapped, cv2.COLOR\_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">        corners, ids, rejectedImgPoints = aruco.detectMarkers(frame\_remapped\_gray, aruco_dict, parameters=arucoParams)  # First, detect markers</span><br><span class="line">        aruco.refineDetectedMarkers(frame\_remapped\_gray, board, corners, ids, rejectedImgPoints)</span><br><span class="line"></span><br><span class="line">        if ids != None: # if there is at least one marker detected</span><br><span class="line">            im\_with\_aruco\_board = aruco.drawDetectedMarkers(frame\_remapped, corners, ids, (0,255,0))</span><br><span class="line">            retval, rvec, tvec = aruco.estimatePoseBoard(corners, ids, board, camera\_matrix, dist\_coeffs)  # posture estimation from a diamond</span><br><span class="line">            if retval != 0:</span><br><span class="line">                im_with_aruco_board = aruco.drawAxis(im_with_aruco_board, camera_matrix, dist_coeffs, rvec, tvec, 100)  # axis length 100 can be changed according to your requirement</span><br><span class="line">        else:</span><br><span class="line">            im_with_aruco_board = frame_remapped</span><br><span class="line"></span><br><span class="line">        cv2.imshow(&quot;arucoboard&quot;, im_with_aruco_board)</span><br><span class="line"></span><br><span class="line">        if cv2.waitKey(2) &amp; 0xFF == ord(&apos;q&apos;):</span><br><span class="line">            break</span><br><span class="line">    else:</span><br><span class="line">        break</span><br></pre></td></tr></table></figure></p>
<p>The drawn axis is just the world coordinators and orientations estimated from the images taken by the testing camera.<br>
At the end of the code, we release the video capture handle and destroy all opening windows.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cap.release()   # When everything done, release the capture</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://longervision.github.io/2017/03/12/opencv-external-posture-estimation-ArUco-board/" data-id="cjfbycv100004xqy7dlfbhsxo" class="article-share-link">Longer Vision</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Camera-Posture-Estimation-ArUco-Board-Pattern-OpenCV-Python/">Camera Posture Estimation, ArUco Board, Pattern, OpenCV, Python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-opencv-external-posture-estimation-ArUco-diamond" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/11/opencv-external-posture-estimation-ArUco-diamond/" class="article-date">
  <time datetime="2017-03-11T19:11:11.000Z" itemprop="datePublished">2017-03-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/11/opencv-external-posture-estimation-ArUco-diamond/">Camera Posture Estimation Using An ArUco Diamond Marker</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="preparation">Preparation</h2>
<p>Very similar to our previous post <a href="../../10/opencv-external-posture-estimation-ArUco-single-marker/">Camera Posture Estimation Using A Single aruco Marker</a>, you need to make sure your camera has already been calibrated. In the coding section, it&#x2019;s assumed that you can successfully load the camera calibration parameters.</p>
<h2 id="coding">Coding</h2>
<p>The code can be found at <a href="https://github.com/LongerVision/OpenCV_Examples/blob/master/02_external_camera_posture_estimation/ArUco_diamond.py" target="_blank" rel="noopener">OpenCV Examples</a>.</p>
<h3 id="first-of-all">First of all</h3>
<p>We need to ensure <strong>cv2.so</strong> is under our system path. <strong>cv2.so</strong> is specifically for OpenCV Python.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">sys.path.append(&apos;/usr/local/python/3.5&apos;)</span><br></pre></td></tr></table></figure>
<p>Then, we import some packages to be used. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import cv2</span><br><span class="line">from cv2 import aruco</span><br><span class="line">import numpy as np</span><br></pre></td></tr></table></figure></p>
<h3 id="secondly">Secondly</h3>
<p>Again, we need to load all camera calibration parameters, including: <strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">calibrationFile = &quot;calibrationFileName.xml&quot;</span><br><span class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</span><br><span class="line">camera_matrix = calibrationParams.getNode(&quot;cameraMatrix&quot;).mat()</span><br><span class="line">dist_coeffs = calibrationParams.getNode(&quot;distCoeffs&quot;).mat()</span><br></pre></td></tr></table></figure>
<p>If you are using a calibrated fisheye camera like us, two extra parameters are to be loaded from the calibration file.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = calibrationParams.getNode(&quot;R&quot;).mat()</span><br><span class="line">new_camera_matrix = calibrationParams.getNode(&quot;newCameraMatrix&quot;).mat()</span><br></pre></td></tr></table></figure>
<p>Afterwards, two mapping matrices are pre-calculated by calling function <a href="http://docs.opencv.org/trunk/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a" target="_blank" rel="noopener">cv2.fisheye.initUndistortRectifyMap()</a> as (supposing the images to be processed are of 1080P):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_size = (1920, 1080)</span><br><span class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</span><br></pre></td></tr></table></figure>
<h3 id="thirdly">Thirdly</h3>
<p>The dictionary <strong>aruco.DICT_6X6_250</strong> is to be loaded. Although current OpenCV provides four groups of <a href="http://docs.opencv.org/trunk/d9/d6a/group__aruco.html" target="_blank" rel="noopener">aruco</a> patterns, <strong>4X4</strong>, <strong>5X5</strong>, <strong>6X6</strong>, <strong>7X7</strong>, etc., it seems OpenCV Python does NOT provide a function named <a href="http://docs.opencv.org/trunk/d9/d6a/group__aruco.html#gaf71fb897d5f03f7424c0c84715aa6228" target="_blank" rel="noopener">drawCharucoDiamond()</a>. Therefore, we have to refer to the C++ tutorial <a href="http://docs.opencv.org/trunk/d5/d07/tutorial_charuco_diamond_detection.html" target="_blank" rel="noopener">Detection of Diamond Markers</a>. And, we directly use this particular diamond marker in the tutorial:<br>
<img src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/board_charuco_diamond.png" title="aruco.DICT_6X6_250.diamond" alt="aruco.DICT_6X6_250.diamond"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aruco_dict = aruco.Dictionary_get( aruco.DICT_6X6_250 )</span><br></pre></td></tr></table></figure>
<p>After having this aruco diamond marker printed, the edge lengths of this particular diamond marker are to be measured and stored in two variables <strong>squareLength</strong> and <strong>markerLength</strong>.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">squareLength = 40   # Here, our measurement unit is centimetre.</span><br><span class="line">markerLength = 25   # Here, our measurement unit is centimetre.</span><br></pre></td></tr></table></figure>
<p>Meanwhile, create aruco detector with default parameters. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arucoParams = aruco.DetectorParameters_create()</span><br></pre></td></tr></table></figure></p>
<h3 id="finally">Finally</h3>
<p>This time, let&#x2019;s test on a video stream, a .mp4 file. We first load the video file and initialize a video capture handle.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">videoFile = &quot;aruco_diamond.mp4&quot;</span><br><span class="line">cap = cv2.VideoCapture(videoFile)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">while(True):</span><br><span class="line">    ret, frame = cap.read() # Capture frame-by-frame</span><br><span class="line">    if ret == True:</span><br><span class="line">        frame_remapped = cv2.remap(frame, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)     # for fisheye remapping</span><br><span class="line">        frame_remapped_gray = cv2.cvtColor(frame_remapped, cv2.COLOR\_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">        corners, ids, rejectedImgPoints = aruco.detectMarkers(frame_remapped_gray, aruco_dict, parameters=arucoParams)  # First, detect markers</span><br><span class="line"></span><br><span class="line">        if ids != None: # if there is at least one marker detected</span><br><span class="line">            diamondCorners, diamondIds = aruco.detectCharucoDiamond(frame_remapped_gray, corners, ids, squareLength/markerLength)   # Second, detect diamond markers</span><br><span class="line">            if len(diamondCorners) &gt;= 1:    # if there is at least one diamond detected</span><br><span class="line">                im_with_diamond = aruco.drawDetectedDiamonds(frame_remapped, diamondCorners, diamondIds, (0,255,0))</span><br><span class="line">                rvec, tvec = aruco.estimatePoseSingleMarkers(diamondCorners, squareLength, camera_matrix, dist_coeffs)  # posture estimation from a diamond</span><br><span class="line">                im_with_diamond = aruco.drawAxis(im_with_diamond, camera_matrix, dist_coeffs, rvec, tvec, 100)  # axis length 100 can be changed according to your requirement</span><br><span class="line">        else:</span><br><span class="line">            im_with_diamond = frame_remapped</span><br><span class="line"></span><br><span class="line">        cv2.imshow(&quot;diamondLeft&quot;, im_with_diamond)   # display</span><br><span class="line"></span><br><span class="line">        if cv2.waitKey(2) &amp; 0xFF == ord(&apos;q&apos;):   # press &apos;q&apos; to quit</span><br><span class="line">            break</span><br><span class="line">    else:</span><br><span class="line">        break</span><br></pre></td></tr></table></figure>
<p>The drawn axis is just the world coordinators and orientations estimated from the images taken by the testing camera.<br>
At the end of the code, we release the video capture handle and destroy all opening windows.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cap.release()   # When everything done, release the capture</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://longervision.github.io/2017/03/11/opencv-external-posture-estimation-ArUco-diamond/" data-id="cjfbycv120005xqy7ghfdyamj" class="article-share-link">Longer Vision</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Camera-Posture-Estimation-ArUco-Diamond-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, ArUco, Diamond Marker, Pattern, OpenCV, Python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-opencv-external-posture-estimation-ArUco-single-marker" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/10/opencv-external-posture-estimation-ArUco-single-marker/" class="article-date">
  <time datetime="2017-03-11T06:22:22.000Z" itemprop="datePublished">2017-03-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/10/opencv-external-posture-estimation-ArUco-single-marker/">Camera Posture Estimation Using A Single ArUco Marker</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="preparation">Preparation</h2>
<p>Before start coding, you need to ensure your camera has already been calibrated. (Camera calibration is covered in our blog as well.) In the coding section, it&#x2019;s assumed that you can successfully load the camera calibration parameters.</p>
<h2 id="coding">Coding</h2>
<p>The code can be found at <a href="https://github.com/LongerVision/OpenCV_Examples/blob/master/02_external_camera_posture_estimation/ArUco_single_marker.py" target="_blank" rel="noopener">OpenCV Examples</a>.</p>
<h3 id="first-of-all">First of all</h3>
<p>We need to ensure <strong>cv2.so</strong> is under our system path. <strong>cv2.so</strong> is specifically for OpenCV Python.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">sys.path.append(&apos;/usr/local/python/3.5&apos;)</span><br></pre></td></tr></table></figure>
<p>Then, we import some packages to be used.<br>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import cv2</span><br><span class="line">from cv2 import aruco</span><br><span class="line">import numpy as np</span><br></pre></td></tr></table></figure></p>
<h3 id="secondly">Secondly</h3>
<p>We now load all camera calibration parameters, including: <strong>cameraMatrix</strong>, <strong>distCoeffs</strong>, etc. For example, your code might look like the following: <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">calibrationFile = &quot;calibrationFileName.xml&quot;</span><br><span class="line">calibrationParams = cv2.FileStorage(calibrationFile, cv2.FILE_STORAGE_READ)</span><br><span class="line">camera_matrix = calibrationParams.getNode(&quot;cameraMatrix&quot;).mat()</span><br><span class="line">dist_coeffs = calibrationParams.getNode(&quot;distCoeffs&quot;).mat()</span><br></pre></td></tr></table></figure></p>
<p>Since we are testing a calibrated fisheye camera, two extra parameters are to be loaded from the calibration file. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = calibrationParams.getNode(&quot;R&quot;).mat()</span><br><span class="line">new_camera_matrix = calibrationParams.getNode(&quot;newCameraMatrix&quot;).mat()</span><br></pre></td></tr></table></figure></p>
<p>Afterwards, two mapping matrices are pre-calculated by calling function <a href="http://docs.opencv.org/trunk/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a" target="_blank" rel="noopener">cv2.fisheye.initUndistortRectifyMap()</a> as (supposing the images to be processed are of 1080P): <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image_size = (1920, 1080)</span><br><span class="line">map1, map2 = cv2.fisheye.initUndistortRectifyMap(camera_matrix, dist_coeffs, r, new_camera_matrix, image_size, cv2.CV_16SC2)</span><br></pre></td></tr></table></figure></p>
<h3 id="thirdly">Thirdly</h3>
<p>A dictionary is to be loaded. Current OpenCV provides four groups of <a href="http://docs.opencv.org/trunk/d9/d6a/group__aruco.html" target="_blank" rel="noopener">aruco</a> patterns, <strong>4X4</strong>, <strong>5X5</strong>, <strong>6X6</strong>, <strong>7X7</strong>, etc. Here, <strong>aruco.DICT_6X6_1000</strong> is randomly selected as our example, which looks like:<br>
<img src="https://raw.githubusercontent.com/LongerVision/OpenCV_Examples/master/markers/marker_66.jpg" title="aruco.DICT_6X6_1000" alt="aruco.DICT_6X6_1000"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aruco_dict = aruco.Dictionary_get( aruco.DICT_6X6_1000 )</span><br></pre></td></tr></table></figure>
<p>After having this aruco square marker printed, the edge length of this particular marker is to be measured and stored in a variable <strong>markerLength</strong>.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">markerLength = 20 # Here, our measurement unit is centimetre.</span><br></pre></td></tr></table></figure>
<p>Meanwhile, create aruco detector with default parameters.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arucoParams = aruco.DetectorParameters_create()</span><br></pre></td></tr></table></figure>
<h3 id="finally">Finally</h3>
<p>Estimate camera postures. Here, we are testing a sequence of images, rather than video streams. We first list all file names in sequence.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">imgDir = &quot;imgSequence&quot;  # Specify the image directory</span><br><span class="line">imgFileNames = [os.path.join(imgDir, fn) for fn in next(os.walk(imgDir))[2]]</span><br><span class="line">nbOfImgs = len(imgFileNames)</span><br></pre></td></tr></table></figure>
<p>Then, we calculate the camera posture frame by frame: <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">for i in range(0, nbOfImgs):</span><br><span class="line">    img = cv2.imread(imgFileNames[i], cv2.IMREAD_COLOR)</span><br><span class="line">    imgRemapped = cv2.remap(img, map1, map2, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT) # for fisheye remapping</span><br><span class="line">    imgRemapped_gray = cv2.cvtColor(imgRemapped, cv2.COLOR_BGR2GRAY)    # aruco.etectMarkers() requires gray image</span><br><span class="line">    corners, ids, rejectedImgPoints = aruco.detectMarkers(imgRemapped_gray, aruco_dict, parameters=arucoParams) # Detect aruco</span><br><span class="line">    if ids != None: # if aruco marker detected</span><br><span class="line">        rvec, tvec = aruco.estimatePoseSingleMarkers(corners, markerLength, camera_matrix, dist_coeffs) # For a single marker</span><br><span class="line">        imgWithAruco = aruco.drawDetectedMarkers(imgRemapped, corners, ids, (0,255,0))</span><br><span class="line">        imgWithAruco = aruco.drawAxis(imgWithAruco, camera_matrix, dist_coeffs, rvec, tvec, 100)    # axis length 100 can be changed according to your requirement</span><br><span class="line">    else:   # if aruco marker is NOT detected</span><br><span class="line">        imgWithAruco = imgRemapped  # assign imRemapped_color to imgWithAruco directly</span><br><span class="line"></span><br><span class="line">    cv2.imshow(&quot;aruco&quot;, imgWithAruco)   # display</span><br><span class="line">    </span><br><span class="line">    if cv2.waitKey(2) &amp; 0xFF == ord(&apos;q&apos;):   # if &apos;q&apos; is pressed, quit.</span><br><span class="line">        break</span><br></pre></td></tr></table></figure></p>
<p>The drawn axis is just the world coordinators and orientations estimated from the images taken by the testing camera.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://longervision.github.io/2017/03/10/opencv-external-posture-estimation-ArUco-single-marker/" data-id="cjfbycv170009xqy79f6rxqoo" class="article-share-link">Longer Vision</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Camera-Posture-Estimation-ArUco-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, ArUco, Marker, Pattern, OpenCV, Python</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hi-nobody" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/10/hi-nobody/" class="article-date">
  <time datetime="2017-03-10T19:11:11.000Z" itemprop="datePublished">2017-03-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/10/hi-nobody/">Hi, Everyone...</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Hi, everyone. This is Nobody from <a href="http://www.longervision.ca" target="_blank" rel="noopener">Longer Vision Technology</a>. I come back to life, at least, half life. And finally, I decided to write something, either useful, or useless. Hope my blogs will be able to help some of the pure researchers, as well as the students, in the field of Computer Vision &amp; Machine Vision. By the way, our products will be put on sale soon. Keep an eye on our blogs please. Thank you&#x2026;</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://longervision.github.io/2017/03/10/hi-nobody/" data-id="cjfbycv0w0001xqy7xkxd6q5c" class="article-share-link">Longer Vision</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Longer-Vision-Technology-Computer-Vision-Machine-Vision/">Longer Vision Technology, Computer Vision, Machine Vision</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ArUco-Marker-Pattern-OpenCV-Python/">ArUco, Marker, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Beaglebone-Beaglebone-Black-Linaro-GCC-U-Boot-Linux-Kernel-BSP/">Beaglebone, Beaglebone Black, Linaro GCC, U-Boot, Linux Kernel, BSP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN-PyTorch-Deep-Learning-Machine-Learning/">CNN, PyTorch, Deep Learning, Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Calibration-Chessboard-Marker-Pattern-OpenCV-Python/">Camera Calibration, Chessboard, Marker, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Calibration-Circle-Grid-Marker-Pattern-OpenCV-Python/">Camera Calibration, Circle Grid, Marker, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Posture-Estimation-ArUco-Board-Pattern-OpenCV-Python/">Camera Posture Estimation, ArUco Board, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Posture-Estimation-ArUco-Diamond-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, ArUco, Diamond Marker, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Posture-Estimation-ArUco-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, ArUco, Marker, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Posture-Estimation-ChArUco-Board-Pattern-OpenCV-Python/">Camera Posture Estimation, ChArUco Board, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Camera-Posture-Estimation-Circle-Grid-Marker-Pattern-OpenCV-Python/">Camera Posture Estimation, Circle Grid, Marker, Pattern, OpenCV, Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Longer-Vision-Technology-Computer-Vision-Machine-Vision/">Longer Vision Technology, Computer Vision, Machine Vision</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NanoPi-NEO-AllWinner-H3-Armbian-Debian-BSP/">NanoPi NEO, AllWinner H3, Armbian, Debian, BSP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Orange-Pi-Plus-2-AllWinner-H3-Armbian-Ubuntu-Mainline-Linux-Kernel-BSP/">Orange Pi Plus 2, AllWinner H3, Armbian, Ubuntu, Mainline Linux Kernel, BSP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dd-wrt-Wireless-Repeater-Bridge/">dd-wrt, Wireless, Repeater Bridge</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ArUco-Marker-Pattern-OpenCV-Python/" style="font-size: 10px;">ArUco, Marker, Pattern, OpenCV, Python</a> <a href="/tags/Beaglebone-Beaglebone-Black-Linaro-GCC-U-Boot-Linux-Kernel-BSP/" style="font-size: 10px;">Beaglebone, Beaglebone Black, Linaro GCC, U-Boot, Linux Kernel, BSP</a> <a href="/tags/CNN-PyTorch-Deep-Learning-Machine-Learning/" style="font-size: 10px;">CNN, PyTorch, Deep Learning, Machine Learning</a> <a href="/tags/Camera-Calibration-Chessboard-Marker-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Calibration, Chessboard, Marker, Pattern, OpenCV, Python</a> <a href="/tags/Camera-Calibration-Circle-Grid-Marker-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Calibration, Circle Grid, Marker, Pattern, OpenCV, Python</a> <a href="/tags/Camera-Posture-Estimation-ArUco-Board-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Posture Estimation, ArUco Board, Pattern, OpenCV, Python</a> <a href="/tags/Camera-Posture-Estimation-ArUco-Diamond-Marker-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Posture Estimation, ArUco, Diamond Marker, Pattern, OpenCV, Python</a> <a href="/tags/Camera-Posture-Estimation-ArUco-Marker-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Posture Estimation, ArUco, Marker, Pattern, OpenCV, Python</a> <a href="/tags/Camera-Posture-Estimation-ChArUco-Board-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Posture Estimation, ChArUco Board, Pattern, OpenCV, Python</a> <a href="/tags/Camera-Posture-Estimation-Circle-Grid-Marker-Pattern-OpenCV-Python/" style="font-size: 10px;">Camera Posture Estimation, Circle Grid, Marker, Pattern, OpenCV, Python</a> <a href="/tags/Longer-Vision-Technology-Computer-Vision-Machine-Vision/" style="font-size: 10px;">Longer Vision Technology, Computer Vision, Machine Vision</a> <a href="/tags/NanoPi-NEO-AllWinner-H3-Armbian-Debian-BSP/" style="font-size: 10px;">NanoPi NEO, AllWinner H3, Armbian, Debian, BSP</a> <a href="/tags/Orange-Pi-Plus-2-AllWinner-H3-Armbian-Ubuntu-Mainline-Linux-Kernel-BSP/" style="font-size: 10px;">Orange Pi Plus 2, AllWinner H3, Armbian, Ubuntu, Mainline Linux Kernel, BSP</a> <a href="/tags/dd-wrt-Wireless-Repeater-Bridge/" style="font-size: 10px;">dd-wrt, Wireless, Repeater Bridge</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/04/01/CNN-by-PyTorch/">CNN by PyTorch</a>
          </li>
        
          <li>
            <a href="/2018/03/02/setup-repeater-bridge-using-a-dd-wrt-router/">Setup Repeater Bridge Using A dd-wrt Router</a>
          </li>
        
          <li>
            <a href="/2018/02/27/orange-pi-plus-2-armbian/">Install Armbian Ubuntu Desktop with the Newest Supported Mainline Linux Kernel onto Orange Pi Plus 2</a>
          </li>
        
          <li>
            <a href="/2018/02/24/nanopi-neo-armbian/">Install Armbian Debian Server onto NanoPi NEO</a>
          </li>
        
          <li>
            <a href="/2018/01/10/beaglebone-black-uboot-kernel/">Build U-Boot and Linux Kernel for Beaglebone and Beaglebone Black</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Longer Vision<br>
      Powered by <a href="http://www.longervision.com/" target="_blank">Longer Vision</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>