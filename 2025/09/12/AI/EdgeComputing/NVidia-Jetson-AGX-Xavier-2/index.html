<!DOCTYPE html>
<html lang="en,default">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"longervision.ca","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Good new. I‚Äôm flying back to China for some traditional Chinese food - ÁÉ≠Âπ≤Èù¢  üòç‚ù§Ô∏èüòäIn my first blog post about Jetson AGX Xavier early in year 2021, I just did a very simple demo with any industrial ca">
<meta property="og:type" content="article">
<meta property="og:title" content="NVidia Jetson AGX Xavier - Deepstream Live Twitter (2)">
<meta property="og:url" content="http://longervision.ca/2025/09/12/AI/EdgeComputing/NVidia-Jetson-AGX-Xavier-2/index.html">
<meta property="og:site_name" content="Longer Vision Technology">
<meta property="og:description" content="Good new. I‚Äôm flying back to China for some traditional Chinese food - ÁÉ≠Âπ≤Èù¢  üòç‚ù§Ô∏èüòäIn my first blog post about Jetson AGX Xavier early in year 2021, I just did a very simple demo with any industrial ca">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/LongerVision/Resource/refs/heads/main/Embedded/Jetson/AGX_Xavier/2025/neofetch.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LongerVision/Resource/refs/heads/main/Embedded/Jetson/AGX_Xavier/2025/jtop.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LongerVision/Resource/refs/heads/main/Embedded/Jetson/AGX_Xavier/2025/tegrastats_jetson_release.png">
<meta property="og:image" content="https://raw.githubusercontent.com/LongerVision/Resource/refs/heads/main/Embedded/Jetson/AGX_Xavier/2025/deepstream_yolo11s_onnx.png">
<meta property="article:published_time" content="2025-09-12T07:00:00.000Z">
<meta property="article:modified_time" content="2025-09-16T21:00:26.964Z">
<meta property="article:author" content="Nobody">
<meta property="article:tag" content="NVidia, Jetson, Embedded System, AGX Xavier, Edge Computing, Deepstream, Live Twitter">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/LongerVision/Resource/refs/heads/main/Embedded/Jetson/AGX_Xavier/2025/neofetch.png">

<link rel="canonical" href="http://longervision.ca/2025/09/12/AI/EdgeComputing/NVidia-Jetson-AGX-Xavier-2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>NVidia Jetson AGX Xavier - Deepstream Live Twitter (2) | Longer Vision Technology</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Longer Vision Technology</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Github Blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://longervision.ca/2025/09/12/AI/EdgeComputing/NVidia-Jetson-AGX-Xavier-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Nobody">
      <meta itemprop="description" content="Longer Vision Technology Github Blog">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Longer Vision Technology">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          NVidia Jetson AGX Xavier - Deepstream Live Twitter (2)
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-09-12 00:00:00" itemprop="dateCreated datePublished" datetime="2025-09-12T00:00:00-07:00">2025-09-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-09-16 14:00:26" itemprop="dateModified" datetime="2025-09-16T14:00:26-07:00">2025-09-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/Edge-Computing/" itemprop="url" rel="index"><span itemprop="name">Edge Computing</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Good new. I‚Äôm flying back to China for some traditional Chinese food - <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%83%AD%E5%B9%B2%E9%9D%A2">ÁÉ≠Âπ≤Èù¢</a>  üòç‚ù§Ô∏èüòä<br>In my <a href="../../../../../../2021/08/12/AI/EdgeComputing/NVidia-Jetson-AGX-Xavier-1/">first blog post about Jetson AGX Xavier</a> early in year 2021, I just did a very simple demo with any industrial camera using <a target="_blank" rel="noopener" href="https://github.com/AravisProject/aravis">Aravis</a>. Today, I‚Äôm going to make full use of the <a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-gpus">CUDA GPU Compute Capability</a> of my <a target="_blank" rel="noopener" href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-agx-xavier/">Jetson AGX Xavier</a>, running <a target="_blank" rel="noopener" href="https://developer.nvidia.com/deepstream-sdk">DeepStream</a> to live cam stream the city of <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Vancouver">Vancouver</a> and twitter it out.</p>
<p>By the way, I forget to mention my this blog <a href="../../../../../../2024/07/08/MachineVision/RGBD/Kinect-2/">Kinect 2 on Jetson AGX Xavier</a>.</p>
<h1 id="1-Environment"><a href="#1-Environment" class="headerlink" title="1. Environment"></a>1. Environment</h1><h2 id="1-1-neofetch"><a href="#1-1-neofetch" class="headerlink" title="1.1 neofetch"></a>1.1 <code>neofetch</code></h2><p><img src="https://raw.githubusercontent.com/LongerVision/Resource/refs/heads/main/Embedded/Jetson/AGX_Xavier/2025/neofetch.png" alt="Neofetch"></p>
<h2 id="1-2-jtop"><a href="#1-2-jtop" class="headerlink" title="1.2 jtop"></a>1.2 <code>jtop</code></h2><p><img src="https://raw.githubusercontent.com/LongerVision/Resource/refs/heads/main/Embedded/Jetson/AGX_Xavier/2025/jtop.png" alt="jtop"></p>
<h2 id="1-3-tegrastats-and-jetson-release"><a href="#1-3-tegrastats-and-jetson-release" class="headerlink" title="1.3 tegrastats and jetson_release"></a>1.3 <code>tegrastats and jetson_release</code></h2><p><img src="https://raw.githubusercontent.com/LongerVision/Resource/refs/heads/main/Embedded/Jetson/AGX_Xavier/2025/tegrastats_jetson_release.png" alt="tegrastats and jetson_release"></p>
<h1 id="2-DeepStream"><a href="#2-DeepStream" class="headerlink" title="2. DeepStream"></a>2. <a target="_blank" rel="noopener" href="https://developer.nvidia.com/deepstream-sdk">DeepStream</a></h1><h2 id="2-1-Install-DeepStream-On-Jetson-AGX-Xavier"><a href="#2-1-Install-DeepStream-On-Jetson-AGX-Xavier" class="headerlink" title="2.1 Install DeepStream On Jetson AGX Xavier"></a>2.1 Install <a target="_blank" rel="noopener" href="https://developer.nvidia.com/deepstream-sdk">DeepStream</a> On <a target="_blank" rel="noopener" href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-agx-xavier/">Jetson AGX Xavier</a></h2><p>You <strong>first</strong> have to find the corresponding [DeekStream] version from its official website <a target="_blank" rel="noopener" href="https://developer.nvidia.com/deepstream-sdk">DeepStream</a>. Since I‚Äôm using a <a target="_blank" rel="noopener" href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-agx-xavier/">Jetson AGX Xavier</a>, I‚Äôd choose <a target="_blank" rel="noopener" href="https://catalog.ngc.nvidia.com/orgs/nvidia/resources/deepstream/files?version=6.3">DeepStream 6.3</a> and have it installed on my device.</p>
<h2 id="2-2-Prepare-YOLO11-Using-DeepStream-Yolo"><a href="#2-2-Prepare-YOLO11-Using-DeepStream-Yolo" class="headerlink" title="2.2 Prepare YOLO11 Using DeepStream-Yolo"></a>2.2 Prepare <a target="_blank" rel="noopener" href="https://docs.ultralytics.com/models/yolo11/">YOLO11</a> Using <a target="_blank" rel="noopener" href="https://github.com/marcoslucianops/DeepStream-Yolo">DeepStream-Yolo</a></h2><p>Please strictly follow <a target="_blank" rel="noopener" href="https://github.com/LongerVision/DeepStream-Yolo/blob/master/docs/YOLO11.md">DeepStream-Yolo YOLO11 usage</a>.</p>
<p><img src="https://raw.githubusercontent.com/LongerVision/Resource/refs/heads/main/Embedded/Jetson/AGX_Xavier/2025/deepstream_yolo11s_onnx.png" alt="DeepStream Yolo11s Converted to ONNX"></p>
<p><strong><span style="color: red;">And this step is recommended to be done on your desktop, instead of <a target="_blank" rel="noopener" href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-agx-xavier/">Jetson AGX Xavier</a>.</span></strong></p>
<h2 id="2-3-Convert-from-ONNX-to-Engine-for-Jetson-AGX-Xavier-Using-TensorRT"><a href="#2-3-Convert-from-ONNX-to-Engine-for-Jetson-AGX-Xavier-Using-TensorRT" class="headerlink" title="2.3 Convert from ONNX to Engine for Jetson AGX Xavier Using TensorRT"></a>2.3 Convert from ONNX to Engine for <a target="_blank" rel="noopener" href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-agx-xavier/">Jetson AGX Xavier</a> Using <a target="_blank" rel="noopener" href="https://developer.nvidia.com/tensorrt">TensorRT</a></h2><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br></pre></td><td class="code"><pre><span class="line">‚ûú  trtexec \</span><br><span class="line">  --onnx=/opt/nvidia/deepstream/deepstream-6.3/samples/models/yolo/yolo11s_960x544.onnx \</span><br><span class="line">  --saveEngine=/opt/nvidia/deepstream/deepstream-6.3/samples/models/yolo/yolo11s_960x544_fp16.engine \</span><br><span class="line">  --fp16 --workspace=4096</span><br><span class="line">&amp;&amp;&amp;&amp; RUNNING TensorRT.trtexec [TensorRT v8502] # trtexec --onnx=/opt/nvidia/deepstream/deepstream-6.3/samples/models/yolo/yolo11s_960x544.onnx --saveEngine=/opt/nvidia/deepstream/deepstream-6.3/samples/models/yolo/yolo11s_960x544_fp16.engine --fp16 --workspace=4096</span><br><span class="line">[09/13/2025-05:01:04] [W] --workspace flag has been deprecated by --memPoolSize flag.</span><br><span class="line">[09/13/2025-05:01:04] [I] === Model Options ===</span><br><span class="line">[09/13/2025-05:01:04] [I] Format: ONNX</span><br><span class="line">[09/13/2025-05:01:04] [I] Model: /opt/nvidia/deepstream/deepstream-6.3/samples/models/yolo/yolo11s_960x544.onnx</span><br><span class="line">[09/13/2025-05:01:04] [I] Output:</span><br><span class="line">[09/13/2025-05:01:04] [I] === Build Options ===</span><br><span class="line">[09/13/2025-05:01:04] [I] Max batch: explicit batch</span><br><span class="line">[09/13/2025-05:01:04] [I] Memory Pools: workspace: 4096 MiB, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default</span><br><span class="line">[09/13/2025-05:01:04] [I] minTiming: 1</span><br><span class="line">[09/13/2025-05:01:04] [I] avgTiming: 8</span><br><span class="line">[09/13/2025-05:01:04] [I] Precision: FP32+FP16</span><br><span class="line">[09/13/2025-05:01:04] [I] LayerPrecisions: </span><br><span class="line">[09/13/2025-05:01:04] [I] Calibration: </span><br><span class="line">[09/13/2025-05:01:04] [I] Refit: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Sparsity: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Safe mode: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] DirectIO mode: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Restricted mode: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Build only: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Save engine: /opt/nvidia/deepstream/deepstream-6.3/samples/models/yolo/yolo11s_960x544_fp16.engine</span><br><span class="line">[09/13/2025-05:01:04] [I] Load engine: </span><br><span class="line">[09/13/2025-05:01:04] [I] Profiling verbosity: 0</span><br><span class="line">[09/13/2025-05:01:04] [I] Tactic sources: Using default tactic sources</span><br><span class="line">[09/13/2025-05:01:04] [I] timingCacheMode: local</span><br><span class="line">[09/13/2025-05:01:04] [I] timingCacheFile: </span><br><span class="line">[09/13/2025-05:01:04] [I] Heuristic: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Preview Features: Use default preview flags.</span><br><span class="line">[09/13/2025-05:01:04] [I] Input(s)s format: fp32:CHW</span><br><span class="line">[09/13/2025-05:01:04] [I] Output(s)s format: fp32:CHW</span><br><span class="line">[09/13/2025-05:01:04] [I] Input build shapes: model</span><br><span class="line">[09/13/2025-05:01:04] [I] Input calibration shapes: model</span><br><span class="line">[09/13/2025-05:01:04] [I] === System Options ===</span><br><span class="line">[09/13/2025-05:01:04] [I] Device: 0</span><br><span class="line">[09/13/2025-05:01:04] [I] DLACore: </span><br><span class="line">[09/13/2025-05:01:04] [I] Plugins:</span><br><span class="line">[09/13/2025-05:01:04] [I] === Inference Options ===</span><br><span class="line">[09/13/2025-05:01:04] [I] Batch: Explicit</span><br><span class="line">[09/13/2025-05:01:04] [I] Input inference shapes: model</span><br><span class="line">[09/13/2025-05:01:04] [I] Iterations: 10</span><br><span class="line">[09/13/2025-05:01:04] [I] Duration: 3s (+ 200ms warm up)</span><br><span class="line">[09/13/2025-05:01:04] [I] Sleep time: 0ms</span><br><span class="line">[09/13/2025-05:01:04] [I] Idle time: 0ms</span><br><span class="line">[09/13/2025-05:01:04] [I] Streams: 1</span><br><span class="line">[09/13/2025-05:01:04] [I] ExposeDMA: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Data transfers: Enabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Spin-wait: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Multithreading: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] CUDA Graph: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Separate profiling: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Time Deserialize: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Time Refit: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] NVTX verbosity: 0</span><br><span class="line">[09/13/2025-05:01:04] [I] Persistent Cache Ratio: 0</span><br><span class="line">[09/13/2025-05:01:04] [I] Inputs:</span><br><span class="line">[09/13/2025-05:01:04] [I] === Reporting Options ===</span><br><span class="line">[09/13/2025-05:01:04] [I] Verbose: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Averages: 10 inferences</span><br><span class="line">[09/13/2025-05:01:04] [I] Percentiles: 90,95,99</span><br><span class="line">[09/13/2025-05:01:04] [I] Dump refittable layers:Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Dump output: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Profile: Disabled</span><br><span class="line">[09/13/2025-05:01:04] [I] Export timing to JSON file: </span><br><span class="line">[09/13/2025-05:01:04] [I] Export output to JSON file: </span><br><span class="line">[09/13/2025-05:01:04] [I] Export profile to JSON file: </span><br><span class="line">[09/13/2025-05:01:04] [I] </span><br><span class="line">[09/13/2025-05:01:04] [I] === Device Information ===</span><br><span class="line">[09/13/2025-05:01:04] [I] Selected Device: Xavier</span><br><span class="line">[09/13/2025-05:01:04] [I] Compute Capability: 7.2</span><br><span class="line">[09/13/2025-05:01:04] [I] SMs: 8</span><br><span class="line">[09/13/2025-05:01:04] [I] Compute Clock Rate: 1.377 GHz</span><br><span class="line">[09/13/2025-05:01:04] [I] Device Global Memory: 30990 MiB</span><br><span class="line">[09/13/2025-05:01:04] [I] Shared Memory per SM: 96 KiB</span><br><span class="line">[09/13/2025-05:01:04] [I] Memory Bus Width: 256 bits (ECC disabled)</span><br><span class="line">[09/13/2025-05:01:04] [I] Memory Clock Rate: 0.675 GHz</span><br><span class="line">[09/13/2025-05:01:04] [I] </span><br><span class="line">[09/13/2025-05:01:04] [I] TensorRT version: 8.5.2</span><br><span class="line">[09/13/2025-05:01:06] [I] [TRT] [MemUsageChange] Init CUDA: CPU +187, GPU +0, now: CPU 216, GPU 3083 (MiB)</span><br><span class="line">[09/13/2025-05:01:08] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +106, GPU +148, now: CPU 344, GPU 3252 (MiB)</span><br><span class="line">[09/13/2025-05:01:08] [I] Start parsing network model</span><br><span class="line">[09/13/2025-05:01:08] [I] [TRT] ----------------------------------------------------------------</span><br><span class="line">[09/13/2025-05:01:08] [I] [TRT] Input filename:   /opt/nvidia/deepstream/deepstream-6.3/samples/models/yolo/yolo11s_960x544.onnx</span><br><span class="line">[09/13/2025-05:01:08] [I] [TRT] ONNX IR version:  0.0.7</span><br><span class="line">[09/13/2025-05:01:08] [I] [TRT] Opset version:    12</span><br><span class="line">[09/13/2025-05:01:08] [I] [TRT] Producer name:    pytorch</span><br><span class="line">[09/13/2025-05:01:08] [I] [TRT] Producer version: 2.8.0</span><br><span class="line">[09/13/2025-05:01:08] [I] [TRT] Domain:           </span><br><span class="line">[09/13/2025-05:01:08] [I] [TRT] Model version:    0</span><br><span class="line">[09/13/2025-05:01:08] [I] [TRT] Doc string:       </span><br><span class="line">[09/13/2025-05:01:08] [I] [TRT] ----------------------------------------------------------------</span><br><span class="line">[09/13/2025-05:01:08] [W] [TRT] onnx2trt_utils.cpp:375: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.</span><br><span class="line">[09/13/2025-05:01:09] [W] [TRT] onnx2trt_utils.cpp:403: One or more weights outside the range of INT32 was clamped</span><br><span class="line">[09/13/2025-05:01:09] [W] [TRT] Tensor DataType is determined at build time for tensors not marked as input or output.</span><br><span class="line">[09/13/2025-05:01:09] [I] Finish parsing network model</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] ---------- Layers Running on DLA ----------</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] ---------- Layers Running on GPU ----------</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONSTANT: /0/model.23/Constant_3_output_0</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONSTANT: /0/model.23/Constant_3_output_0_clone_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONSTANT: /0/model.23/Constant_3_output_0_clone_2</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONSTANT: /0/model.23/Constant_5_output_0</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONSTANT: /0/model.23/Constant_6_output_0</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONSTANT: (Unnamed Layer* 766) [Constant] + (Unnamed Layer* 767) [Shuffle]</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONSTANT: /0/model.23/Constant_10_output_0</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONSTANT: /0/model.23/Constant_11_output_0</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONSTANT: (Unnamed Layer* 781) [Constant] + (Unnamed Layer* 782) [Shuffle]</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONSTANT: /0/model.23/Constant_15_output_0</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONSTANT: /0/model.23/Constant_16_output_0</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONSTANT: (Unnamed Layer* 796) [Constant] + (Unnamed Layer* 797) [Shuffle]</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.0/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SLICE: /0/model.23/Expand</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SLICE: /0/model.23/Expand_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SLICE: /0/model.23/Expand_2</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SLICE: /0/model.23/Expand_3</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SLICE: /0/model.23/Expand_4</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SLICE: /0/model.23/Expand_5</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Unsqueeze_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Unsqueeze_1_copy_output</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Unsqueeze</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SLICE: /0/model.23/ConstantOfShape</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Unsqueeze_3</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Unsqueeze_3_copy_output</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Unsqueeze_2</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SLICE: /0/model.23/ConstantOfShape_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Unsqueeze_5</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Unsqueeze_5_copy_output</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Unsqueeze_4</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SLICE: /0/model.23/ConstantOfShape_2</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.0/act/Sigmoid), /0/model.0/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Squeeze + (Unnamed Layer* 770) [Shuffle]_copy_input</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Squeeze + (Unnamed Layer* 770) [Shuffle]</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Squeeze_1 + (Unnamed Layer* 785) [Shuffle]_copy_input</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Squeeze_1 + (Unnamed Layer* 785) [Shuffle]</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Squeeze_2 + (Unnamed Layer* 800) [Shuffle]_copy_input</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Squeeze_2 + (Unnamed Layer* 800) [Shuffle]</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Unsqueeze_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Unsqueeze_2_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Unsqueeze_4_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.1/conv/Conv + PWN(PWN(/0/model.1/act/Sigmoid), /0/model.1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] ELEMENTWISE: /0/model.23/Add</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] ELEMENTWISE: /0/model.23/Add_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] ELEMENTWISE: /0/model.23/Add_2</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Reshape_3</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Reshape_3_copy_output</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Reshape_4</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Reshape_4_copy_output</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Reshape_5</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Reshape_5_copy_output</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.2/cv1/conv/Conv + PWN(PWN(/0/model.2/cv1/act/Sigmoid), /0/model.2/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Transpose + /0/model.23/Unsqueeze_6</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.2/m.0/cv1/conv/Conv + PWN(PWN(/0/model.2/m.0/cv1/act/Sigmoid), /0/model.2/m.0/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.2/m.0/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(PWN(/0/model.2/m.0/cv2/act/Sigmoid), /0/model.2/m.0/cv2/act/Mul), /0/model.2/m.0/Add)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.2/Slice_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.2/Slice_1_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.2/cv2/conv/Conv + PWN(PWN(/0/model.2/cv2/act/Sigmoid), /0/model.2/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.3/conv/Conv + PWN(PWN(/0/model.3/act/Sigmoid), /0/model.3/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.4/cv1/conv/Conv + PWN(PWN(/0/model.4/cv1/act/Sigmoid), /0/model.4/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.4/m.0/cv1/conv/Conv + PWN(PWN(/0/model.4/m.0/cv1/act/Sigmoid), /0/model.4/m.0/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.4/m.0/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(PWN(/0/model.4/m.0/cv2/act/Sigmoid), /0/model.4/m.0/cv2/act/Mul), /0/model.4/m.0/Add)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.4/Slice_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.4/Slice_1_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.4/cv2/conv/Conv + PWN(PWN(/0/model.4/cv2/act/Sigmoid), /0/model.4/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.5/conv/Conv + PWN(PWN(/0/model.5/act/Sigmoid), /0/model.5/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.6/cv1/conv/Conv + PWN(PWN(/0/model.6/cv1/act/Sigmoid), /0/model.6/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.6/m.0/cv1/conv/Conv || /0/model.6/m.0/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.6/m.0/cv1/act/Sigmoid), /0/model.6/m.0/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.6/m.0/cv2/act/Sigmoid), /0/model.6/m.0/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.6/m.0/m/m.0/cv1/conv/Conv + PWN(PWN(/0/model.6/m.0/m/m.0/cv1/act/Sigmoid), /0/model.6/m.0/m/m.0/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.6/m.0/m/m.0/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(PWN(/0/model.6/m.0/m/m.0/cv2/act/Sigmoid), /0/model.6/m.0/m/m.0/cv2/act/Mul), /0/model.6/m.0/m/m.0/Add)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.6/m.0/m/m.1/cv1/conv/Conv + PWN(PWN(/0/model.6/m.0/m/m.1/cv1/act/Sigmoid), /0/model.6/m.0/m/m.1/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.6/m.0/m/m.1/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(PWN(/0/model.6/m.0/m/m.1/cv2/act/Sigmoid), /0/model.6/m.0/m/m.1/cv2/act/Mul), /0/model.6/m.0/m/m.1/Add)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.6/m.0/cv3/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.6/m.0/cv3/act/Sigmoid), /0/model.6/m.0/cv3/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.6/Slice_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.6/Slice_1_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.6/cv2/conv/Conv + PWN(PWN(/0/model.6/cv2/act/Sigmoid), /0/model.6/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.7/conv/Conv + PWN(PWN(/0/model.7/act/Sigmoid), /0/model.7/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.8/cv1/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.8/cv1/act/Sigmoid), /0/model.8/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.8/m.0/cv1/conv/Conv || /0/model.8/m.0/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.8/m.0/cv1/act/Sigmoid), /0/model.8/m.0/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.8/m.0/cv2/act/Sigmoid), /0/model.8/m.0/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.8/m.0/m/m.0/cv1/conv/Conv + PWN(PWN(/0/model.8/m.0/m/m.0/cv1/act/Sigmoid), /0/model.8/m.0/m/m.0/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.8/m.0/m/m.0/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(PWN(/0/model.8/m.0/m/m.0/cv2/act/Sigmoid), /0/model.8/m.0/m/m.0/cv2/act/Mul), /0/model.8/m.0/m/m.0/Add)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.8/m.0/m/m.1/cv1/conv/Conv + PWN(PWN(/0/model.8/m.0/m/m.1/cv1/act/Sigmoid), /0/model.8/m.0/m/m.1/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.8/m.0/m/m.1/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(PWN(/0/model.8/m.0/m/m.1/cv2/act/Sigmoid), /0/model.8/m.0/m/m.1/cv2/act/Mul), /0/model.8/m.0/m/m.1/Add)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.8/m.0/cv3/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.8/m.0/cv3/act/Sigmoid), /0/model.8/m.0/cv3/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.8/Slice_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.8/Slice_1_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.8/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.8/cv2/act/Sigmoid), /0/model.8/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.9/cv1/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.9/cv1/act/Sigmoid), /0/model.9/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POOLING: /0/model.9/m/MaxPool</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POOLING: /0/model.9/m_1/MaxPool</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POOLING: /0/model.9/m_2/MaxPool</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.9/cv1/act/Mul_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.9/m/MaxPool_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.9/m_1/MaxPool_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.9/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.9/cv2/act/Sigmoid), /0/model.9/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.10/cv1/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.10/cv1/act/Sigmoid), /0/model.10/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.10/Split_87</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.10/m/m.0/attn/qkv/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.10/m/m.0/attn/Reshape</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.10/m/m.0/attn/Split</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.10/m/m.0/attn/Split_89</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.10/m/m.0/attn/Split_90</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.10/m/m.0/attn/Reshape_2</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] MATRIX_MULTIPLY: /0/model.10/m/m.0/attn/MatMul</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: (Unnamed Layer* 354) [Shuffle]</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SOFTMAX: /0/model.10/m/m.0/attn/Softmax</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: (Unnamed Layer* 356) [Shuffle] + /0/model.10/m/m.0/attn/Transpose_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] MATRIX_MULTIPLY: /0/model.10/m/m.0/attn/MatMul_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.10/m/m.0/attn/Reshape_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.10/m/m.0/attn/pe/conv/Conv + /0/model.10/m/m.0/attn/Add</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.10/m/m.0/attn/proj/conv/Conv + /0/model.10/m/m.0/Add</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.10/m/m.0/ffn/ffn.0/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.10/m/m.0/ffn/ffn.0/act/Sigmoid), /0/model.10/m/m.0/ffn/ffn.0/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.10/m/m.0/ffn/ffn.1/conv/Conv + /0/model.10/m/m.0/Add_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.10/Split_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.10/m/m.0/Add_1_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.10/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.10/cv2/act/Sigmoid), /0/model.10/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] RESIZE: /0/model.11/Resize</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.11/Resize_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.13/cv1/conv/Conv + PWN(PWN(/0/model.13/cv1/act/Sigmoid), /0/model.13/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.13/m.0/cv1/conv/Conv + PWN(PWN(/0/model.13/m.0/cv1/act/Sigmoid), /0/model.13/m.0/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.13/m.0/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(PWN(/0/model.13/m.0/cv2/act/Sigmoid), /0/model.13/m.0/cv2/act/Mul), /0/model.13/m.0/Add)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.13/Slice_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.13/Slice_1_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.13/cv2/conv/Conv + PWN(PWN(/0/model.13/cv2/act/Sigmoid), /0/model.13/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] RESIZE: /0/model.14/Resize</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.14/Resize_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.16/cv1/conv/Conv + PWN(PWN(/0/model.16/cv1/act/Sigmoid), /0/model.16/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.16/m.0/cv1/conv/Conv + PWN(PWN(/0/model.16/m.0/cv1/act/Sigmoid), /0/model.16/m.0/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.16/m.0/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(PWN(/0/model.16/m.0/cv2/act/Sigmoid), /0/model.16/m.0/cv2/act/Mul), /0/model.16/m.0/Add)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.16/Slice_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.16/Slice_1_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.16/cv2/conv/Conv + PWN(PWN(/0/model.16/cv2/act/Sigmoid), /0/model.16/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.17/conv/Conv + PWN(PWN(/0/model.17/act/Sigmoid), /0/model.17/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv2.0/cv2.0.0/conv/Conv + PWN(PWN(/0/model.23/cv2.0/cv2.0.0/act/Sigmoid), /0/model.23/cv2.0/cv2.0.0/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.0/cv3.0.0/cv3.0.0.0/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.23/cv3.0/cv3.0.0/cv3.0.0.0/act/Sigmoid), /0/model.23/cv3.0/cv3.0.0/cv3.0.0.0/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.13/cv2/act/Mul_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv2.0/cv2.0.1/conv/Conv + PWN(PWN(/0/model.23/cv2.0/cv2.0.1/act/Sigmoid), /0/model.23/cv2.0/cv2.0.1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.0/cv3.0.0/cv3.0.0.1/conv/Conv + PWN(PWN(/0/model.23/cv3.0/cv3.0.0/cv3.0.0.1/act/Sigmoid), /0/model.23/cv3.0/cv3.0.0/cv3.0.0.1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.19/cv1/conv/Conv + PWN(PWN(/0/model.19/cv1/act/Sigmoid), /0/model.19/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv2.0/cv2.0.2/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.0/cv3.0.1/cv3.0.1.0/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.23/cv3.0/cv3.0.1/cv3.0.1.0/act/Sigmoid), /0/model.23/cv3.0/cv3.0.1/cv3.0.1.0/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.0/cv3.0.1/cv3.0.1.1/conv/Conv + PWN(PWN(/0/model.23/cv3.0/cv3.0.1/cv3.0.1.1/act/Sigmoid), /0/model.23/cv3.0/cv3.0.1/cv3.0.1.1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.0/cv3.0.2/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Reshape</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Reshape_copy_output</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.19/m.0/cv1/conv/Conv + PWN(PWN(/0/model.19/m.0/cv1/act/Sigmoid), /0/model.19/m.0/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.19/m.0/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(PWN(/0/model.19/m.0/cv2/act/Sigmoid), /0/model.19/m.0/cv2/act/Mul), /0/model.19/m.0/Add)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.19/Slice_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.19/Slice_1_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.19/cv2/conv/Conv + PWN(PWN(/0/model.19/cv2/act/Sigmoid), /0/model.19/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.20/conv/Conv + PWN(PWN(/0/model.20/act/Sigmoid), /0/model.20/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv2.1/cv2.1.0/conv/Conv + PWN(PWN(/0/model.23/cv2.1/cv2.1.0/act/Sigmoid), /0/model.23/cv2.1/cv2.1.0/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.1/cv3.1.0/cv3.1.0.0/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.23/cv3.1/cv3.1.0/cv3.1.0.0/act/Sigmoid), /0/model.23/cv3.1/cv3.1.0/cv3.1.0.0/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.10/cv2/act/Mul_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv2.1/cv2.1.1/conv/Conv + PWN(PWN(/0/model.23/cv2.1/cv2.1.1/act/Sigmoid), /0/model.23/cv2.1/cv2.1.1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.1/cv3.1.0/cv3.1.0.1/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.22/cv1/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.23/cv3.1/cv3.1.0/cv3.1.0.1/act/Sigmoid), /0/model.23/cv3.1/cv3.1.0/cv3.1.0.1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.22/cv1/act/Sigmoid), /0/model.22/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv2.1/cv2.1.2/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.1/cv3.1.1/cv3.1.1.0/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.23/cv3.1/cv3.1.1/cv3.1.1.0/act/Sigmoid), /0/model.23/cv3.1/cv3.1.1/cv3.1.1.0/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.1/cv3.1.1/cv3.1.1.1/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.23/cv3.1/cv3.1.1/cv3.1.1.1/act/Sigmoid), /0/model.23/cv3.1/cv3.1.1/cv3.1.1.1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.1/cv3.1.2/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Reshape_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Reshape_1_copy_output</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.22/m.0/cv1/conv/Conv || /0/model.22/m.0/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.22/m.0/cv1/act/Sigmoid), /0/model.22/m.0/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.22/m.0/cv2/act/Sigmoid), /0/model.22/m.0/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.22/m.0/m/m.0/cv1/conv/Conv + PWN(PWN(/0/model.22/m.0/m/m.0/cv1/act/Sigmoid), /0/model.22/m.0/m/m.0/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.22/m.0/m/m.0/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(PWN(/0/model.22/m.0/m/m.0/cv2/act/Sigmoid), /0/model.22/m.0/m/m.0/cv2/act/Mul), /0/model.22/m.0/m/m.0/Add)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.22/m.0/m/m.1/cv1/conv/Conv + PWN(PWN(/0/model.22/m.0/m/m.1/cv1/act/Sigmoid), /0/model.22/m.0/m/m.1/cv1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.22/m.0/m/m.1/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(PWN(/0/model.22/m.0/m/m.1/cv2/act/Sigmoid), /0/model.22/m.0/m/m.1/cv2/act/Mul), /0/model.22/m.0/m/m.1/Add)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.22/m.0/cv3/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.22/m.0/cv3/act/Sigmoid), /0/model.22/m.0/cv3/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.22/Slice_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.22/Slice_1_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.22/cv2/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.22/cv2/act/Sigmoid), /0/model.22/cv2/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv2.2/cv2.2.0/conv/Conv + PWN(PWN(/0/model.23/cv2.2/cv2.2.0/act/Sigmoid), /0/model.23/cv2.2/cv2.2.0/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.2/cv3.2.0/cv3.2.0.0/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.23/cv3.2/cv3.2.0/cv3.2.0.0/act/Sigmoid), /0/model.23/cv3.2/cv3.2.0/cv3.2.0.0/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv2.2/cv2.2.1/conv/Conv + PWN(PWN(/0/model.23/cv2.2/cv2.2.1/act/Sigmoid), /0/model.23/cv2.2/cv2.2.1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.2/cv3.2.0/cv3.2.0.1/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.23/cv3.2/cv3.2.0/cv3.2.0.1/act/Sigmoid), /0/model.23/cv3.2/cv3.2.0/cv3.2.0.1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv2.2/cv2.2.2/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.2/cv3.2.1/cv3.2.1.0/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.23/cv3.2/cv3.2.1/cv3.2.1.0/act/Sigmoid), /0/model.23/cv3.2/cv3.2.1/cv3.2.1.0/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.2/cv3.2.1/cv3.2.1.1/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(PWN(/0/model.23/cv3.2/cv3.2.1/cv3.2.1.1/act/Sigmoid), /0/model.23/cv3.2/cv3.2.1/cv3.2.1.1/act/Mul)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/cv3.2/cv3.2.2/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Reshape_2</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /0/model.23/Reshape_2_copy_output</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/dfl/Reshape + /0/model.23/dfl/Transpose</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: (Unnamed Layer* 810) [Shuffle]</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SOFTMAX: /0/model.23/dfl/Softmax</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: (Unnamed Layer* 812) [Shuffle] + /0/model.23/dfl/Transpose_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CONVOLUTION: /0/model.23/dfl/conv/Conv</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/dfl/Reshape_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] ELEMENTWISE: /0/model.23/Sub</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] ELEMENTWISE: /0/model.23/Add_4</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /0/model.23/Transpose_1 + (Unnamed Layer* 876) [Shuffle]</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] ELEMENTWISE: /0/model.23/Mul_2</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] POINTWISE: PWN(/0/model.23/Sigmoid)</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] SHUFFLE: /1/Transpose</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /1/Slice_1</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] REDUCE: /1/ReduceMax</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] TOPK: /1/ArgMax</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] CAST: /1/Cast</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /1/Slice_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /1/ReduceMax_output_0 copy</span><br><span class="line">[09/13/2025-05:01:10] [I] [TRT] [GpuLayer] COPY: /1/Cast_output_0 copy</span><br><span class="line">[09/13/2025-05:01:14] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +261, GPU +371, now: CPU 645, GPU 3695 (MiB)</span><br><span class="line">[09/13/2025-05:01:15] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +82, GPU +127, now: CPU 727, GPU 3822 (MiB)</span><br><span class="line">[09/13/2025-05:01:15] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.</span><br><span class="line">[09/13/2025-05:11:07] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size will enable more tactics, please check verbose output for requested sizes.</span><br><span class="line">[09/13/2025-05:22:38] [I] [TRT] Total Activation Memory: 4473714176</span><br><span class="line">[09/13/2025-05:22:38] [I] [TRT] Detected 1 inputs and 4 output network tensors.</span><br><span class="line">[09/13/2025-05:22:39] [I] [TRT] Total Host Persistent Memory: 261264</span><br><span class="line">[09/13/2025-05:22:39] [I] [TRT] Total Device Persistent Memory: 184320</span><br><span class="line">[09/13/2025-05:22:39] [I] [TRT] Total Scratch Memory: 4194304</span><br><span class="line">[09/13/2025-05:22:39] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 19 MiB, GPU 3278 MiB</span><br><span class="line">[09/13/2025-05:22:39] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 196 steps to complete.</span><br><span class="line">[09/13/2025-05:22:39] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 58.1301ms to assign 20 blocks to 196 nodes requiring 24934400 bytes.</span><br><span class="line">[09/13/2025-05:22:39] [I] [TRT] Total Activation Memory: 24934400</span><br><span class="line">[09/13/2025-05:22:39] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1016, GPU 8025 (MiB)</span><br><span class="line">[09/13/2025-05:22:39] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +8, now: CPU 1017, GPU 8033 (MiB)</span><br><span class="line">[09/13/2025-05:22:39] [W] [TRT] TensorRT encountered issues when converting weights between types and that could affect accuracy.</span><br><span class="line">[09/13/2025-05:22:39] [W] [TRT] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.</span><br><span class="line">[09/13/2025-05:22:39] [W] [TRT] Check verbose logs for the list of affected weights.</span><br><span class="line">[09/13/2025-05:22:39] [W] [TRT] - 78 weights are affected by this issue: Detected subnormal FP16 values.</span><br><span class="line">[09/13/2025-05:22:39] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +18, GPU +32, now: CPU 18, GPU 32 (MiB)</span><br><span class="line">[09/13/2025-05:22:39] [E] Saving engine to file failed.</span><br><span class="line">[09/13/2025-05:22:39] [E] Engine set up failed</span><br><span class="line">&amp;&amp;&amp;&amp; FAILED TensorRT.trtexec [TensorRT v8502] # trtexec --onnx=/opt/nvidia/deepstream/deepstream-6.3/samples/models/yolo/yolo11s_960x544.onnx --saveEngine=/opt/nvidia/deepstream/deepstream-6.3/samples/models/yolo/yolo11s_960x544_fp16.engine --fp16 --workspace=4096</span><br><span class="line">‚ûú   </span><br></pre></td></tr></table></figure>



    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/NVidia-Jetson-Embedded-System-AGX-Xavier-Edge-Computing-Deepstream-Live-Twitter/" rel="tag"># NVidia, Jetson, Embedded System, AGX Xavier, Edge Computing, Deepstream, Live Twitter</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/09/05/AI/EdgeComputing/raspberry-pi-5-hailo-2/" rel="prev" title="Raspberry Pi 5 + Hailo AI - (2)">
      <i class="fa fa-chevron-left"></i> Raspberry Pi 5 + Hailo AI - (2)
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/12/14/AI/EdgeComputing/raspberry-pi-5-hailo-3/" rel="next" title="Raspberry Pi 5 + Hailo AI - (3)">
      Raspberry Pi 5 + Hailo AI - (3) <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Environment"><span class="nav-number">1.</span> <span class="nav-text">1. Environment</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-neofetch"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 neofetch</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-jtop"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 jtop</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-tegrastats-and-jetson-release"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 tegrastats and jetson_release</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-DeepStream"><span class="nav-number">2.</span> <span class="nav-text">2. DeepStream</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-Install-DeepStream-On-Jetson-AGX-Xavier"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 Install DeepStream On Jetson AGX Xavier</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-Prepare-YOLO11-Using-DeepStream-Yolo"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 Prepare YOLO11 Using DeepStream-Yolo</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-Convert-from-ONNX-to-Engine-for-Jetson-AGX-Xavier-Using-TensorRT"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 Convert from ONNX to Engine for Jetson AGX Xavier Using TensorRT</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Nobody</p>
  <div class="site-description" itemprop="description">Longer Vision Technology Github Blog</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">157</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">145</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Nobody</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
